
We use cookies to enhance your experience on our website.By continuing to use our website, you are agreeing to our use of cookies. You can change your cookie settings at any time. Find out more Skip to Main Content
Oxford University Press

    Search
    Account Menu
    Menu
    Universidad de Granada - Biblioteca
        Universidad de Granada - Biblioteca
    Sign In
    Register

Navbar Search Filter This issue All Research Evaluation All Journals Mobile Microsite Search Term

    Sign In
    Universidad de Granada - Biblioteca
        Universidad de Granada - Biblioteca
    Register

    Issues
    Advance articles
    Submit
        Author Guidelines
        Submission Site
        Open Access
    Purchase
    Alerts
    About
        About Research Evaluation
        Editorial Board
        Advertising and Corporate Services
        Journals Career Network
        Policies
        Self-Archiving Policy
        Dispatch Dates

Research Evaluation

    Issues
    Advance articles
    Submit
        Author Guidelines
        Submission Site
        Open Access
    Purchase
    Alerts
    About
        About Research Evaluation
        Editorial Board
        Advertising and Corporate Services
        Journals Career Network
        Policies
        Self-Archiving Policy
        Dispatch Dates

Close
search filter This issue All Research Evaluation All Journals search input
Advanced Search
Article Navigation
Close mobile search navigation
Article Navigation
Issue Cover
Volume 23
Issue 4
October 2014
Article Contents

    Abstract
    Introduction
    Focus of this review
    Methodology
    Panel review of grant applications
    Distribution of information
    Conclusions and implications
    Acknowledgements
    Notes
    References

    < Previous
    Next >

Article Navigation
The selection of talent as a group process. A literature review on the social dynamics of decision making in grant panels
Pleun van Arensbergen
1
Nijmegen School of Management, Radboud University, Nijmegen, The Netherlands, 2 Centre for Science and Technology Studies CWTS, Leiden University, Leiden, The Netherlands and 3 Network Institute & Department of Organization Science, VU University, Amsterdam, The Netherlands
*Corresponding author. Email: p.vanarensbergen@fm.ru.nl
Search for other works by this author on:
Oxford Academic
Google Scholar
Pleun van Arensbergen ,
Inge van der Weijden
1
Nijmegen School of Management, Radboud University, Nijmegen, The Netherlands, 2 Centre for Science and Technology Studies CWTS, Leiden University, Leiden, The Netherlands and 3 Network Institute & Department of Organization Science, VU University, Amsterdam, The Netherlands
Search for other works by this author on:
Oxford Academic
Google Scholar
Inge van der Weijden ,
Peter van den Besselaar
1
Nijmegen School of Management, Radboud University, Nijmegen, The Netherlands, 2 Centre for Science and Technology Studies CWTS, Leiden University, Leiden, The Netherlands and 3 Network Institute & Department of Organization Science, VU University, Amsterdam, The Netherlands
Search for other works by this author on:
Oxford Academic
Google Scholar
Peter van den Besselaar
Research Evaluation , Volume 23, Issue 4, October 2014, Pages 298–311, https://doi.org/10.1093/reseval/rvu017
Published:
18 August 2014

    pdf PDF
    Split View
    Views
        Article contents
        Figures & tables
    Cite
    Cite

    Pleun van Arensbergen, Inge van der Weijden, Peter van den Besselaar, The selection of talent as a group process. A literature review on the social dynamics of decision making in grant panels, Research Evaluation , Volume 23, Issue 4, October 2014, Pages 298–311, https://doi.org/10.1093/reseval/rvu017
    Select Format Download citation
    Close
    Permissions Icon Permissions
    Share
        Email
        Twitter
        Facebook
        More

Navbar Search Filter This issue All Research Evaluation All Journals Mobile Microsite Search Term

    Sign In
    Universidad de Granada - Biblioteca
        Universidad de Granada - Biblioteca
    Register

Close
search filter This issue All Research Evaluation All Journals search input
Advanced Search
Abstract

Talent selection within science is increasingly performed by panels, e.g. by reviewing grant or fellowship applications. Many studies from fields of sociology of science and science policy studies have been conducted to identify biases and predict outcomes of these processes, mainly focusing on characteristics of applicants, applications, and reviewers. However, as panel reviewing entails social interaction, group dynamics influence these processes. By adding insights from social psychology to current knowledge on panel reviews, we are better able to identify factors affecting talent selection and funding decisions in grant panels. By opening up this so-called black box, we aim to contribute to a better understanding of the dynamics of panel decision making. This knowledge is also relevant for various stakeholders involved in grant allocation, for applicants, reviewers, and policymakers, as it can be used to improve transparency, fairness, and legitimation of talent selection processes.
Introduction

The academic market in both the United States and most European countries is a buyer’s market, and has been so for quite some years, given the strong preferences of many new PhDs and postdocs for a job at the university. Researchers who are lower in the academic hierarchy hold to an increasing extent temporary positions without prospect of permanent employment ( Stephan 2012 ). This shift towards more temporary contracts is mainly due to an increase of the proportion of research within universities that is based on short-term external funding, like project funding or individual career grants. Consequently, opportunities for especially young academics to conduct research and develop an academic career are more and more characterized by competition for funding. 1

A rationale behind project funding is that it strengthens competition between researchers, and therefore promotes the quality of science: only the best succeed. The ability to acquire research grants is turning into a prominent criterion in processes of academic recruitment and performance evaluation ( De Jonge Akademie 2010 ; Van Arensbergen, Hessels, and van der Meulen 2013 ). Career grants are not only a way to directly distribute financial resources amongst young researchers to conduct research, but it also provides them indirectly with improved career opportunities as grants are considered significant indicators of excellence or talent ( Van Arensbergen, Van der Weijden, and Van den Besselaar 2014 ). This line of reasoning is based on the assumption that grants are awarded to the best applicants. Although this obviously is what funding agencies claim, several recent studies suggest otherwise ( Melin and Danell 2006 ; Van den Besselaar, and Leydesdorff 2007 , 2009 ; Hornborstel et al. 2009 ; Bornmann, Leydesdorff, and Van den Besselaar 2010 ; Van den Besselaar 2013 ). As these funding decisions not only have great impact on individuals’ careers but also shape the direction of academic research ( Hodgson 1997 ; Hornborstel et al. 2009 ), we consider it of great importance to create a better understanding of underlying decision making processes. Of course, uncertainty in grant decisions is unavoidable, which prevents high predictive validity. But a better understanding of the social dynamics may help research councils to improve their selection practices and to reduce the systematic bias that may emerge from social dynamics in decision making bodies.

The main method used to make these allocation decisions is a combination of individual peer review and panel review (peers and other experts reviewing in a group). Originally, peer review is considered the legitimate method to evaluate scientific quality of scholarly contributions and therefore is deeply embedded in research culture. Peers are considered to be best suitable to assess scholarly quality and to distinguish inferior from meritorious research by means of critical appraisal ( Hartmann and Neihardt 1990 ; Langfeldt 2002 ). At the same time, it is highly criticized as being unreliable, costly, and biased (e.g. Marsh, Jayasinghe, and Bond 2008 ; Porter and Rossini 1985 ).

Although peer review has been extensively studied, attempts to predict the outcomes of funding allocation processes show it still largely is a black box ( Cole, Cole, and Simon 1981 ; Hartmann and Neihardt 1990 ; Van den Besselaar, and Leydesdorff 2007 ). Contributing to the unpredictability of these review outcomes is the nature of this type of decision making: it often involves group decision making. Panels of peer experts are installed to assess the quality of applications and to decide on funding allocation. Because panels have to assess heterogeneous objects (e.g. grant applications covering a range of fields, research programs, and job candidates), they are composed in such a way that they cover a broad range of expertise. Consequently, panelists are not all experts or peers to every object they review. Panels may also include nonscientific members, e.g. societal stakeholders, representatives from funding agencies, or university board members. Furthermore, peer review generally is just part of panel review procedures, which often include interviews with applicants too.

Reasons for installing panels mainly have to do with the size and width of the set of applications and with the weight of funding decisions. A panel of reviewers has more resources to draw on than one or two individual reviewers (information integration). And secondly, decisions made by a panel of experts (through consensus building) are considered more acceptable than individual decisions ( Olbrecht and Bornmann 2010 ).
Focus of this review

The present literature study focuses on decision making as performed by panels, including individual peer review. Most of the studies on peer review stem from sociology of science (SoS) and science policy studies (SPS). 2 They mainly deal with how review outcomes are affected by performance and characteristics of individual applicants, and by characteristics of reviewers. These studies are predominantly based on analyses of written documentation (e.g. submitted proposals, review reports, and reports of meetings), interviews (e.g. with reviewers and applicants), and bibliometric data.

However, many allocation (and appointment) decisions are made in panels, which are not covered very well by peer review literature. Panel review is not the same as peer review, as panelists are often not peers. Furthermore, it is embedded within group interaction, and therefore to be characterized as a social activity. For this reason, we combine SoS and SPS literature on peer review with literature on group decision making from social psychology (SP). The first part mainly focuses on how peer review affects review outcomes, whereas the latter part focuses on actual review processes. SP research predominantly deals with central mechanisms involved in decision making processes and the context in which these are carried out. To a large extent, this literature is based on experimental research. Langfeldt ( 2001 , 2002 ), Lamont (2009) , and Olbrecht and Bornmann (2010) also looked at social psychological research with regard to panel review. Although they describe several important mechanisms that could affect panel review (e.g. motivation losses and group polarization), based on exploratory observations of panels, we know there are more factors related to panel interaction that influence allocation decisions.
Methodology

The literature exploited in this study mainly comes from Web of Knowledge searches, added with Google Scholar hits. Figure 1 depicts the straightforward model we used for our literature search and to structure our review.
Figure 1.
Basic model of grant allocation process.
Open in new tab Download slide

Basic model of grant allocation process.
Figure 1.
Basic model of grant allocation process.
Open in new tab Download slide

Basic model of grant allocation process.

We searched for literature using as main key words ‘peer review’, ‘grant allocation’, ‘group decision making’, ‘group interaction’, and ‘intragroup behaviour’. Searches resulted in a broad scope of literature in terms of type of research (e.g. interview studies, bibliometric analyses, historical case study analyses, (laboratory) experiments) and in terms of potential factors influencing panel reviews. Results were refined based on six exploratory observations of panel meetings at three Dutch universities and a national research council in 2010 and 2012, in which grant applications were reviewed and ranked in preselection and selection phases. We observed several issues related to group dynamics, which seemed to influence panel processes. For example, panelists varied in their motivation and contribution to panel deliberation, and similar types of information (e.g. anecdotal or shared) were not always considered evenly important. Factors identified in our observations and included in our SP literature review are social status and identity, group norms and cohesiveness, information distribution, motivation and interests, and procedural factors. Table 1 lists all factors included in this review.
Table 1.

Overview of variables included in the current review
Academic status  	Information distribution  	Prototypicality 
Accountability  	Interests  	Rating scale 
Cohesiveness  	Motivation  	Research field 
Coverage of expertise/skills  	Panelist affiliation  	Research trail 
Decision making task  	Panelist nomination  	Recognition of expertise 
Gender  	Past performance  	Social identity 
Group identity  	Power distribution in panel  	Social status 
Group norms  	Procedural guidelines  	Time pressure 
Academic status  	Information distribution  	Prototypicality 
Accountability  	Interests  	Rating scale 
Cohesiveness  	Motivation  	Research field 
Coverage of expertise/skills  	Panelist affiliation  	Research trail 
Decision making task  	Panelist nomination  	Recognition of expertise 
Gender  	Past performance  	Social identity 
Group identity  	Power distribution in panel  	Social status 
Group norms  	Procedural guidelines  	Time pressure 
Open in new tab
Table 1.

Overview of variables included in the current review
Academic status  	Information distribution  	Prototypicality 
Accountability  	Interests  	Rating scale 
Cohesiveness  	Motivation  	Research field 
Coverage of expertise/skills  	Panelist affiliation  	Research trail 
Decision making task  	Panelist nomination  	Recognition of expertise 
Gender  	Past performance  	Social identity 
Group identity  	Power distribution in panel  	Social status 
Group norms  	Procedural guidelines  	Time pressure 
Academic status  	Information distribution  	Prototypicality 
Accountability  	Interests  	Rating scale 
Cohesiveness  	Motivation  	Research field 
Coverage of expertise/skills  	Panelist affiliation  	Research trail 
Decision making task  	Panelist nomination  	Recognition of expertise 
Gender  	Past performance  	Social identity 
Group identity  	Power distribution in panel  	Social status 
Group norms  	Procedural guidelines  	Time pressure 
Open in new tab

Next, we describe how characteristics of people or proposals under review affect review outcomes. For this, we primarily draw upon SoS and SPS literature. Second, review processes as a social interaction between various panelists are explored in more detail. Characteristics of panels and dynamics inherent to group decision making are further explained predominantly using SP literature. Finally, also based on SP literature, we look at influences of external factors related to the organizational context in which the review process is carried out.

We provide a qualitative overview of the effects, but do not aim at estimating the expected effect sizes, as that would require a meta-analysis for each of the individual factors. However, doing such meta-analyses would be a useful next step.
Panel review of grant applications
Explicit quality-related criteria

Because funding organizations claim to fund only excellent research and the best researchers, one expects in accordance with Merton’s (1973 [1942]) norms of universalism the scholarly quality of grant proposals and of applicants to be central criteria for a proposal’s acceptance or rejection. However, already 30 years ago the study of Cole, Cole, and Simon (1981) on funding decisions within the National Science Foundation could not confirm this. They did not find a strong correlation between funding success and past performance of researchers. More recent studies using different types of data sources show inconsistent results. For example, to build statistical discriminatory models that can replicate peer review outcomes, Cañibano, Otamendi, and Andújar (2009) used curricula vitae of applicants to a Spanish research program. They found research productivity to be the main determinant of grant success. Other studies comparing past performance of granted applicants with unsuccessful applicants generally found that the former have higher average performance than the latter (e.g., Bornmann and Daniel 2006 ; Van Leeuwen and Moed 2012 ; Neufeld, Huber and Wegner 2013 ). However, as competition has become harsh, successful groups are much smaller than rejected groups, which include also many low-performing applicants. This has been subject to further investigation, and researchers have started to compare successful applicants with more restricted sets of good performing rejected ones—something that changed the outcomes: successful applicants do not outperform about equally large groups of best-performing applicants ( Melin and Danell 2006 ; Van den Besselaar and Leydesdorff 2007 , 2009 ; Hornborstel et al. 2009 ). More generally, in terms of past performance, selection processes are characterized by large numbers of false positives (granted applicants performing less than rejected applicants) and false negatives (rejected applicants performing higher than granted applicants). Bornmann, Wallon, and Ledin (2008) found percentages between 26 and 48% in two grant programs within life sciences, and Bornmann, Leydesdorff, and Van den Besselaar (2010) similar percentages in grant programs in the life sciences and the social sciences.

More recently, the focus has shifted from past performance to post performance analyses: do the selected applicants indeed prove to be better in the years after having received grants? Here, similar patterns of results are emerging—granted applicants have in average a better post-performance than all rejected ( Bornmann, Wallon, and Ledin 2008 ) but not if compared with the best rejected ( Melin and Danell 2006 ; Van den Besselaar 2013 ).
Implicit quality-related criteria

Laudel (2006) disproves the dominant ‘quality myth’ in her interview study with German and Australian scientists about their research trails and funding sources. She suggested several non-quality-related factors influencing funding decisions. For example, continuity of research trails and countries’ general investment in research and scientists’ research field . A research field bias was also found in several other studies. Bornmann and Daniel (2005) demonstrate that success rates for doctoral fellowship applicants working in the field of chemistry are approximately half as high as for applicants working in other fields within life sciences. The analysis of applications for postdoctoral fellowships, however, does not confirm this bias, suggesting we cannot speak of an unambiguous relation between research fields of applicants and grant success. A relevant issue here is whether choice of field is a ‘non-quality-related factor’, as there are more promising and less promising research topics and fields, and selection of topics may be seen as a quality of the researcher at stake.

An important variable that should be taken into account is the research field of reviewers. In case of a disciplinary match between applicant and reviewer, review scores were found to be significantly higher than when there is no match ( Porter and Rossini 1985 ). This can be explained in terms of cognitive particularism , meaning that people make decisions based on cognitive similarity, their membership in a particular scientific school of thought. ‘It is not that panel members are not of goodwill but that they simply do not fight so hard for subjects that are not close to their hearts’ ( Travis and Collins 1991 : 336). Consequently, proposals on topics that are unrelated to the panel members’ interests may be disadvantaged here, and that may also hold for interdisciplinary research proposals. As interdisciplinary research can be seen as a novel way of integrating expertise, real peers may be hard to identify 3 . However, research on both peer review and bibliometric assessments found no significant bias with respect to interdisciplinarity ( Rinia et al. 2001 ).

Status also plays an eminent role in evaluation processes. This relates to academic status of applicants and status of their department, university, or institute. Applicants with a higher academic and/or departmental status have better chances of securing grants than applicants with relatively lower status ( Cole, Cole, and Simon 1981 ; Bazeley 1998 ; Viner, Powell, and Green 2004 ; Bornmann and Daniel 2005 ). This shows that not only characteristics of applicants themselves are influential, but also those of institutes they are affiliated with. Another influential type of affiliation involves relations with panelists. Wennerås and Wold (1997) found that higher competence scores are given to applicants who are affiliated with a panelist than to applicants without such ties. This affiliation may explain partly why the academic status of the applicants’ institution plays a role: the panelists themselves may predominantly come from the same high-reputation institutes. Important to emphasize is that the affiliated panelists themselves are not allowed to participate in scoring of the specific proposals. ‘Neutral’ reviewers seem to compensate for the absence of scores by ‘biased’ reviewers by raising their scores assigned to applicants associated with one of their peers. Furthermore, applicants who are themselves member of a peer review cadre have more chance to be allocated grants than applicants who lack this type of a membership ( Viner, Powell, and Green 2004 ), and this is not explained by performance differences ( Van den Besselaar 2012 ).

A highly contested variable in peer review literature is gender . Related to funding decisions, it was demonstrated that women receive relatively fewer grants than men ( Bornmann, Mutz, and Daniel 2007 ). However, there consists general disagreement over the impact of gender on outcomes of peer review and grant allocation. In their well-known study, Wennerås and Wold (1997) looked at applications submitted to the Swedish Medical Research Council. They observed that peer reviewers assigned lower scores to female than to male applicants, while their levels of scientific productivity were about the same. A similar study on grant applications in the Netherlands confirmed that gender matters ( Brouns 2000 ). How it matters was found to vary between disciplines. Whereas in some disciplines, in case of equal average publication scores, more men than women were evaluated as excellent, less productive women also obtained grants in others. This implies the use of double standards. Women have to perform to higher levels to be considered as qualified as men, according to both men and women ( Foschi 2004 ; Van den Brink 2009 ). However, in accordance with several other studies ( Bazeley 1998 ; Jayasinghe, Marsh, and Bond 2001 ; Marsh, Jayasinghe, and Bond 2008 ; Sändstrom and Hallsten 2008 ; Mutz, Bornmann, and Daniel 2012 ), Ceci and Williams (2011) in their recent review on discrimination against women in science, found no evidence supporting current discrimination of women in grant allocation. 4 However, an extension and reanalysis of previous data by Marsh et al. (2009) shows it is important to distinguish between types of applications. Whereas there were no gender differences with regard to grant applications, there were differences in favor of men with regard to fellowship applications.

Decreasing gender disparities can be the effect of changed (council) policies, as suggested by several studies ( Van den Besselaar and Leydesdorff 2007 , 2009 ; Sändstrom and Hallsten 2008 ). Among scientists themselves—male and female—it is not even seen as a main concern in grant assessments ( Van der Weijden and Calero Medina 2014 ). However, because gender disparities persist within science in general (e.g. Ranga, Gupta, and Etzkowitz 2012 ; Larivière et al. 2013 ), this issue still needs further study and attention. 5

As we already saw with regard to research field and affiliation, review outcomes do not solely depend on characteristics of candidates under review. Evaluation outcomes are determined by interaction between characteristics of reviewers and the reviewed. With regard to panel review there is another type of interaction significantly affecting the review outcomes: interaction between panelists. Therefore, we will now take a closer look at panels and describe review processes as social interaction between panelists. We will describe various factors inherent to social interaction that influence decision making processes and are subsequently expected to affect review outcomes. In the following paragraphs, we will identify factors that need to be studied in more detail to determine how they affect outcomes of grant allocation processes.
Peer review as social interaction

As processes of grant allocation generally involve quality assessment by panels, they can be considered to be social, emotional, and interactional processes ( Lamont 2009 ). Panel decisions are the outcome of and are influenced by group interaction. Differences in, for example, status and expertise of the panelists can play an important role in this type of interaction. Furthermore, group interaction can make group members motivate each other and increase the amount of information that is collected and discussed, compared with individual decision making. On the other hand, group interaction can result in poorer decision making because shared responsibility creates a situation in which everyone withdraws and no one really endeavors, better known as social loafing ( Levi 2007 ). It can also encourage members to focus primarily on reaching consensus, so they are not really motivated to detect possible weaknesses in their decisions and to realistically appraise alternative decisions. This social psychological phenomenon is better known as groupthink ( Janis 1982 ). We will therefore look in more detail at panel review as a social interaction process. We will describe how specific characteristics related to the social nature of this process can affect panel decisions. Based on our observations, we will successively focus on the composition of the panel, group norms and cohesiveness, information distribution, and finally, we will look at the motivation and interests of panelists.
Panel composition

Several studies showed that outcomes of reviewing decisions to a great extent depend on who the reviewers are and how the panel is composed (e.g. Lamont 2009 ; Van Arensbergen, Van der Weijden, and Van den Besselaar 2014 ). According to Van den Brink (2009) , in the Netherlands, more women in appointment committees led to higher numbers of women being appointed as full professor. The same was found in a Spanish study on promotion decisions: adding a female evaluator to the committee increases the number of females promoted to full professor by 14% ( Zinovyeva and Bagues 2010 ). This indicates preferences for same-sex candidates. However, this type of bias was not found in promotion decisions for associate professors. Moreover, female associate professors were found to discriminate against female candidates from the same institution, possibly for strategic reasons.

In general, scholars are asked for grant panels based on their disciplinary expertise and research experience. Often applicants may enclose to their proposal names of some reviewers they definitely do not want to be part of the panel. In some cases, applicants also have the opportunity to nominate people for panel membership. Reviewers nominated by applicants are found to systematically give higher scores to all proposals than reviewers who are appointed by the board or otherwise ( Marsh, Jayasinghe, and Bond 2008 ; Jayasinghe, Marsh, and Bond 2001 ).

Another aspect of panel composition is the difference in expertise represented by panelists. The set of applications generally covers a broad range of topics, sometimes even from various disciplines. Consequently, experts from different disciplines have to be included in the panel to enable a fair and comprehensive evaluation of all proposals. But also within a disciplinary panel, people can be considered experts on different topics or research areas. It is important to pay attention to panel composition, as the composition sets the potential for interaction and conflict among its members. Overlap in competences is associated with better cooperation and with open conflict between scientific experts ( Langfeldt 2002 ). Research on decision making also shows that groups with heterogeneous members with complementary skills take better group decisions than homogenous groups ( Levi 2007 ). However, the advantage of heterogeneous groups does not arise directly from the broad range of knowledge that is present in groups. Members have to be conscious of differences in areas of expertise. An experiment conducted by Bonner, Baumann, and Dalal (2002) showed that when group members know who the experts are in reference to a specific task, they will adjust their group decision to the decision of the experts. This of course, does not necessarily mean that the group decision will be of better quality when decisions of experts are taken over. But it can be considered a stimulus for information sharing. A social psychological experiment using the hidden profile 6 task demonstrates that when people know who knows what, distributed information is mentioned more often and the hidden profile is solved more often ( Stasser, Stewart, and Wittenbaum 1995 ). Hence, group decision making can benefit from diverse panel compositions as long as this diversity is evident to everyone within the panel. We will come back to the issue of information sharing later.

Furthermore, within panels there may be differences in status. By this we mean the status as perceived and implicitly assigned to them by other panelists. Some people might be considered to be hotshots with very good reputation and hence have a high status. Others might be seen as newcomers or relatively insignificant in their field. These perceived status differences cause unequal power distribution amongst group members, which subsequently will disturb communication within groups. In general, high-status members talk more and receive more attention from other members. Low-status members generally talk less or even do not talk at all when their opinions deviate from those of high-status members. This can harm decision making processes because not all true opinions are expressed and high-status people will not be contradicted often. Communication plays an important role in processes of group decision making. For a group to perform well, it is desirable that group members trust each other and that there is open communication between them. This can be facilitated by good social relations within the group ( Levi 2007 ).

Finally, panel composition affects the way individual panelists identify themselves. Individuals do not have one fixed identity, but depending on the social context they are in, different identities can be addressed. Interaction between characteristics of individuals and of the specific situation determines which particular identity is activated. This process of social identity formation comprises two important activities, namely social comparison and self-categorization in terms of membership in particular groups ( Stets and Burke 2000 ). By means of self-categorization, in-groups and out-groups are created, which leads to accentuation of perceived similarities between the self and other in-group members and of perceived differences between the self and out-group members ( Hogg and Terry 2000 ). Grant panels can be considered by its members as (one) in-group, but can also comprise several smaller groups. Panelists possibly identify themselves with some and not with other members. For example, when people share a disciplinary background, professional status, or faculty membership, this can determine the in-group identity.

Van Kleef et al. (2007) studied social identification in terms of prototypicality. A group that people identify with generally comprises one or more members that can be considered to be the group prototype. ‘Prototypes embody all attributes that characterize groups and distinguish them from other groups, including beliefs, attitudes, feelings, and behaviours’ ( Hogg and Terry 2000 : 123). In two experiments, Van Kleef et al. (2007) compared differences in negotiation behavior between prototypical and peripheral group members. Prototypical group members are those who strongly match group prototypes and those who hardly match are called peripherals. They demonstrate that in case of valued group membership (wanting to be part of the group), peripherals within the group are more competitive and less cooperative than prototypicals. Two studies conducted by Terry and Hogg (1996) show that social identification has an effect on the intentions and actual behavior of group members. ‘When social identity is salient, depersonalization occurs, such that a person’s feelings and actions are guided more by group prototypes and norms than by personal factors’ (p. 790).
Group norms and cohesiveness

According to Lamont (2009) , panel discussions are steered by informal rules, generally known by all panelists. These unwritten rules defining appropriate and inappropriate behavior in groups are called group norms . Norms usually emerge unconsciously and gradually through interactions of group members, and are not necessarily made explicit or formal. Sometimes people are unable to articulate norms that they clearly use to guide their behavior. Norms can have a strong impact on behavior of group members, even stronger than externally imposed rules, e.g. by supervisors or organizational practices. Examples of group norms are that panelists are expected to give each other full liberty to express opinions without reprisal, they should be oriented towards producing consensual decisions, and they should maintain collegiality ( Janis 1982 ; Spector 1996 ; Marques et al. 2001 ; Levi 2007 ; Lamont 2009 ).

According to Levi (2007) , norms enable groups to create a clear group identity , as they express central values of groups and prescribe what the accepted and deviant behavior within groups are. This way, group members can distinguish themselves from others and have a sense of who they are as a group. The other way around, norms are found to be dependent on the social identity perceived by individual panelists. As mentioned earlier, group norms have more effect on the behavior of individuals the stronger they identify themselves as being part of a social group and not merely as unique individuals ( Terry and Hogg 1996 ). Social identity is related to cohesiveness within groups. A highly cohesive group is characterized by strong interpersonal bonds holding a group together. Group cohesiveness refers to a sense of team spirit and the extent to which group members appreciate their group membership and share group goals. Conformity to norms is found to be more likely in groups that are highly cohesive ( Spector 1996 ; Levi 2007 ). Groups characterized by high levels of cohesion are found to be better able to communicate and work together ( Beal et al. 2003 ). This could lead to better group outcomes. An analysis of case histories of seven corporations compared decision making characteristics of top management teams in successful and unsuccessful times ( Peterson et al. 1998 ). Group cohesiveness was one of the characteristics they studied. They found that successful decision making groups showed more cohesiveness than unsuccessful groups. On the other hand, members of cohesive groups may want to preserve the group’s relationships and therefore avoid any kind of behavior considered to be harmful. This could mean that people agree to group decisions, while they actually do not agree with it individually. According to Janis (1982) , strong group cohesion is one of the important antecedent conditions for groupthink; ‘a mode of thinking that people engage in when they are deeply involved in a cohesive in-group, when the members’ strivings for unanimity override their motivation to realistically appraise alternative courses of action’ (p. 9). Groupthink increases chances on flaws in the decision making process, consequently, leading to poorer decisions. However, Esser (1998) , who reviewed two areas of groupthink research—historical case analyses and laboratory tests—poses that group cohesiveness is not a strong predictor of groupthink. That cohesiveness is a rather complex variable was also shown by Spector (1996) , who found no unambiguous relation between cohesiveness and group performance or decision making.
Distribution of information

The main advantage of panel compared with individual peer review is that there is more knowledge available as all individuals’ knowledge is pooled together. During panel meetings, reviewers share their expertise and inform each other about their assessments. Generally, type of information can be classified in three different ways: shared versus unshared , preference consistent versus preference inconsistent , and instrumental versus non instrumental .

In terms of shared and unshared information, the general knowledge most reviewers have about applications can be considered to be shared information, whereas any additional knowledge someone has based on his specific expertise can be considered as unshared information. An experiment using the hidden profile task showed that groups in which all information is shared make better decisions than groups in which some group members have unique information ( Schulz-Hardt et al. 2006 ). As grant panelists vary on level of expertise with regard to applications they have to evaluate, there will always be both unique and shared information. In general, during group deliberations, more attention is paid to shared than to unshared information. Consequently, shared information has more impact on the final group decision ( Gigone and Hastie 1993 ; Winquist and Larson 1998 ; Tindale et al. 2001 ; Baron 2005 ). This tendency would inhibit the added value of experts, contributing their specific knowledge that other reviewers do not have to panel review processes. However, based on the study mentioned earlier of Bonner, Baumann, and Dalal (2002) , we argue that for unique information to be influential on panel decisions, the person bringing in this information should be recognized as being an expert.

Information distribution is also affected by initial opinions or preferences of panelists. In panels characterized by divergent opinions, more information is put into deliberation than panels in which there is high agreement to start with. Furthermore, heterogeneity in opinions stimulates group members to spend more time on (information steered) deliberation and results in better group decision outcomes ( Schulz-Hardt et al. 2006 ; Scholten et al. 2007 ). With regard to type of information that is put into discussion, we discern information that is consistent and inconsistent with one’s initial preferences. Mojzisch, Grouneva, and Schulz-Hardt (2010) found in their experiment on biased information evaluation that people paid more attention to preference-consistent information than to information that conflicted with their preferences. This effect was even stronger when confirming information was introduced by the person himself than by other group members. Whether people adjust their initial preference based on new information that is contributed to the discussion is strongly influenced by social validation . Affirmation of preference-inconsistent information by other group members raises the perceived quality of this information ( Mojzisch, Grouneva, and Schulz-Hardt 2008 ). The bias of favoring preference-consistent information can be explained as a tactic: people defend their initial preference and in order to convince others they mention more information that supports their preference ( Wittenbaum, Hollingshead, and Botero 2004 ). But it can also be the result of more unconscious processes: people consider preference-consistent information as more accurate and relevant and therefore pay more attention to it ( Mojzisch, Grouneva, and Schulz-Hardt 2010 ).

Finally, we discern instrumental and noninstrumental information. Information that is relevant for and ought to impact decisions is called instrumental, whereas irrelevant information that should not affect decisions is called noninstrumental. According to Bastardi and Shafir (2000) , people often give noninstrumental information instrumental value without being aware of this. To base their final selection decisions on thorough evaluations, review panels collect as much information as possible, both instrumental and noninstrumental. Next, newly obtained noninstrumental information is also used to make decisions, as ‘the very act of pursuing information may lead people to endow it with instrumental value’ (p.217). As the mere act of obtaining adds weight to new information, disregarding its relevance, information that is known from the start might receive less attention than new information ( Bastardi and Shaffir 1998 ). This implies that, for example, anecdotal information about applicants mentioned by panelists rather coincidently can influence review outcomes.
Motivation and interests of panelists

Panelists might differ in their motivation to engage in allocation processes. According to Merton’s norm of disinterestedness , reviewers should not have any personal, political, or economical interests interfering with their assessment of applications. Applications should be assessed purely on their academic merits. Nonetheless, several types of interests are conceivable to be held by panelists, like personal, departmental, university, disciplinary, gender etc. For example, reviewers might find it important to fund more research in his specific field or that more women get opportunities to build academic careers. Reviewers do not always have to be completely aware of these interests, as they can influence their preferences in a more subtle way. The stronger the individual preferences deviate from preferences of other panelists, the smaller its contribution to final panel preferences ( Tindale et al. 2001 ). How panelists interact with each other and the extent to which they exert themselves during review processes is influenced by their motivation. Next, we will discern various types of motivation: epistemic, social, and competitive motivation.

The extent to which reviewers search for missing information and process newly obtained information depend on their willingness to exert oneself to come to accurate and well-informed assessments of applications. This is called epistemic motivation . Interaction within groups characterized by high epistemic motivation is found to be more steered by information than by preferences and is less susceptible for reasoning errors. Furthermore, these groups are more open to deviating opinions and they develop more egalitarian and participatory interaction patterns ( De Dreu, Nijstad, and Van Knippenberg 2008 ). A way to increase the epistemic motivation is to make reviewers accountable for review processes ( De Dreu et al. 2007 ). We will come back to the role of accountability when describing procedural factors.

The type of information reviewers search for and process is found to be influenced by their social motivation ( De Dreu et al. 2006 ; De Dreu, Nijstad, and Van Knippenberg 2008 ).There are two types of social motivation: proself and prosocial. People with proself motivation have a strong focus on reaching personal goals and interests. On the other hand, people with prosocial motivation focus more on fairness and common goals. Considering the general task of review panels (assessing the quality of applications), panelists are not expected to be proself-motivated. Panels in which members do have personal interests and primarily strive for reaching personal goals are less likely to reach consensus than panels focusing on common goals. This can be the result of the exchange of information being distorted, as people with proself motivation tend to neglect other people’s opinions. Social motivation consequently can lead to biases in information processing ( De Dreu, Nijstad, and Van Knippenberg 2008 ). Kramer, Pommerenke, and Newton (1993) found that the extent to which one takes decisions based on self-interests or on the other party’s interests is also affected by the salience of a shared social identity. During a decision making task that involved negotiation, people were found to show greater concern with outcomes obtained by the other party and to have preferences for more equal outcomes, when a social identity was salient. When a distinctive personal identity instead of a social identity was salient, negotiators focused primarily on their own outcomes guided by self-interests.

The process of grant allocation involves a certain extent of negotiation, when panelists have strong preferences and try to convince each other of these. Looking at panel review processes as a type of negotiation, panelists can be ascribed competitive motivation ; assuming that an individual’s goal achievement is negatively related to goal achievements of others ( Ten Velden, Beersma, and De Dreu 2011 ). Two types of competitive motivation can be discerned: appetitive and aversive. People with appetitive motivation focus on outdoing their counterparts, acquiring better results. Aversive competitors try to prevent their counterparts from doing better than them; they aim at avoiding worse results than their competitors. In a series of experiments, Ten Velden, Beersma, and De Dreu (2011) compared negotiation behavior of appetitive and aversive competitors. Their study showed that individuals with appetitive motivation were more confident that agreements would satisfy their goals, and they more easily reached agreements. Furthermore, identical pieces of information were found to have different effects on negotiation, depending on motivational goals of negotiators. This shows that the same information can be used in different ways and that motivation influences the effect specific information has on negotiation processes.

We described earlier how social identity influences interaction and negotiation within groups: prototypical members are less competitive and more cooperative than peripherals ( Van Kleef et al. 2007 ). This suggests that panelists may use different strategies or social tactics in processes of decision making, e.g. consultation, pressure, personal appeals, and coalition tactics. The use of social tactics to influence one another is affected by status differences. It is less plausible to imagine low-status members pressuring high-status members by making demands or threatening them than vice versa. They will probably try to persuade high-status people by using factual information or flattery ( Yukl 1989 ; Levi 2007 ).

On a more unconscious level, group negotiation is liable to the use of cognitive heuristics . On one hand, these heuristics accelerate efficient decision making, and on the other hand, they can undermine the quality of its outcomes. Kahneman and Traversky (1973) identified three types of cognitive heuristics that enable people to understand their complex environment, availability, representativeness, and anchoring. Availability relates to the inclination to rely predominantly on information that is most salient in one’s memory. The representativeness heuristic refers to the tendency to judge something or someone based on its most evident features. Anchoring involves the strong reliance on randomly determined anchoring points. Often, opening statements serve as point of reference for all statements being made thereafter. With regard to panel review, this implies the comments of the first reviewer are very influential and set the tone for further discussion ( Van Arensbergen, Van der Weijden, and Van den Besselaar 2014 ). Knowledge of these cognitive heuristics can be implemented as social tactics when panelists actively use them to influence negotiation outcomes.

So far, we have described how outcomes of panel reviews are based on characteristics of the object (features of the applicant and application) and how panel review processes are affected by social characteristics of this type of group interaction (panel composition, group norms and cohesiveness, information distribution, and motivation). How these latter factors influence review outcomes is a major task of research within the field of SoS/SPS. Finally, we will focus on the organization of review processes. How do review procedures and external contextual factors influence review outcomes?
The organization of panel review: procedures and context

The organization of panel reviews involves various aspects. For example, selecting and installing panelists, determining specific panel tasks, developing review procedures and guidelines, and implementing some sort of control mechanism, e.g. by the presence of independent supervisors or by having to write detailed review reports. Then, there are contextual factors related to review processes like available budget and time pressure. With regard to panel composition, we showed earlier how it may affect evaluation processes. For example, composition is found to determine the representation of expertise, social identities, status, and interests among its members. These constellations can impact communication, behavior, and information sharing within groups, subsequently affecting panel results.

The general task of review panels as discussed in this article is to evaluate the quality of scientific work, of research proposals, or of scientists. The actual objects of review processes can therefore vary from hard copy research proposals and curriculum vitae to people in one’s own proper person. Review procedures are designed accordingly and panels are generally clearly instructed how to execute their task. The presence of clear decision making procedures decreases the risk of groupthink ( Esser 1998 ). However, procedural rules and guidelines generally do not fully steer review processes. Behavior of panelists can, for example, be more susceptible for (implicit and explicit) group norms ( Spector 1996 ). Langfeldt (2001) , who observed panel meetings of the Norwegian Research Council, furthermore found that although review protocols prescribed quality criteria to be used, the weight assigned to these criteria differed within and between panels. The kind of criteria eventually used by panelists depended strongly on budget restrictions and rating scales they had to use. For example, tight budgets and fine-rating scales tend to strengthen established research and allow less pluralism in funded research. At the same time, she found that reviewers who individually reviewed applications and send their reviews per mail, more consciously attempted to follow guidelines than panelists who discussed applications in panel meetings. This underlines the limited effect of guidelines in processes of social interaction.

With regard to funding decisions, often panels have to judge all applications, resulting in rank orders and subsequently in selections of the ‘best’. This final selection decision can be made by the panel themselves or by organizing parties like research councils. Consulting (in writing) external experts for every specific application can also be part of the procedure. The specific task assigned to panels is found to affect decision making processes ( Hollingshead 1996 ; Stewart and Stasser 1998 ; Langfeldt 2002 ). In an experiment, Hollingshead (1996) studied the effect of group decision making procedures on information sharing. She compared groups who were instructed to rank all alternatives to those who had to choose the best alternatives. Ranking groups were found to exchange more information and to consider all alternatives, eventually taking better decisions than selecting groups. However, the beliefs panelist have about the correctness of their decisions also play a role. When people believe there is only one correct answer (solve task) instead of no correct answer (judge task), they tend to produce more discussion ( Stewart and Stasser 1998 ). According to Langfeldt (2002) , also explicitness of review procedures influences decision making processes. She distinguishes between sounding and open confrontation as two ends of a continuum. Sounding involves tacit exploration of opinions, no explicit voting, and an emphasis on reaching consensus, whereas explicit voting without any preceding exploration of opinions is called open confrontation. The open confrontation method may be more efficient in terms of time needed for decision making, but at the same time may have rather negative consequences for group cohesiveness. With regard to explicit voting, it is good to realize that the timing and sequence of voting calls influences the preferences of panelists ( Davis et al. 1988 ).

Another aspect of review procedures is the degree of accountability of panels regarding their decisions. Accountability increases epistemic motivation of individuals, their need to search for information, the extent to which they repeat unshared information, and the quality of decision making ( De Dreu et al. 2007 ; Scholten et al. 2007 ). Therefore, it is an important factor influencing chances on groupthink ( Esser 1998 ). Groupthink is more likely to occur in groups where any degree of accountability is absent. Making individuals accountable is found to be more effective on reducing groupthink tendencies than making them collectively accountable as a panel ( Kroon, Hart, and Van Kreveld 1991 ).

A last important factor usually seen as complicating review processes is the available time. A thorough review of all applications generally requires a lot of time, which is often at the expense of valuable research time of panelists. The combination of the large scope of applications to be evaluated and the restricted time available reduces the ambitions of panelists to execute very rigorous reviews ( Langfeldt 2002 ; De Dreu et al. 2007 ). When panels experience strong time pressure, reviewers pay more attention to shared information and less attention to alternatives, consequently resulting in a closing of the mind . People tend to rely more on cognitive heuristics like the availability heuristic, as mentioned earlier, and are more focused on reaching (cognitive) closure ( De Dreu et al. 2007 ). Therefore, high time pressure is considered an important antecedent for groupthink ( Janis 1982 ).
Conclusions and implications

This article aims to contribute to a better understanding of panel review processes by combining literature from the fields of SoS and SPS with SP. Considering the complexity of review processes characterized by social interaction, innumerable factors can be identified influencing review processes and their outcomes. As it is impossible to include them all, we chose to focus on a limited number of factors we consider to be most illustrating based on several observations of panel meetings.

Figure 2 depicts a more detailed model of grant allocation processes, including the main social psychological factors discussed. Some of these factors—mainly related to applicants and proposals—are found to influence review outcomes too. Other factors—mainly related to panels and social interaction—need further research to determine their effect on outcomes of review processes. These factors (within the rectangle) contribute to the uncertainty with which review outcomes can be predicted outright using criteria related to scholarly quality. As shown, there are many non (directly)-quality-related criteria involved in review processes.
Figure 2.
More detailed model of grant allocation processes.
Open in new tab Download slide

More detailed model of grant allocation processes.
Figure 2.
More detailed model of grant allocation processes.
Open in new tab Download slide

More detailed model of grant allocation processes.

Despite the need for further research, we may be able to formulate recommendations on how to stimulate open and thorough panel discussions resulting in fair and good quality outcomes—based on general SP studies reviewed above.

    Compose panels in such a way that there is heterogeneity among panelists. A heterogeneous panel can be established, for example, by appointing men and women with different disciplinary and/or methodological backgrounds, with different specializations, from various institutions. This will decrease the risk for groupthink, a situation that needs to be avoided as it leads to flaws in decision making.

    At the same time, make sure there is some overlap in competences, as this is associated with better cooperation between panelists and allows for open discussion between experts. They should be able to understand each other’s language.

    Provide panelists with information on each other’s expertise, so they can value their information accordingly. To benefit from diverse panel composition, this diversity should be evident to all panelists.

    Create a situation that supports a sense of collegiality and a good atmosphere during panel meetings. This will contribute to the team spirit and good communication.

    Be aware that there should also be room for deviating opinions and open conflict between reviewers. Panelists with deviating opinions should get the opportunity to explain their opinions, facilitate discussion, and stimulate information sharing. An independent chair or moderator could take up this task. This person should not be involved in reviewing the content, but should watch over the review process and make sure all panelists get the chance to express their opinions, disregarding perceived differences in status or social identity—as these factors cannot be easily moderated in another way.

    Increase panelists’ accountability. For example, by requiring reports of panel meetings in which selection decisions regarding all applications are clearly explained. This may lead to a more thorough search for and sharing of information, and it prevents panels from wanting to reach decisions too easily and prematurely. Having to report on review processes also involves being more explicit on which criteria were used.

    Let the moderator take on the role of devil’s advocate to avoid reaching agreement too quickly without considering relevant alternatives. This will involve panelists in alternative ways of thinking and forces them to explicitly justify their decisions. Moderators should also take up the responsibility to point out the irrelevance of noninstrumental information, prevent that unique or preference-inconsistent information is neglected, or too much weight is assigned to relatively unimportant information known by everyone. This could decrease the risk of decisions being influenced by double standards, noninstrumental information, or personal interests.

    Provide panelists with sufficient time and resources to successfully do their job. Of course it is easier said than done, but time pressure should be reduced as much as possible, as this negatively impacts review processes.

    Reward panelists. Researchers should be rewarded for the time and effort they put in executing panel review activities. Many job, promotions, and grant decisions are mainly based on traditional criteria of scientific quality and do not sufficiently take into account the broader social and economic functions of scientific and scholarly research. Being a member of a panel review committee is an indicator of influence on science ( ACUMEN 2014 ) and should therefore be included in research evaluations.

Future research

Future research is necessary to test how factors related to social processes of group decision making as described above, affect outcomes of panel reviews. More specifically, the role of panel composition, motivation of panelists, criteria deployed, type of information being distributed and exchanged, and accountability need further investigation. 7

    As described in this review, several studies are available on the effects of specific group mechanisms on decision making. Further research (meta-analysis) is needed to estimate effect sizes of these various mechanisms to assess how important they may be. Effects may exist, but not necessarily strong enough to have a negative impact on the decision making.

    By means of social psychological experiments, more insight may be gained in the effects of accountability, motivation, and time pressure on the thoroughness of panel discussion and information sharing. An important difference with previous comparable experiments using the hidden profile task is that in the case of decision making in grant panels, no ‘right answer’ can be identified. Still, experiments can show, e.g. types of information that are emphasized or neglected, criteria that are decisive, or social strategies that are used.

    Also the impact of panel composition needs further attention. Various characteristics of the panel and its members could impact the decision making. One especially important issue is the question of cognitive distance. Do reviewers and panelists assess applicants differently depending on the level of similarity in terms discipline, research topic, research front, and methodological approach? This could be investigated by mapping the cognitive space of the panel and by situating the applicants in that space. Does the position of applicants in that cognitive space correlate with the scores they receive?

    An important question is what implicit and explicit criteria panelists deploy during the selection process—compared with formal criteria as specified in official selection procedures. Motivation and other characteristics of panelist play a role here. To uncover those criteria, and the way they are deployed, direct observations of panels are required, but are until now hardly ever carried out. When the aim is to really understand review processes, this can be considered a methodological problem because results are now mainly based on indirect reconstructions of review processes. Ethnographic observation is, therefore, desirable as it offers opportunities to investigate review and decision making processes where they happen.

    If one would know the criteria de facto deployed, one may try to answer two questions. Firstly, the normative question: which of these criteria should be used at all. But, secondly, one may also investigate whether the selections made are correct in terms of the qualifications of the applicants, by comparing those criteria with the applicants’ curricula vitae. Also, that is difficult because curricula vitae are often not available, and if they are, the analysis is very laborious.

    Observations are additionally needed to study two contexts. Firstly, the increasing numbers of applicants research councils in many countries are facing puts a huge pressure on the first phase of the process, where many applicants are rejected. Panels have only very little time per applicant to come to a decision, and under those conditions, social dynamics—in contrast to scholarly quality—may have very strong impact on the outcomes.

    The second issue where observations are important is when panels interview the applicants. Research shows that this interview may heavily impact the selection decision, but we do not know what exactly the basis behind this is.

    Competition for grants increases and success rates go down. It is important to study the effect of increased competition on the dynamics of decision making. Does it influence the way the panel works—in terms of internal competition and collaboration, dominance, and status differences?

    Finally, there is hardly any research on predictive validity of panel decisions: are the granted—especially early career—applicants indeed the best researchers if one would look back after 10 years?

Acknowledgements

We would like to thank the two anonymous referees for their comments on an earlier version of this article.
Notes
1. To give an impression of how strong the competition for individual career grants is: for the starting grants of the European Research Council, the success rate in 2013 was 9% ( http://erc.europa.eu/statistics ). For similar type of career grants in the Netherlands— Veni and Vidi grants—success rates in 2012 were 16 and 14%, respectively ( NWO 2012 ).
2. See Bornmann (2011) for a recent literature review on peer review.
3. One may use bibliometric methods to find those peers, by identifying other researchers in the same research front through e.g., bibliographic coupling.
4. Many studies included in their review did not use data on the performance of applicants—a general weakness of many studies of gender bias in grant decisions.
5. For example, the European Research Council (ERC) recently launched the projects ERCAREER (Capturing gendered career paths of ERC grantees and applicants) and GendERC (Gendered dimensions in ERC grant selection), and the European Committee granted EGERA (Effective Gender Equality in Research and the Academia) and GARCIA (Gendering the Academy and Research: combating Career Instability and Asymmetries).
6. This contains a group decision-making task in which the best solution cannot be detected by individual members based only on the information they received prior to discussion. There is a difference in the information individuals have at their disposal. Prior to the group discussion, partial information is given to all group members (shared information), whereas other pieces of information are known to some but unknown to other members (unshared information). Based on the available information, individuals will detect different ‘best’ solutions. To find the only real best solution, unshared information has to be pooled during the discussion.
7. Several of the issues mentioned will be explored within the GendERC project. The last author acknowledges the ERC for funding this project.
References
ACUMEN
‘Final Report’
, 
2014
 
(29 April 2014) < http://research-acumen.eu/ >
COPAC
 
Baron
R S
. 
‘So right it's wrong: Groupthink and the ubiquitous nature of polarized group decision-making’
, 
Advances in Experimental Social Psychology
, 
2005
, vol. 
37
 (pg. 
219
-
53
)
WorldCat
 
Bastardi
A
, 
Shafir
E
. 
‘On the pursuit and misuse of useless information’
, 
Journal of Personality and Social Psychology
, 
1998
, vol. 
75
 (pg. 
19
-
32
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Bastardi
A
, 
Shafir
E
. 
‘Nonconsequential reasoning and its consequences’
, 
Current Direcions in Psychological Science
, 
2000
, vol. 
9
 
6
(pg. 
216
-
19
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Bazeley
P
. 
‘Peer review and panel decisions in the assessment of Australian Research Council project grant applicant: What counts in a highly competitive context?’
, 
Higher Education
, 
1998
, vol. 
35
 (pg. 
435
-
52
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Beal
D J
, et al. 
‘Cohesion and performance in groups: A meta-analytic clarification of construct relations’
, 
Journal of Applied Psychology
, 
2003
, vol. 
88
 
6
(pg. 
989
-
1004
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Bonner
B L
, 
Baumann
M R
, 
Dalal
R S
. 
‘The effects of member expertise on group decision-making and performance’
, 
Organizational Behavior and Human Decision Processes
, 
2002
, vol. 
88
 (pg. 
719
-
36
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Bornmann
L
. 
‘Scientific peer review’
, 
Annual Review of Information Science and Technology
, 
2011
, vol. 
45
 
1
(pg. 
197
-
245
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Bornmann
L
, 
Daniel
H-D
. 
‘Selection of research fellowship recipients by committee peer review. Reliability, fairness and predictive validity of Board of Trustees' decisions’
, 
Scientometrics
, 
2005
, vol. 
63
 
2
(pg. 
297
-
320
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Bornmann
L
, 
Daniel
H-D
. 
‘Selecting scientific excellence through committee peer review’
, 
Scientometrics
, 
2006
, vol. 
68
 
3
(pg. 
427
-
40
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Bornmann
L
, 
Leydesdorff
L
, 
Van den Besselaar
P
. 
‘A Meta-evaluation of scientific research proposals: Different ways of comparing rejected to awarded applications’
, 
Journal of Informetrics
, 
2010
, vol. 
4
 (pg. 
211
-
20
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Bornmann
L
, 
Mutz
R
, 
Daniel
H-D
. 
‘Gender differences in grant peer review: A meta-analysis’
, 
Journal of Informetrics
, 
2007
, vol. 
1
 (pg. 
226
-
38
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Bornmann
L
, 
Wallon
G
, 
Ledin
A
. 
‘Does the committee peer review select the best applicants for funding? An investigation of the selection process for two European Molecular Biology Organization programmes’
, 
PLoS One
, 
2008
, vol. 
3
 
10
pg. 
e3480
 
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Brouns
M
. 
‘The gendered nature of assessment procedures in scientific research funding: The Dutch case’
, 
Higher Education in Europe
, 
2000
, vol. 
25
 
2
(pg. 
193
-
9
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Cañibano
C
, 
Otamendi
J
, 
Andújar
I
. 
‘An assessment of selection processes among candidates for public research grants: The case of the Ramón y Cajal Programme in Spain’
, 
Research Evaluation
, 
2009
, vol. 
18
 
2
(pg. 
153
-
61
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Ceci
S J
, 
Williams
W M
. 
‘Understanding current causes of women’s underrepresentation in science’
, 
Proceedings of the National Academy of Sciences of the USA
, 
2011
, vol. 
108
 
8
(pg. 
3157
-
62
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Cole
S
, 
Cole
J R
, 
Simon
G A
. 
‘Chance and consensus in peer review’
, 
Science
, 
1981
, vol. 
214
 (pg. 
881
-
6
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Davis
J H
, et al. 
‘Effects of straw polls on group decision making: Sequential voting pattern, timing, and local majorities’
, 
Journal of Personality and Social Psychology
, 
1988
, vol. 
55
 
6
(pg. 
918
-
26
)
Google Scholar
Crossref
Search ADS
WorldCat
 
De Dreu
C K W
, et al. 
Kruglanski
A W
, 
Higgins
E T
. 
‘The psychology of negotiation: Principles and basis processes’
, 
Handbook of Basic Principles in Social Psychology
, 
2007
2nd edn
New York, NY
Guilford
(pg. 
608
-
29
)
Google Preview
WorldCat
COPAC
 
De Dreu
C K W
, et al. 
‘Motivated information processing, strategic choice, and the quality of negotiated agreement’
, 
Journal of Personality and Social Psychology
, 
2006
, vol. 
90
 
6
(pg. 
927
-
43
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
De Dreu
C K W
, 
Nijstad
BA
, 
Van Knippenberg
D
. 
‘Motivated information processing in group judgement and decision making’
, 
Personality and Social Psychology Review
, 
2008
, vol. 
12
 (pg. 
22
-
49
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
De Jonge Akademie
, 
Rendement van Talent. Aanbevelingen Voor Motiverend en Stimulerend Loopbaanbeleid
, 
2010
Amsterdam
De Jonge Akademie
WorldCat
COPAC
 
Esser
J K
. 
‘Alive and well after 25 years: A review of groupthink research’
, 
Organizational Behavior and Human Decision Processes
, 
1998
, vol. 
73
 
2–3
(pg. 
116
-
41
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Foschi
M
. 
Brouns
M
, 
Addis
E
. 
‘Blocking the use of gender-based double standards for competence’
, 
Gender and Excellence in the Making
, 
2004
 
(EUR 21222 Report). Brussels: European Commission
Google Preview
WorldCat
COPAC
 
Gigone
D
, 
Hastie
R
. 
‘The common knowledge effect: Information sharing and group judgment’
, 
Journal of Personality and Social Psychology
, 
1993
, vol. 
65
 
5
(pg. 
959
-
74
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Hartmann
I
, 
Neidhardt
F
. 
‘Peer review at the Deutsche Forschungsgemeinschaft’
, 
Scientometrics
, 
1990
, vol. 
19
 
5–6
(pg. 
419
-
25
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Hodgson
C
. 
‘How reliable is peer review? An examination of operating grant proposals simultaneously submitted to two similar peer review systems’
, 
Journal of Clinical Epidemiology
, 
1997
, vol. 
50
 (pg. 
1189
-
95
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Hogg
M A
, 
Terry
D J
. 
‘Social identity and self-categorization processes in organizational contexts’
, 
The Academy of Management Review
, 
2000
, vol. 
25
 
1
(pg. 
121
-
40
)
WorldCat
 
Hollingshead
A B
. 
‘The rank-order effect in group decision making’
, 
Organizational Behavior and Human Decision Processes
, 
1996
, vol. 
68
 
3
(pg. 
181
-
93
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Hornborstel
S
, et al. 
‘Funding of young scientists and scientific excellence’
, 
Scientometrics
, 
2009
, vol. 
79
 
1
(pg. 
171
-
90
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Janis
I L
. 
, 
Groupthink. Psychological Studies of Policy Decisions and Fiascoes
, 
1982
2nd edn
Boston
Houghton Mifflin Company
Google Preview
WorldCat
COPAC
 
Jayasinghe
U W
, 
Marsh
H W
, 
Bond
N
. 
‘Peer review in the funding of research in higher education: The Australian experience’
, 
Educational Evaluation and Policy Analysis
, 
2001
, vol. 
23
 
4
(pg. 
343
-
64
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Kahneman
D
, 
Tversky
A
. 
‘On the psychology of prediction’
, 
Psychological Review
, 
1973
, vol. 
80
 (pg. 
237
-
51
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Kramer
R M
, 
Pommerenke
P
, 
Newton
E
. 
‘The social context of negotiation: Effects of social identity and interpersonal accountability on negotiator decision making’
, 
Journal of Conflict Resolution
, 
1993
, vol. 
37
 
4
(pg. 
633
-
54
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Kroon
M B R
, 
Hart
P
, 
Van Kreveld
D
. 
‘Managing group decision making processes: Individual versus collective accountability and groupthink’
, 
International Journal of Conflict Management
, 
1991
, vol. 
2
 
2
(pg. 
91
-
115
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Lamont
M
. 
, 
How Professors Think. Inside the Curious World of Academic Judgment
, 
2009
Cambridge, London
Harvard University Press
Google Preview
WorldCat
COPAC
 
Langfeldt
L
. 
‘The decision-making constraints and processes of grant peer review, and their effects on the review outcome’
, 
Social Studies of Science
, 
2001
, vol. 
31
 
6
(pg. 
820
-
41
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Langfeldt
L
. 
, 
Decision-making in Expert Panels Evaluating Research. Constraints, Processes and Bias
, 
2002
Oslo
Norwegian Institute for Studies in Innovation, Research and Education
Google Preview
WorldCat
COPAC
 
Laudel
G
. 
‘The ‘quality myth': Promoting and hindering conditions for acquiring research funds’
, 
Higher Education
, 
2006
, vol. 
52
 (pg. 
375
-
403
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Larivière
V
, et al. 
‘Global gender disparities in science’
, 
Nature
, 
2013
, vol. 
504
 (pg. 
211
-
13
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Levi
D
. 
, 
Group Dynamics for Teams
, 
2007
2nd edn
Los Angeles
Sage Publications
Google Preview
WorldCat
COPAC
 
Marques
J M
, et al. 
Hogg
M A
, 
Tindale
R S
. 
‘Social categorization, social identification, rejection of deviant group members’
, 
Blackwell Handbook of Social Psychology: Group Processes
, 
2001
, vol. 
Vol. 3
 
Oxford, UK
Blackwell Publishers
(pg. 
400
-
24
)
Google Preview
WorldCat
COPAC
 
Marsh
H W
, et al. 
‘Gender effects in the peer reviews of grant proposals: A comprehensive meta-analysis comparing traditional and multilevel approaches’
, 
Review of Educational Research
, 
2009
, vol. 
79
 
3
(pg. 
1290
-
326
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Marsh
H W
, 
Jayasinghe
U W
, 
Bond
N W
. 
‘Improving the peer-review process for grant applications. Reliability, validity, bias, and generalizability’
, 
American Psychologist
, 
2008
, vol. 
63
 
3
(pg. 
160
-
8
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Melin
G
, 
Danell
R
. 
‘The top eight percent: Development of approved and rejected applicants for a prestigious grant in Sweden’
, 
Science and Public Policy
, 
2006
, vol. 
33
 
10
(pg. 
702
-
12
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Merton
R K
. 
Merton
R K
. 
‘The normative structure of science’
, 
The Sociology of Science
, 
1973[1942]
Chicago
The University of Chicago Press
(pg. 
267
-
78
)
Google Preview
WorldCat
COPAC
 
Mojzisch
A
, 
Grouneva
L
, 
Schulz-Hardt
S
. 
‘Biased evaluation of information during discussion: Disentangling the effects of preference consistency, social validation, and ownership of information’
, 
European Journal of Social Psychology
, 
2010
, vol. 
40
 (pg. 
946
-
56
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Mojzisch
A
, et al. 
‘Social validation in group decision-making: Differential effects on the decisional impact of preference-consistent and preference-inconsistent information’
, 
Journal of Experimental Social Psychology
, 
2008
, vol. 
44
 (pg. 
1477
-
90
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Mutz
R
, 
Bornmann
L
, 
Daniel
H-D
. 
‘Does gender matter in grant peer review? An empirical investigation using the example of the Austrian Science Fund’
, 
Zeitschrift für Psychologie
, 
2012
, vol. 
220
 
2
(pg. 
121
-
9
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Neufeld
J
, 
Huber
N
, 
Wegner
A
. 
‘Peer review-based selection decisions in individual research funding, applicants publication strategies and performance: The case of the ERC Starting Grants’
, 
Research Evaluation
, 
2013
, vol. 
22
 
3
(pg. 
1
-
11
)
Google Scholar
Crossref
Search ADS
WorldCat
 
NWO
, 
NWO Jaarverslag 2012
, 
2012
Den Haag
NWO
WorldCat
COPAC
 
Olbrecht
M
, 
Bornmann
L
. 
‘Panel peer review of grant applications: What do we know from research in social psychology on judgment and decision-making in groups?’
, 
Research Evaluation
, 
2010
, vol. 
19
 
4
(pg. 
293
-
304
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Peterson
R S
, et al. 
‘Group dynamics in top management teams: Groupthink, vigilance, and alternative models of organizational failure and success’
, 
Organizational Behavior and Human Decision Processes
, 
1998
, vol. 
73
 
2–3
(pg. 
272
-
305
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Porter
A L
, 
Rossini
F A
. 
‘Peer review of interdisciplinary research proposals’
, 
Science, Technology & Human Values
, 
1985
, vol. 
10
 
3
(pg. 
33
-
8
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Ranga
M
, 
Gupta
N
, 
Etzkowitz
H
. 
, 
Gender Effects in Research Funding: A Review of the Scientific Discussion on the Gender-specific Aspects of the Evaluation of Funding Proposals and the Awarding of Funding
, 
2012
Bonn
Deutsche Forschungsgemeinschaft
Google Preview
WorldCat
COPAC
 
Rinia
E J
, et al. 
‘Influence of interdisciplinarity on peer-review and bibliometric evaluations in physics research’
, 
Research Policy
, 
2001
, vol. 
30
 (pg. 
357
-
61
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Sändstrom
U
, 
Hallsten
M
. 
‘Persistent nepotism in peer-review’
, 
Scientometrics
, 
2008
, vol. 
74
 
2
(pg. 
175
-
89
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Scholten
L
, et al. 
‘Motivated information processing and group decision-making: Effects of process accountability on information processing and decision quality’
, 
Journal of Experimental Social Psychology
, 
2007
, vol. 
43
 (pg. 
539
-
52
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Schulz-Hardt
S
, et al. 
‘Group decision making in hidden profile situations: Dissent as a facilitator for decision quality’
, 
Journal of Personality and Social Psychology
, 
2006
, vol. 
91
 
6
(pg. 
1080
-
93
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Spector
P E
. 
, 
Industrial and Organizational Psychology. Research and Practice
, 
1996
New York
John Wiley & Sons, Inc
Google Preview
WorldCat
COPAC
 
Stasser
G
, 
Stewart
D D
, 
Wittenbaum
G M
. 
‘Expert roles and information exchange during discussion: The importance of knowing who knows what’
, 
Journal of Experimental Social Psychology
, 
1995
, vol. 
31
 (pg. 
244
-
65
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Stephan
P
. 
, 
How Economics Shapes Science
, 
2012
Cambridge
Harvard University Press
Google Preview
WorldCat
COPAC
 
Stets
J E
, 
Burke
P J
. 
‘Identity theory and social identity theory’
, 
Social Psychology Quarterly
, 
2000
, vol. 
63
 
3
(pg. 
224
-
37
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Stewart
D D
, 
Stasser
G
. 
‘The sampling of critical, unshared information in decision-making groups: The role of an informed minority’
, 
European Journal of Social Psychology
, 
1998
, vol. 
28
 (pg. 
95
-
113
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Ten Velden
F S
, 
Beersma
B
, 
De Dreu
C K W
. 
‘When competition breeds equality: Effects of appetitive versus aversive competition in negotiation’
, 
Journal of Experimental Social Psychology
, 
2011
, vol. 
47/6
 (pg. 
1127
-
33
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Terry
D J
, 
Hogg
M A
. 
‘Group norms and the attitude-behavior relationships: A role for ingroup norms’
, 
Personality and Social Psychology Bulletin
, 
1996
, vol. 
22
 (pg. 
776
-
93
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Tindale
R S
, et al. 
Hogg
M A
, 
Tindale
R S
. 
‘Shared cognitions in small groups’
, 
Blackwell Handbook of Social Psychology: Group Processes
, 
2001
Oxford
Blackwell Publisers
(pg. 
1
-
30
)
Google Preview
WorldCat
COPAC
 
Travis
G D L
, 
Collins
H M
. 
‘New light on old boys: Cognitive and institutional particularism in the peer review system’
, 
Science, Technology and Human Values
, 
1991
, vol. 
16
 
3
(pg. 
322
-
41
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Van Arensbergen
P
, 
Hessels
L K
, 
van der Meulen
B
. 
, 
Talent Centraal. Ontwikkeling en Selectie van Wetenschappers in Nederland
, 
2013
Den Haag
Rathenau Instituut
Google Preview
WorldCat
COPAC
 
Van Arensbergen
P
, 
Van der Weijden
I
, 
Van den Besselaar
P
. 
‘Different views on scholarly talent: What are the talents we are looking for in science?’,
, 
Research Evaluation
, 
2014
, vol. 
23
 
4
(pg. 
273
-
84
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Van den Besselaar
P
. 
‘Grant committee membership: Service or self-service?’
, 
Journal of Informetrics
, 
2012
, vol. 
6
 (pg. 
580
-
5
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Van den Besselaar
P
. 
Hinze
S
, et al. 
‘More competition, better science - on the predictive validity of grant selection’
, 
Translational Twists and Turns: Science as a Socio-Economic Endeavor; Proceedings 18 th STI
, 
2013
Berlin
(pg. 
385
-
92
)
Google Preview
WorldCat
COPAC
 
Van den Besselaar
P
, 
Leydesdorff
L
. 
, 
Past Performance as Predictor of Successful Grant Applications
, 
2007
Den Haag
Rathenau Instituut
Google Preview
WorldCat
COPAC
 
Van den Besselaar
P
, 
Leydesdorff
L
. 
‘Past performance, peer review, and project selection: A case study in the social and behavioral sciences’
, 
Research Evaluation
, 
2009
, vol. 
18
 
4
(pg. 
273
-
88
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Van den Brink
M
. 
‘Behind the scenes of science. Gender practices in the recruitment and selection of professors in the Netherlands’
, 
2009
PhD thesis, Radboud Universiteit Nijmegen
COPAC
 
Van der Weijden
I
, 
Calero Medina
C
. 
, 
Gender effects on evaluation indicators
, 
2014
 
Leiden: CWTS ACUMEN Deliverable
Google Preview
WorldCat
COPAC
 
Van Kleef
G A
, et al. 
‘Group member prototypicality and intergroup negotiation: How one's standing in the group affects negotiation behaviour’
, 
British Journal of Social Psychology
, 
2007
, vol. 
46
 (pg. 
129
-
52
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Van Leeuwen
T N
, 
Moed
H F
. 
‘Funding decisions, peer review, and scientific excellence in physical sciences, chemistry and geosciences’
, 
Research Evaluation
, 
2012
, vol. 
21
 (pg. 
189
-
98
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Viner
N
, 
Powell
P
, 
Green
R
. 
‘Institutionalized biases in the award of research grants: A preliminary analysis revisiting the principle of accumulative advantage’
, 
Research Policy
, 
2004
, vol. 
33
 (pg. 
443
-
54
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Wennerås
C
, 
Wold
A
. 
‘Nepotism and sexism in peer-review’
, 
Nature
, 
1997
, vol. 
387
 (pg. 
341
-
3
)
Google Scholar
Crossref
Search ADS
PubMed
WorldCat
 
Winquist
J R
, 
Larson
J R
Jr.
. 
‘Information pooling: When it impacts group decision making’
, 
Journal of Personality and Social Psychology
, 
1998
, vol. 
74
 
2
(pg. 
371
-
7
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Wittenbaum
G M
, 
Hollingshead
A B
, 
Botero
I C
. 
‘From cooperative to motivated information sharing in groups: Moving beyond the hidden profile paradigm’
, 
Communication Monographs
, 
2004
, vol. 
71
 (pg. 
286
-
310
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Yukl
G
. 
‘Managerial leadership: A review of theory and research’
, 
Journal of Management
, 
1989
, vol. 
15
 
2
(pg. 
251
-
89
)
Google Scholar
Crossref
Search ADS
WorldCat
 
Zinovyeva
N
, 
Bagues
M
. 
‘Does gender matter for academic promotion? Evidence from a randomized natural experiment’
, 
Working papers
, 
2010
 
2010-15, FEDEA
Google Preview
WorldCat
COPAC
 
© The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com
Issue Section:
MAIN ARTICLES
Download all figures
325 Views
15 Citations
Article has an altmetric score of 3
View Metrics
×
Email alerts
Article activity alert
Advance article alerts
New issue alert
Receive exclusive offers and updates from Oxford Academic
Close
Related articles in

    Web of Science
    Google Scholar

Citing articles via
Web of Science (15)
Google Scholar
Crossref

    Latest
    Most Read
    Most Cited

Methods for mapping the impact of social sciences and humanities — A literature review
Should we fund research randomly? An epistemological criticism of the lottery model as an alternative to peer review for the funding of science
Normal versus extraordinary societal impact: how to understand, evaluate, and improve research activities in their relations to society?
Introducing and testing an advanced quantitative methodological approach for the evaluation of research centers: a case study on sustainability science

    About Research Evaluation
    Editorial Board
    Policies
    Author Guidelines
    Facebook

    Twitter
    Purchase
    Recommend to your Library
    Advertising and Corporate Services
    Journals Career Network

Research Evaluation

    Online ISSN 1471-5449
    Print ISSN 0958-2029
    Copyright © 2020 Oxford University Press

    About Us
    Contact Us
    Careers
    Help
    Access & Purchase
    Rights & Permissions
    Open Access

Connect

    Join Our Mailing List
    OUPblog
    Twitter
    Facebook
    YouTube
    Tumblr

Resources

    Authors
    Librarians
    Societies
    Sponsors & Advertisers
    Press & Media
    Agents

Explore

    Shop OUP Academic
    Oxford Dictionaries
    Oxford Index
    Epigeum
    OUP Worldwide
    University of Oxford

Oxford University Press is a department of the University of Oxford. It furthers the University's objective of excellence in research, scholarship, and education by publishing worldwide
Oxford University Press

    Copyright © 2020 Oxford University Press
    Cookie Policy
    Privacy Policy
    Legal Notice
    Site Map
    Accessibility
    Get Adobe Reader

Close
This Feature Is Available To Subscribers Only

Sign In or Create an Account
Close

This PDF is available to Subscribers Only
View Article Abstract & Purchase Options

For full access to this pdf, sign in to an existing account, or purchase an annual subscription.
Close
Scholarly IQ
