Screen reader users, click here to load entire article This page uses JavaScript to progressively load the article content as a user scrolls. Screen reader users, click the load entire article button to bypass dynamically loaded article content.
ScienceDirect will be phasing out support for Internet Explorer 7. Click here to upgrade to a higher version. Close
 

    Journals
    Books

    Sign in
    Sign in
    OpenAthens login
    Login via your institution
    Other institution login
    Sign in using your ScienceDirect credentials
    Username:
    Password:
    Remember me
    | Not Registered?
    Forgotten username or password?
    Help

    Download PDF
     
    Other export options
    Warning Icon
    You have selected 1 citation for export.
        Direct export
        About Mendeley      
        About RefWorks      
        Export file
          RIS (for EndNote, Reference Manager, ProCite)
          BibTeX
          Text
          RefWorks Direct Export
    More options...
            eReader format   What's this?
              ePub
              Mobipocket

Advanced search

 
Article outline
Show full outline

    Abstract
    Highlights
    Keywords
    1. Introduction
    2. Data and methodology
    3. Results for national university systems
    4. Results at the level of individual universities
    5. Discussion and conclusions
    References

Alert message
JavaScript is disabled on your browser.
Please enable JavaScript to use all the features on this page.
Figures and tables

    Table 1
    Table 2
    Table 3
    Table 4
    Table 5

JavaScript is disabled on your browser. Please enable JavaScript to use all the features on this page.

Journal of Informetrics

Volume 5, Issue 4 , October 2011, Pages 649–658
Cover image Cover image
Is concentration of university research associated with better research performance?

    Henk F. Moed a , Corresponding author contact information Corresponding author contact information , E-mail the corresponding author E-mail the corresponding author ,
    Félix de Moya-Anegón b , E-mail the corresponding author E-mail the corresponding author ,
    Carmen López-Illescas b , E-mail the corresponding author E-mail the corresponding author ,
    Martijn Visser c , E-mail the corresponding author E-mail the corresponding author

    a Elsevier, Radarweg 29, 1043 NX Amsterdam, The Netherlands
    b SCImago Unit, IPP, CCHS Institute, CSIC, Spanish National Research Council, Madrid, Spain
    c Centre for Science and Technology Studies (CWTS), Leiden University, the Netherlands

    Received 4 February 2011, Revised 15 May 2011, Accepted 14 June 2011, Available online 22 July 2011

Choose an option to locate/access this article:

    http://dx.doi.org/10.1016/j.joi.2011.06.003 
    Get rights and content 

Abstract

This paper analyses relationships between university research performance and concentration of university research. Using the number of publications and their citation impact extracted from Scopus as proxies of research activity and research performance, respectively, it examines at a national level for 40 major countries the distribution of published research articles among its universities, and at an institutional level for a global set of 1500 universities the distribution of papers among 16 main subject fields.

Both at a national and an institutional level it was found that a larger publication output is associated with a higher citation impact. If one conceives the number of publications as a measure of concentration, this outcome indicates that, in university research, concentration and performance are positively related, although the underlying causal relationships are complex. But a regression analysis found no evidence that more concentration of research among a country's universities or among an institution's main fields is associated with better overall performance.

The study reveals a tendency that the research in a particular subject field conducted in universities specializing in other fields outperforms the work in that field in institutions specializing in that field. This outcome may reflect that it is multi-disciplinary research that is the most promising and visible at the international research front, and that this type of research tends to develop better in universities specializing in a particular domain and expanding their capabilities in that domain towards other fields.
Highlights

► It analyzes in Scopus a global set of as many as 1500 universities, and uses citation impact as performance indicator. ► The research question is: Does more concentration lead to better research? In four separate analyses the study found no empirical evidence that this is the case ► In a group of 40 major countries found no significant linear or rank correlation between national research performance and the degree of concentration of research among their universities. Among top performing nations one finds both concentrated and more evenly distributed national academic systems in terms of research output. ► At the level of individual universities it was found that universities showing a high overall disciplinary specialization tend to have a lower citation impact than general academic institutions do, although the linear correlation is weak ► This result may reflect that it is multi-disciplinary research that is the most promising and visible at the international research front, and that this type of research tends to develops better in general institutions covering a broad range of main fields than it does in specialized ones.
Keywords

    University rankings ;
    Citation analysis ;
    Research performance ;
    Research concentration ;
    Disciplinary specialization ;
    National academic systems ;
    Scopus

1. Introduction

In many OECD countries ministers responsible for higher education institutions and scientific research established a research policy aimed at concentrating research in centers of excellence, or they started distributing parts of the research budget among research institutions on the basis of performance criteria ( OECD, 2010  and  Hicks, 2010 ). The latter policy is believed to be one of the key strategies to establish concentration among national research institutions, at least at a long run. What are the effects of concentration policies upon the overall research performance of a national research system and upon individual research institutions?

The optimal distribution of research funding and activity does not only relate at a national level to the question as to how to distribute funds among institutions , but also within an institution to distribute funds among the various subject fields . Research institutions, especially universities, differ as regards their disciplinary specialization; while some are general, others are specialized and focus on a few main fields only. The relationship between size, specialization and performance in scientific and technological activity is a key issue in policy debates. While some are in favor of establishing more integration and breadth, others underline the need for specialization, diversity and competition ( Von Tunzelmann, Ranga, Martin, & Geuna, 2003 ). A series of studies on the scientific and technological performance of research institutions, firms and countries analyzed these relationships. For a review the reader is referred to Brusoni and Geuna (2004) .

This paper focuses on one particular type of institutions: higher education institutions, also denoted as universities throughout this paper. University rankings have gained a strong interest both from managers, researchers and the general public (e.g., CEPES, 2006 , Liu and Cheng, 2005 , Liu and Cheng, 2008 , Salmi, 2009 , SJTU, 2007  and  Van Raan, 2005 ). Although such rankings are marketing tools rather than research management tools ( AUBR, 2010 ), underlying data constitute a rich source for secondary analyses of policy-relevant issues that help testing policy assumptions and interpreting rankings in a proper way (e.g., Calero-Medina et al., 2008  and  López-Illescas et al., 2011 ). From this perspective, in a quantitative-empirical, bibliometric approach, using citation impact as proxi of research performance and the number of published articles as an indicator of research activity, this paper analyses 40 major national university systems and 1500 universities, addressing the following four research questions:

1.

    Do countries in which research is concentrated in a relatively small number of universities perform better than countries do that show a more even distribution of research between their higher education institutions?
2.

    Do countries in which universities tend to show a large degree of overall disciplinary specialization perform better than nations do with more general universities covering a wide range of subject fields?
3.

    Do specialized universities perform better than general academic institutions do?
4.

    Do universities specializing in a particular subject field outperform in their field of specialization universities that are less specialized in that field?

The relation between ‘size’ and ‘performance’ is often analyzed in terms of critical mass, i.e., a minimum size of research input that is needed to create substantial scientific progress. Critical mass is to be assessed at the level of a research group or department rather than at the level of a university as a whole. If a university published, say, one hundred papers per year in a particular research subject, a key question is whether this output was created by one single research department carrying out a coherent research programme, or whether it was dispersed among a large number of small groups or individuals hardly interacting with each other. The data analyzed in this paper relate to a breakdown of a university's research output into 16 main subject fields; data at the level of research groups or departments were not available in the current study.

Concentration of research can be considered from two viewpoints: internal and external . The first compares the publication output of a university in a particular field to the same institution's output in other fields, and to its total output; the second compares it to the number of articles published by other institutions in the same subject field. A ‘big’ research university may show internally a low publication activity in a field compared to its output in other fields, but externally , compared to other institutions in the same field, be among the most productive ones. A similar distinction can be made in the analysis of national university systems: one can apply a internal, national viewpoint, comparing one university with other universities in the same country, or an external, international one, comparing it with all other institutions in the world. Therefore, when interpreted from an external viewpoint, the number of publications is also an indicator of concentration of research.

The structure of this paper is as follows. Section 2 gives a description of the data analyzed and methodologies applied. Results at the level of national university systems are presented in Section 3 , and those conducted at the level of individual universities in Section 4 . Finally, Section 5 discusses the outcomes and makes suggestions for further research.
Elsevier homepage (opens in a new window)

    About ScienceDirect

    Contact and support

    Information for advertisers

    Terms and conditions

    Privacy policy

Copyright © 2014 Elsevier B.V. except certain content provided by third parties. ScienceDirect® is a registered trademark of Elsevier B.V.
Cookies are used by this site. To decline or learn more, visit our Cookies page
  Recommended articles

        CWTS crown indicator measures citation impact of a research group's publication oeuvre
        2010, Journal of Informetrics
        more
            Henk F. Moed
            CWTS crown indicator measures citation impact of a research group's publication oeuvre
            Journal of Informetrics, Volume 4, Issue 3, July 2010, Pages 436–438
                PDF (97 K)
        Assessing the varying level of impact measurement accuracy as a function of the citation window length
        2011, Journal of Informetrics
        more
            Giovanni Abramo, Tindaro Cicero, Ciriaco Andrea D’Angelo
            Assessing the varying level of impact measurement accuracy as a function of the citation window length
            Journal of Informetrics, Volume 5, Issue 4, October 2011, Pages 659–667
            Original Research Article
                PDF (359 K)
        Bibliometric impact assessment with R and the CITAN package
        2011, Journal of Informetrics
        more
            Marek Gagolewski
            Bibliometric impact assessment with R and the CITAN package
            Journal of Informetrics, Volume 5, Issue 4, October 2011, Pages 678–692
            Original Research Article
                PDF (796 K)
    View more articles »

  Citing articles ( 4 )

    This article has not been cited.

  Related reference work articles

    No articles found.

 
Close
ScienceDirect article suggestions
ScienceDirect

    Recommended articles
    = Open Access/Open Archive

People who downloaded this article also downloaded these articles. Learn more
Do not show again
