Screen reader users, click here to load entire article This page uses JavaScript to progressively load the article content as a user scrolls. Screen reader users, click the load entire article button to bypass dynamically loaded article content.
ScienceDirect will be phasing out support for Internet Explorer 7. Click here to upgrade to a higher version. Close
 

    Journals
    Books

    Sign in
    Sign in
    OpenAthens login
    Login via your institution
    Other institution login
    Sign in using your ScienceDirect credentials
    Username:
    Password:
    Remember me
    | Not Registered?
    Forgotten username or password?
    Help

    Download PDF
     
    Other export options
    Warning Icon
    You have selected 1 citation for export.
        Direct export
        About Mendeley      
        About RefWorks      
        Export file
          RIS (for EndNote, Reference Manager, ProCite)
          BibTeX
          Text
          RefWorks Direct Export
    More options...
            eReader format   What's this?
              ePub
              Mobipocket

Advanced search

 
Article outline
Show full outline

    Abstract
    Keywords
    1. Introduction
    2. Data and methodology
    3. Analysis
    3.1. Method of counting—fractional versus whole
    3.2. International comparisons
    3.3. Relative citation impact unpacked
    3.4. Fields of research
    4. Discussion
    4.1. Effect of increased evaluation
    4.2. Sector comparisons
    4.3. Trends across indices
    4.4. Comparison of two universities
    5. Conclusion
    Acknowledgements
    References

Alert message
JavaScript is disabled on your browser.
Please enable JavaScript to use all the features on this page.
Figures and tables

JavaScript is disabled on your browser. Please enable JavaScript to use all the features on this page.

Research Policy

Volume 32, Issue 1 , January 2003, Pages 143–155
Cover image Cover image
Explaining Australia’s increased share of ISI publications—the effects of a funding formula based on publication counts

    Linda Butler E-mail the corresponding author E-mail the corresponding author

    Research Evaluation and Policy Project (REPP), Research School of Social Sciences, Australian National University, Canberra, ACT 0200, Australia

    Received 20 August 2001, Revised 7 November 2001, Accepted 15 January 2002, Available online 19 February 2002

Choose an option to locate/access this article:

    http://dx.doi.org/10.1016/S0048-7333(02)00007-0 
    Get rights and content 

Abstract

Australia’s share of publications in the Science Citation Index (SCI) has increased by 25% in the last decade. The worrying aspect associated with this trend is the significant decline in citation impact Australia is achieving relative to other countries. It has dropped from sixth position in a ranking of 11 OECD countries in 1988, to 10th position by 1993, and the distance from ninth place continues to widen.

The increased publication activity came at a time when publication output was expected to decline due to pressures facing the higher education sector, which accounts for over two-thirds of Australian publications. This paper examines possible methodological and contextual explanations of the trends in Australia’s presence in the SCI, and undertakes a detailed comparison of two universities that introduced diverse research management strategies in the late 1980s. The conclusion reached is that the driving force behind the Australian trends appears to lie with the increased culture of evaluation faced by the sector. Significant funds are distributed to universities, and within universities, on the basis of aggregate publication counts, with little attention paid to the impact or quality of that output. In consequence, journal publication productivity has increased significantly in the last decade, but its impact has declined.
Keywords

    Research funding ;
    Bibliometrics ;
    Effects of evaluation ;
    University research ;
    Productivity

1. Introduction

In 1993, the Research Evaluation and Policy Project (REPP) published a monograph, ‘ A Crisis for Australian Science ?’, which alerted the Australian research community to concerns about its scientific performance ( Bourke and Butler, 1993 ). This followed on from similar warnings issued by the American journal Science Watch ( ISI, 1993 ). Both publications showed a decline in the late 1980s of the impact of Australian scientific publications as measured by citations in the indices of the Institute for Scientific Information (ISI). There was general acceptance in the research community that Australian science was ‘in crisis’, and a number of questions raised in the monograph were taken up by the Australian Academy of Science, which commissioned a study in 1995 to test some of the hypotheses put forward ( Grigg, 1996 ).

The perception of a crisis persisted in the research community throughout the remainder of the 1990s. The university sector is the site of most basic research activity in Australia, currently accounting for three-quarters of all the nation’s publications. A recent government enquiry established in response to concerns within the sector, published its findings in a report titled ‘Universities in Crisis’ ( Australian Senate, 2001 ), and recommended that

    the Government end the funding crisis in higher education by adopting designated Commonwealth programs involving significant expansion in public investment in the higher education system over a 10 years period.

The enquiry noted that government outlays on higher education have declined from a peak of 1.50% in 1974–1975 to a level of only 0.89% in 1997–1998. In the last 5 years, universities have been required to seek private funding to make up the shortfall in public investment, but as government reports concede, in Australia this type of funding is “volatile, uncertain and hard to win” ( Gallagher, 2000 ). The pressure on university academics can also be seen in the deterioration of student-staff ratios which have risen from 12.81 in 1990 to 17.81 in 1999 ( Considine et al., 2001 ).

It was in this context that the earlier analysis was updated to include an additional 7 years data. Given the perception of a continuing crisis in the research sector in general, and in universities in particular, it was expected that the trends apparent in 1993 would have persisted.
2. Data and methodology

Two databases have been accessed to undertake the analyses presented in this paper. The principal source used is the REPP database, which is updated annually and contains all Australian publications indexed in ISI’s three main indices: the Science Citation Index (SCI), the Social Sciences Citation Index (SSCI), and the Arts and Humanities Citation Index (A&HCI). Data from ISI’s National Science Indicators (NSI) database have also been used. It provides the international context against which to judge Australia’s recent performance in the journal literature. It differs from the REPP database in that its journal coverage is more extensive.

The analysis covers four types of publications—articles, notes, reviews and proceedings papers. These publication types account for 78% of all Australian entries in ISI indices and, most importantly, attract 97% of all Australian citations. Counts are based on tape year (the year in which the publication was indexed by ISI) rather than publication year.

The analysis is primarily based on whole publication counts, i.e. each country collaborating on a publication is given a count of one for that publication. In ‘ A Crisis for Australian Science ?’, publications were fractionated: where authors from two countries were listed on a publication, each was allocated a count of 0.5; where three were listed, each was allocated 0.33 of a publication; and so on. The affects of this on publication and citation shares and trends are discussed later in this paper.

Publications are classified to a field of research on the basis of the journal which carries the publication. ISI has its own descriptive classification system involving approximately 200 subject categories and REPP has, for a number of previous exercises, translated these as closely as possible into the fields and sub-fields of the Australian Standard Research Classification (ASRC) ( ABS, 1998 ). The ASRC is a classification scheme prepared by the Australian Bureau of Statistics (ABS) for use in the measurement and analysis of research and experimental development undertaken in Australia.

The bibliometric measures used in this paper are as follows.

•

    Shares of world publication and citation totals : the number of publications and citations assigned to Australia as a percentage of the world total (i.e. the total in the ISI database).
•

    Relative citation impact ( RCI ): the comparison of publication and citation shares, calculated by dividing Australia’s share of world citations by its share of world publications.
•

    Relative journal impact : a comparison of the average citation rates for the journals Australia is publishing in with the average citation rate for all journals.

3. Analysis

The trends in Australia’s publication and citation shares of ISI’s SCI over an 18 years period are shown in Fig. 1 .

Full-size image (8 K) Full-size image (8 K)
    Fig. 1. 

    Australia’s share of publications and citations, and RCI in the SCI, 1981–1998.
    Figure options

        Download full-size image
        Download as PowerPoint slide

The coverage of the previous analysis extended only to 1991. Fig. 1 depicts unexpected and significant changes in the trends over the last decade. Australia’s share of publications has risen markedly since its low-point in 1988, from 2.18 to 2.72%, an increase of 25%. The trend in Australia’s share of citations also showed a turn-around, with an increase of 33% between 1990 and 1998. But though Australia’s share of total citations has kept pace with the increasing publication share, it has not yet regained the ground lost in the late 1980s.

At a superficial level, the result could be summarised as ‘crisis averted’. Australia’s share of world publications has increased considerably, and while the RCI has not regained the level of the early 1980s, it has stabilised at close to unity during the 1990s. However, this result is somewhat at odds with the general acceptance that Australian science was ‘in crisis’ when the original monograph was produced. And as has been illustrated in the introduction to this paper, the pressures on the main sector involved in basic research, the higher education sector, have increased rather than diminished.

Because the trends are counter-intuitive, it is essential to delve more deeply into the data. It will be demonstrated that these trends do not result from any decision made on the methodology used in the analysis. Some aspects of the data will then be examined in more detail to search for clues to explain the dynamics at work in the Australian research system.
3.1. Method of counting—fractional versus whole

There has been much discussion on the way in which internationally-collaborative publications should be treated when calculating national shares of world publication output ( Martin, 1994 ). Should all publications listing at least one author from a country be counted in full for that country (whole counting); or should each country be allocated a share of the publication (fractional counting)?

In 1981, only 11.4% of Australia’s publications involved international collaboration, but by 1999 the level had reached 34.9% and is still rising. Given the level and rise in this proportion, it is possible that the choice of method for counting such publications might affect the interpretation of a nation’s contribution to the world scientific output. Fig. 2 compares the use of fractional and whole counting of Australian publications.

Full-size image (9 K) Full-size image (9 K)
    Fig. 2. 

    Australia’s share of publications and citations in the SCI, fractional and whole counting, 1981–1998.
    Figure options

        Download full-size image
        Download as PowerPoint slide

Using fractional counting almost invariably results in a lower share of publications and an even lower share of citations for a country as only a proportion of internationally-collaborative publications is counted. This is due to the well-established fact that such publications are, on average, more highly cited than those involving authors from a single country ( Hicks and Katz, 1996  and  van Raan, 1997 ). Australian data for the period 1995–1999 can be used to illustrate the effects of fractional counting. In that period, Australia produced a total of 79,232 publications; 53,343 involved only Australian authors and this group had an average citation per publication rate (cpp) of 4.22. There were also 25,889 internationally co-authored publications featuring Australian researchers, with an average cpp of 5.53. In this scenario, where the cpp rate for these publications is significantly higher than the cpp rate for single country publications, the fractionation of counts relating to internationally co-authored publications will inevitably have a more marked effect on citations than on publications. In the case illustrated, fractionation leads to a 17.8% reduction in publication numbers, but a 24.5% reduction in the citation total.

The use of whole counting rather than fractionation does at first sight appear to affect the perception of Australia’s scientific performance. Both methods of counting show parallel trends in publication output, with a marked increase in the 1990s. With whole counting, the increase is 25%, compared to 13% if fractional counting is used. However, using whole counting, Australia’s citation performance seems somewhat rosier, though appearances can be deceptive as the following analysis will demonstrate.
3.2. International comparisons

To have a clearer understanding of its performance, Australia’s trends in publication and citation performance need to be placed in a global context. This enables us to judge the relative effect of world-wide trends on national data.

Fig. 3 compares Australia’s trend in publication shares to 10 other OECD countries. For pragmatic reasons, the USA has not been included in these figures due to its size. In addition, Fig. 3 employs a technique charting time series trends using two different y -axes. This allows for an easier comparison of trends between countries with markedly different publication counts.

Full-size image (43 K) Full-size image (43 K)
    Fig. 3. 

    National shares of ISI publications, selected OECD countries, 1981–2000 (source: NSI database).
    Figure options

        Download full-size image
        Download as PowerPoint slide

Australia’s publication trend (a steady share of the worlds output in the 1980s, followed by a rapid increase in share in the 1990s) can be found in a number of other OECD countries, though for most the size of the recent increase is not as large: UK, Germany, Sweden, Switzerland, France and Belgium. Other countries have been showing a steady increase in ISI-indexed publication output right across the two decades covered by the analyses—The Netherlands, Italy and Japan. The share attributed to Canada is lower in 2000 than it was in 1981, with the decline most apparent in the 1990s. 1

As already noted, internationally co-authored publications are more highly cited than those with no collaboration, or where joint authorship is contained within national boundaries. Where the proportion of a country’s publications involving international collaboration increases significantly, this will result, all other things being equal, in their share of citations increasing relative to their publication share. The result is an improved RCI rate. Hence, it is possible, with the widespread phenomenon of increasing internationalisation, for most major nations to exhibit improving RCIs. Fig. 4 analyses trends in RCI over the last two decades for the countries studied in Fig. 3 .

Full-size image (40 K) Full-size image (40 K)
    Fig. 4. 

    National trends in RCI, selected OECD countries, 1981–1999 (source: NSI database).
    Figure options

        Download full-size image
        Download as PowerPoint slide

Of the six countries that, in addition to Australia, exhibit increasing publication shares, only Sweden shares its declining RCI (though in Sweden’s case, the actual level remains high). For the other five countries, increasing publication shares have been accompanied by an improved RCI. As already explained, with increasing international collaboration, this result is plausible. Australia is the one country that goes against this trend. From being ranked sixth on this measure in 1988, Australia had dropped to 10th position by 1993, and the distance from ninth place has continued to widen.

Herein lies the most worrying aspect of the current analysis—Australia’s share of publication output is increasing, at a greater rate than for many comparable countries, but its share of the world’s citation pool increasingly lags behind. The internationalisation of research should have led to an increase in RCI, but this has not eventuated. Australia’s increase in output appears to be at the expense of impact.
3.3. Relative citation impact unpacked

There are two quite distinct components of citation analysis that can effect a country’s relative performance, and it is important to determine which is having the most effect on the Australian trend. Fig. 4 showed that the impact of Australia’s publications is losing ground relative to other OECD countries. This could be due to either: (i) Australians publishing in lower impact journals; or (ii) Australian publications not attracting as many citations as expected for the journals in which they appear; or (iii) a combination of (i) and (ii). Fig. 5 examines this issue.

Full-size image (7 K) Full-size image (7 K)
    Fig. 5. 

    Aspects of Australia’s citation performance, Science Citation Index, 1981–1999.
    Figure options

        Download full-size image
        Download as PowerPoint slide

Comparing the actual citations received by Australia’s publications to the level expected for the journals in which these appear (actual/expected citation rate), suggests little movement in this indicator. There is a degree of yearly volatility, but the rate has fluctuated around one for the whole period, with levels in the late 1990s similar to those in the early 1980s.

In contrast, the average citation rate of journals carrying Australian publications fell below the aggregate world average in 1990 and has remained below since. Even though other analysis has shown that Australia’s publications were attracting at or above the expected citation rate for its journals, Australia’s relative citation performance continued to slide because the journals which carried its articles were of lower impact ( Butler, 2001 ). This finding is central to the discussion on the effects of increased evaluation of university research performance which is addressed later in this paper.
3.4. Fields of research

While Australia’s relative decline in citation impact is apparent in the aggregate data, it is worth examining whether that trend is also uniform across all fields of science, or whether the overall trend is principally driven by the large biomedical fields. Fig. 6 disaggregates RCI trend data to the field level.
Elsevier homepage (opens in a new window)

    About ScienceDirect

    Contact and support

    Information for advertisers

    Terms and conditions

    Privacy policy

Copyright © 2014 Elsevier B.V. except certain content provided by third parties. ScienceDirect® is a registered trademark of Elsevier B.V.
Cookies are used by this site. To decline or learn more, visit our Cookies page
  Recommended articles

        The effect of government contracting on academic research: Does the source of funding affect scientific output?
        2008, Research Policy
        more
            Brent Goldfarb
            The effect of government contracting on academic research: Does the source of funding affect scientific output?
            Research Policy, Volume 37, Issue 1, February 2008, Pages 41–58
            Original Research Article
                PDF (359 K)
        Allocative efficiency in public research funding: Can bibliometrics help?
        2009, Research Policy
        more
            Giovanni Abramo, Ciriaco Andrea D’Angelo, Alessandro Caprasecca
            Allocative efficiency in public research funding: Can bibliometrics help?
            Research Policy, Volume 38, Issue 1, February 2009, Pages 206–215
            Original Research Article
                PDF (202 K)
        University research funding and publication performance—An international comparison
        2010, Research Policy
        more
            Otto Auranen, Mika Nieminen
            University research funding and publication performance—An international comparison
            Research Policy, Volume 39, Issue 6, July 2010, Pages 822–834
            Original Research Article
                PDF (797 K)
    View more articles »

  Citing articles ( 84 )

    This article has not been cited.

  Related reference work articles

    No articles found.

 
Close
ScienceDirect article suggestions
ScienceDirect

    Recommended articles
    = Open Access/Open Archive

People who downloaded this article also downloaded these articles. Learn more
Do not show again
