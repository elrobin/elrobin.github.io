    Email this article to a friend
        Alert me when this article is cited
        Alert me if a correction is posted
        Alert me when responses are published
        Download to citation manager
        PubMed citation
            Add to Facebook Facebook
            Add to LinkedIn LinkedIn
            Add to Twitter Twitter

        What's this?

    SfN.org
    The Journal of Neuroscience
    NeurOnLine
    BrainFacts.org

    Log in
    Subscribe
    Help

Search The Journal
Advanced Search
The Journal of Neuroscience Society for Neuroscience

Skip to main page content

    Home
    Current Issue
    All Issues
    Letters to the Editor
    Email Alerts
    Author Instructions
    About The Journal

Advertisement
The Journal of Neuroscience www.jneurosci.org

    The Journal of Neuroscience, 5 November 2008, 28 (45): 11433-11434; doi: 10.1523/JNEUROSCI.0003-08.2008

« Previous Table of Contents Next Article »

    Commentary

The Eigenfactor™ Metrics

    Carl T. Bergstrom ,
    Jevin D. West , and
    Marc A. Wiseman

+ Show Affiliations

    Department of Biology, University of Washington, Seattle, Washington 98115

    Correspondence should be addressed to Carl T. Bergstrom, Box 351800, Kincaid 448, Department of Biology, University of Washington, Seattle, WA 98115. cbergst@u.washington.edu

    The Journal of Neuroscience, 5 November 2008, 28 (45): 11433-11434; doi: 10.1523/JNEUROSCI.0003-08.2008

    » Full Text
    Full Text (PDF)

 
Next Section
Introduction

Quantitative metrics are poor choices for assessing the research output of an individual scholar. Summing impact factors, counting citations, tallying an h-index, or looking at Eigenfactor™ Scores (described below)—none of these methods are adequate compared with what should be the gold standard: reading the scholar's publications and talking to experts about her work. But many scholars, librarians, historians of science, editors, and other individuals are also interested in larger-scale questions that require assessing hundreds or thousands of scholarly articles by hundreds or thousands of authors. “Given that my library can afford only one more subscription, should I subscribe to journal x or journal y?” “How often do physicists cite Biology journals, and do biologists pay equal attention to the physics literature?” “Has the increase in size of my journal caused a corresponding decline in average quality?” To answer questions such as these, aggregate bibliometric statistics can be very useful.

For decades, citation counts and impact factor scores have been the primary currency for this sort of assessment. While these measures have the virtue of simplicity, they discard much of the useful information that is present in the full citation network. For example, citation counts and impact factors do not account for where citations come from: by these measures, citations from prestigious journals are worth no more than citations from lower-tier publications, and no attempt is made to adjust for differences in “citation culture” between journals and across fields. We have developed the Eigenfactor Metrics to address these concerns and to provide a more sophisticated way of looking at citation data. The idea behind these metrics is that we can use computational power to extract the wealth of information inherent in the structure of citation networks. The Eigenfactor algorithm (de-scribed in detail at http://www.eigenfactor.org/methods.htm ) is related to a class of network statistics known as eigenvector centrality measures. The approach is similar to that which Google uses to return search results. When ranking web pages, Google's PageRank algorithm takes into account not only how many hyperlinks a web page receives, but also from where those hyperlinks come. Our Eigenfactor algorithm does something similar, but instead of ranking websites, we rank journals, and instead of using hyperlinks, we use citations ( Bergstrom, 2007 ).

One can view the Eigenfactor Score as the result of a random walk through the scientific literature. The algorithm corresponds to a basic model of research in which readers follow chains of citations as they move from journal to journal. Imagine that a researcher goes to the library and selects a journal article at random from a journal published in 2006. After reading the article, the researcher selects at random one of the citations from the article. She then proceeds to the journal that was cited, selects a random 2006 article from that journal and, as before, selects a citation to direct her to her next journal volume. The researcher does this ad infinitum. Because of the structure of the citation network, our model researcher will frequently visit large, important journals such as Nature or Proceedings of the National Academy of Sciences of the United States of America , and will seldom visit small journals in the lowest tiers of the publishing hierarchy. The frequency with which our model researcher visits each journal gives us a measure of that journal's importance within network of academic citations—and this frequency, expressed as a percentage, is essentially the Eigenfactor Score of the journal. In practice, we do not need to simulate this random walk to estimate the frequencies with which our model researcher visits each journal. Instead, we can compute the expected visitation frequencies directly from a matrix that records how often each journal cites each other journal.

We have applied the Eigenfactor algorithm to bibliometric data sets from several sources. At http://www.eigenfactor.org , we display the results of the Eigenfactor algorithm as applied to journal citation data from the Thomson Reuters Journal Citation Reports ® (JCR). To each of the >7000 journals listed within the JCR, we compute two principal scores. The Eigenfactor Score is a measure of the journal's total importance to the scientific community; if a journal doubles in size while the quality of its articles remains constant, we would expect its Eigenfactor score to double. The Article Influence™ Score is a measure of the average influence, per article, of the papers in a journal and, as such, is comparable to the impact factor. Article Influence Scores are normalized so that the mean article in the JCR database has an Article Influence Score of 1.00. Thus, if a journal has an Article Influence Score of 3.0, its articles are on average three times as influential as the average article in the JCR database. In the future, we will also be making available a set of Eigenfactor Metrics calculated for other citation data from other commercial and noncommercial sources.
Figure 1.
View larger version:

    In this page
    In a new window

    Download as PowerPoint Slide

Figure 1.

Article Influence Scores and total articles published for the top 25 journals by Eigenfactor score in the field of Neurosciences. Several prominent journals, including The Journal of Neuroscience , are labeled. The volume of each circle reflects the Eigenfactor score of the corresponding journal. A dynamic version of this graph, online as an animated movie at http://www.eigenfactor.org/bubble/neuro/ , shows the change in rankings and size over the years 1997–2006, allows users to highlight individual journals, and allows users explore other statistics along the x and y axes.

Journal ranking is one of many uses for citation data. In addition to working with the Eigenfactor metrics, we are using citation data to explore the structure of science and the way that this structure is changing. We have developed ways of mapping the terrain of scholarship; these maps are available at http://www.eigenfactor.org as well. Ultimately, a better understanding of the scholarly landscape may be useful not only for those who study the structure of science, but also for practicing scientists as they navigate through ever-increasing volumes of literature.
Previous Section Next Section
Footnotes

        Accepted October 10, 2008.

    Editor's Note: The misuse of journal impact factor in hiring and promotion decisions is a growing concern. This article is one in a series of invited commentaries in which authors discuss this problem and consider alternative measures of an individual's impact.
    Correspondence should be addressed to Carl T. Bergstrom, Box 351800, Kincaid 448, Department of Biology, University of Washington, Seattle, WA 98115. cbergst@u.washington.edu

    Copyright © 2008 Society for Neuroscience 0270-6474/08/2811433-02$15.00/0

Previous Section
 
References

    ↵
        Bergstrom C
    ( 2007 ) Eigenfactor: measuring the value and prestige of scholarly journals . C&RL News 68 : 314 – 316 .
    Search Google Scholar

    Add to Facebook Facebook
    Add to LinkedIn LinkedIn
    Add to Twitter Twitter

What's this?
Articles citing this article

    A critical review of SCImago Journal & Country Rank Research Evaluation , 14 March 2014, 0 ( 2014 ): rvu008v1 - rvu008
        Abstract
        Full Text
        Full Text (PDF)
    The impact factor of a journal is a poor measure of the clinical relevance of its papers The Bone & Joint Journal , 1 March 2014, 96-B ( 3 ): 414 - 419
        Abstract
        Full Text
        Full Text (PDF)
    Modeling the dissemination and uptake of clinical trials results Research Evaluation , 1 September 2013, 22 ( 3 ): 179 - 186
        Abstract
        Full Text
        Full Text (PDF)
    A Bibliometric Analysis of Radiologic Technology (1963-2011) Radiologic Technology , 1 March 2013, 84 ( 4 ): 421 - 428
        Full Text
        Full Text (PDF)
    The Eigenfactor&trade; Score in Highly Specific Medical Fields: The Dental Model Journal of Dental Research , 1 April 2012, 91 ( 4 ): 329 - 333
        Abstract
        Full Text (PDF)
    Can Scientific Quality Be Quantified? Circulation , 8 March 2011, 123 ( 9 ): 947 - 950
        Full Text
        Full Text (PDF)
    A CitationRank algorithm inheriting Google technology designed to highlight genes responsible for serious adverse drug reaction Bioinformatics , 1 September 2009, 25 ( 17 ): 2244 - 2250
        Abstract
        Full Text
        Full Text (PDF)

Navigate This Article

    Top
    Footnotes
    References

Cited By

    MAR 2014 A critical review of SCImago Journal & Country Rank Research Evaluation
    FEB 2014 The impact factor of a journal is a poor measure of the clinical relevance of its papers The Bone & Joint Journal
    JUN 2013 Modeling the dissemination and uptake of clinical trials results Research Evaluation

View citing article information
Cited By

    MAR 2014 A critical review of SCImago Journal & Country Rank Research Evaluation
    FEB 2014 The impact factor of a journal is a poor measure of the clinical relevance of its papers The Bone & Joint Journal
    JUN 2013 Modeling the dissemination and uptake of clinical trials results Research Evaluation

View citing article information

    View citing article information
    Citing articles via Google Scholar

    No NCBI links

Responses to This Article
Be the first to respond to this article
Submit a Response
View Similar Articles
Similar articles in this journal »

    Similar articles in PubMed
    Search for related content

Advertisement
The Journal of Neuroscience

    NeurOnLine
    Facebook
    Twitter
    LinkedIn
    YouTube
    RSS

    Print ISSN: 0270-6474
    Online ISSN: 1529-2401

Society for Neuroscience

Copyright © 2014 by the Society for Neuroscience. The Journal of Neuroscience is distributed with the assistance of Stanford University's HighWire Press®

    Archive of all Online Issues
    Cover Image Archive
    Cover Video Archive

    About The Journal of Neuroscience
    Contact Us
    Subscription Services
    Advertising Rates
    For the Media
    Permissions
    Most Read Articles
    Most Cited Articles
    Collections

    More articles by Carl T. Bergstrom
    Carl T. Bergstrom on Google Scholar
    Carl T. Bergstrom on PubMed

    More articles by Jevin D. West
    Jevin D. West on Google Scholar
    Jevin D. West on PubMed

    More articles by Marc A. Wiseman
    Marc A. Wiseman on Google Scholar
    Marc A. Wiseman on PubMed

