Skip to Main Content
Wiley Online Library
Log in / Register
Log In
E-Mail Address
Password

Forgotten Password?
Remember Me

    Register
    Institutional Login

Advertisement

    Home >
    Computer Science >
    General & Introductory Computer Science >
    Journal of the American Society for Information Science and Technology >
    Vol 59 Issue 9 >
    Abstract

JOURNAL TOOLS

    Get New Content Alerts
    Get RSS feed
    Save to My Profile

JOURNAL MENU

    Journal Home

FIND ISSUES

    All Issues
    Virtual Issues

FIND ARTICLES

    Early View
    Most Accessed
    Most Cited

GET ACCESS

    Subscribe / Renew

FOR CONTRIBUTORS

    OnlineOpen
    Author Guidelines
    Submit an Article

ABOUT THIS JOURNAL

    Overview
    Editorial Board
    Permissions
    Advertise
    Contact

SPECIAL FEATURES

    ASIS&T Digital Library
    Articles in the Advances in Information Science
    Wiley Job Network
    Bulletin of the American Society for Information Science and Technology
    Proceedings of the American Society for Information Science and Technology
    Annual Review of Information Science and Technology
    Virtual Issue on Knowledge Management
    Virtual Issue on Bibliometrics
    Jobs

Advertisement Advertisement

Research Article
You have full text access to this content
Local citation analysis, publishing and reading patterns: Using multiple methods to evaluate faculty use of an academic library's research collection

    Concepción S. Wilson 1,* ,
    Carol Tenopir 2

Article first published online: 28 APR 2008

DOI: 10.1002/asi.20812

© 2008 ASIS&T

Issue
Journal of the American Society for Information Science and Technology
Journal of the American Society for Information Science and Technology

Volume 59 , Issue 9 , pages 1393–1408 , July 2008

Additional Information (Show All)

How to Cite Author Information Publication History
How to Cite

Wilson, C. S. and Tenopir, C. (2008), Local citation analysis, publishing and reading patterns: Using multiple methods to evaluate faculty use of an academic library's research collection. J. Am. Soc. Inf. Sci., 59: 1393–1408. doi: 10.1002/asi.20812
Author Information

    1

    School of Information Systems, Technology and Management, University of New South Wales, Sydney, New South Wales 2052, Australia
    2

    School of Information Sciences, University of Tennessee, Knoxville, TN 37996-0341, USA

Email: Concepción S. Wilson (c.wilson@unsw.edu.au), Carol Tenopir (ctenopir@utk.edu)

* School of Information Systems, Technology and Management, University of New South Wales, Sydney, New South Wales 2052, Australia
Publication History

    Issue published online: 9 JUN 2008
    Article first published online: 28 APR 2008
    Manuscript Accepted: 9 NOV 2007
    Manuscript Revised: 23 SEP 2007
    Manuscript Received: 13 MAY 2007

SEARCH
Search Scope
Search String

    Advanced >
    Saved Searches >

SEARCH BY CITATION
Volume:
Issue:
Page:
ARTICLE TOOLS

    Get PDF (598K)
    Save to My Profile
    E-mail Link to this Article
    Export Citation for this Article
    Get Citation Alerts
    Request Permissions

More Sharing Services Share | Share on citeulike Share on connotea Share on delicious Share on www.mendeley.com Share on twitter

    Abstract
    Article
    References
    Cited By

Get PDF (598K)
Abstract

    Top of page
    Abstract
    Introduction
    Methodology
    Results and Discussion
    Conclusion
    Acknowledgements
    References

This study assessed the intermix of local citation analysis and survey of journal use and reading patterns for evaluating an academic library's research collection. Journal articles and their cited references from faculties at the University of New South Wales were downloaded from the Web of Science (WoS) and journal impact factors from the Journal Citation Reports . The survey of the University of New South Wales (UNSW) academic staff asked both reader-related and reading-related questions. Both methods showed that academics in medicine published more and had more coauthors per paper than academics in the other faculties; however, when correlated with the number of students and academic staff, science published more and engineering published in higher impact journals. When “recalled” numbers of articles published were compared to “actual” numbers, all faculties over-estimated their productivity by nearly two-fold. The distribution of cited serial references was highly skewed with over half of the titles cited only once. The survey results corresponded with U.S. university surveys with one exception: Engineering academics reported the highest number of article readings and read mostly for research related activities. Citation analysis data showed that the UNSW library provided the majority of journals in which researchers published and cited, mostly in electronic formats. However, the availability of non-journal cited sources was low. The joint methods provided both confirmatory and contradictory results and proved useful in evaluating library research collections.

Introduction

    Top of page
    Abstract
    Introduction
    Methodology
    Results and Discussion
    Conclusion
    Acknowledgements
    References

Overview

Building and maintaining a useful library collection to support research across all disciplines of a university require an understanding of a broad range of research activities and information use patterns of a correspondingly wide range of academic staff. The challenges encountered by academic librarians are numerous, one of which is the provision of a balanced collection of journals and monographs in electronic or print formats. This balance is especially precarious in a large university with a strong research culture in medicine and science, to a lesser degree in engineering, and lesser still in the other disciplinary units of commerce (including economics) and the arts and social sciences.

The University of New South Wales (UNSW) in Sydney, Australia is one such university. Started in 1949, it is now one of Australia's largest universities with nine faculties (large academic units), over 70 schools within the faculties, and four teaching hospitals; there are over 2,300 academic staff (teaching and/or research) and nearly 3,000 general staff ( http://www.unsw.edu.au ). The UNSW library ( http://info.library.unsw.edu.au /Welcome.html) serves three different campuses with about 195 staff, including casual staff. In 2006, there were nearly 2.7 million items in the three collections with about 23,000 e-journals and 8,600 print journals.
Goals and Research Questions

The primary goal of the present study is to evaluate this academic library using data from citation analysis, journal publishing outlets, and journal usage and reading. A sample of the UNSW academics' 2003 journal publications (including their cited references) and results of a 2004 survey of the UNSW academic staff journal reading patterns were used. Secondarily, the differences between usage patterns, publishing, and citing patterns of different academic disciplines in one Australian research university using two methodologies are examined. Finally, as these differences are thought to be typical of other research and teaching universities that have large e-journal collections and moderate print collections, we see the joint evaluation tools applicable to other universities, especially ones that have been surveyed using similar instruments by Tenopir & King ( http://web.utk.edu/˜tenopir/research/index.html ).

The underlying questions of this study are answered and discussed in four broad sections: (a) the UNSW academics and the journals in which they publish and cite, (b) their “actual” and self-reported publishing patterns, (c) the quality of their source and cited journals as compared to the extent and purpose of their readings, and (d) the availability in the library of the sources supporting their research and publishing activities. We have reported many detailed findings in these categories as baselines against which similar future studies may be compared. These questions are as follows:

    To what extent do UNSW researchers publish in or cite from journals tracked in the Thomson Scientific ISI Web of Science (WoS) database?

    What is the average number of coauthors per faculty and what are the UNSW authors' positions in multiauthored publications?

    Do citing or reading practices differ from those faculties with more coauthors?

    Do the academics who read more on average publish more or have more cited references per paper?

    What is the “quality” of the source and cited journals as determined by their impact factors?

    Do the academics who publish more also read more and are their citing practices different?

    To what extent is the UNSW library collection meeting the needs of UNSW researchers based on where they publish and what they cite?

    Do UNSW researchers cite more from journals that are available in the UNSW collection (print or electronic)?

    To what extent do academics read from library collections and does this reading pattern relate to their citing patterns?

The survey of the UNSW academic staff journal reading patterns was conducted late in 2004 (Tenopir, Zhou, & King, 2006 ). Motivated in part by the survey, a local citation analysis from a systematic sample of 2003 journal publications of a similar academic research cohort looks at the references cited (as well as the sample's source publications) to assess their “quality” and “availability” in the UNSW library.

Comparison of the results from the two methodologies (hereafter referred to as “citation analysis” and “survey”) for collection evaluation across all disciplines is somewhat novel. Citation analysis looks at “actual” use of materials, while surveys ask respondents to “recall” use of materials whether they were cited in their publications. One recent study by Schloegl & Stock ( 2004 ) compared citation and readership data; however, the citation analysis was limited to one field (library and information science) while the reader survey included practitioners and scientists from both public and private sectors. In contrast, the citation analysis we undertook applied to publications and their cited references produced by a cross-section of the academic survey respondents.

In this study, “availability” in the library is equated to “use” made of the journals UNSW researchers published in and to the publications they cited or referenced. The “quality” of the source journals and the cited journals is measured by their journal impact factors calculated by the Thomson Scientific Journal Citation Reports . The results of the reading survey and the local citation analysis are used for an examination of the reading and citing (usage) patterns of UNSW academics and the relationship between these patterns and the library collection. In this article, the term “faculty” is used to refer to a large academic unit such as the faculty of science; the faculty or teaching/research members of academia are referred to variously as academics, academic members, academic staff, or researchers.
Methodology

    Top of page
    Abstract
    Introduction
    Methodology
    Results and Discussion
    Conclusion
    Acknowledgements
    References

Citation Analysis and Publishing Patterns

The complete research publications of academics from UNSW for 2003 were obtained from the UNSW research office. From the total 3,381 research publications, only 2,215 refereed scholarly journal articles were of interest in this study. These top-tier journal articles were published in a journal included in the Thomson Scientific WoS citation databases, or a journal classified as refereed in Ulrich's International Periodical Directory , or a journal in the supplementary Register of Refereed Journals issued by the Australian Government's Department of Education, Science and Training (DEST). The majority (1933) of the 2,215 journal articles were authored or coauthored by academics in one of five faculties: arts & social sciences, commerce & economics, engineering, science, and medicine. The remaining 282 journal articles were excluded in the study as they were from academic units contributing relatively small numbers of publications.

Based on the 1,933 journal articles published by five faculties, a proportional sample of 100 journal articles was systematically selected. The articles were checked against the WoS accessed from the UNSW library. If a randomly selected paper in a particular faculty did not appear in the WoS, the next article in the faculty list was selected. The number of authors in each of the sample 100 journal articles was also determined and the numbers of UNSW and non-UNSW first authors were noted. First authors from UNSW were further identified as either an academic staff or a student. The availability (in electronic, print or both) of the 100 source journals in the UNSW library was determined.

The cited references for each of the 100 sample journal articles were downloaded from the WoS into an Excel spreadsheet. As with most downloads from commercial databases, considerable ‘cleaning’ of the data is necessary before any bibliometric analysis occurs (Hood & Wilson, 2003 ); these cited references were no exception. To obtain high accuracy, comparison with the cited references from the actual printed article was done before further analysis proceeded. The document types of the cited references for each of the five faculties were categorized broadly using the UNSW library's scheme: “serials” (journals and annual reviews, primarily), “monographs” (books and edited items), and “others” (conference papers, thesis/dissertations, Internet resources, technical reports, ongoing project reports, etc.). Of the 3,095 cited references downloaded, each unique cited reference (for a particular cited year, volume and issue in the case of serials) was checked against the UNSW library collection for availability in various formats: print, electronic, or both print and electronic. The distribution of the publication years for the serial cited references was determined for each of the five faculties. Impact factors from the Journal Citation Reports (JCR) science and social sciences editions were accessed from the UNSW library: 2003 editions for the 100 source journals and 2,000 editions for the cited journals because nearly 42% of the serial cited references were from the years 1998–2002.
Survey of Journal Use and Reading Patterns

The 2004 survey of UNSW academic staff replicated surveys conducted in the U.S. by Tenopir & King (see http://web.utk.edu/˜tenopir/nsw/staff.html for the survey instrument and web.utk.edu/˜tenopir/research/for many similar survey instruments.) It measures reading behavior rather than preferences or opinions. To do this, the survey instrument used both reader-related (recollection of past behavior and demographic) and reading-related questions (specific to the last incident of reading). Respondents were first asked to recollect how many scholarly articles they have read in the last 4 weeks. Scholarly articles are defined as “those found in journal issues, Web sites, or separate copies such as preprints, reprints, and other electronic or paper copies.” Reading is defined as “going beyond the table of contents, title, and abstract to the body of the article.” Respondents were asked to remember just this short period to improve the chance of accurate recollections.

Other reader-related questions focus on standard demographic characteristics of the respondent, including age, year of last degree, gender, academic rank, campus location, and school or professional field (subject discipline.) Demographic questions specific to this study include percent of effort on various work tasks (such as teaching, research, administration, etc.), number of publications in the last two years, coauthorship and funding for the last article published, awards or special recognition in the last two years, and number of personal subscriptions. Each of the reader-related questions can be used as an independent variable, and the population is the total number of academic staff at the university.

Reading-related questions focused in detail on the specific article most recently read, a technique that improves the accuracy of the respondent's ability to remember and allows complex analysis of the value and purpose of reading. Questions about how the article was discovered, its format, time spent reading, the purpose of reading, and the value of the reading to the purpose, provide information about the relative role and value of library collections or alternatives in the overall reading patterns of academics. The incident of last reading is a variation of the critical incident technique in which the universe is all readings by academic staff within the last month. A two-stage sample is taken: The first stage is the readers and their total readings in a month, and the second stage is one incident of their most recent reading, which is assumed to be random in time. Analysis of the reading-related questions (incidence of last reading) allows conclusions on readings rather than readers, answering questions, for example, such as does the value of the reading or average time spent per reading vary with the purpose of the reading.

In late September 2004, an e-mail message from the UNSW director of libraries, with an embedded link to a questionnaire housed on a University of Tennessee server, was sent to a random sample of 987 academic staff members at three UNSW campuses: Kensington (main campus), College of Fine Arts located elsewhere in the Sydney area, and Australian Defence Force Academy, located in Canberra. In addition, the questionnaire was linked on the UNSW library Web site and a follow-up was sent in October. Of a total full-time, academic staff at the time of about 2,300 (excluding casual staff and support staff), 230 responded to the questionnaire or 10% of the total UNSW full-time academic staff. If we assume all of the respondents came from the invitation sent by the random sample of staff, the response rate would be 23.3% (230 of 987).
Limitations

As this study uses multiple methods of analysis, limitations are related to both the individual different methods and the process of comparing different sample sizes and subjects. In citation analysis, citing patterns may be influenced by what is available (if the library does not have it, someone may be less likely to cite it). Therefore, it is difficult to state whether the library collection is meeting their needs or their needs are shaped by what the library collection provides. In addition, we had to check journal titles and dates available in both electronic and print form from the UNSW library because items that are available in both forms are usually cited in a paper version citation, and so we cannot be sure which version the person actually read or cited.

The proportional selection of 100 sample journal articles, representing slightly over 5% of the total publications of the five (main) faculties at UNSW, may have some bias, especially as each of the five faculties has varying numbers of schools and each has varying numbers of academics. To see how well the 100 sample articles represented the total 1,933 journal articles, the mean, median, and range of the number of authors per article were compared. We found very close agreement with the two datasets. As there were 3,095 cited references for the 100 sample journal articles, it would have been nearly impossible to download, clean, verify, analyse, and assess the availability of some 60,000 cited references for the 1,933 journal articles.

The survey is limited by response rate. The individuals who responded to the survey might be different from the nonrespondents in their reading patterns, publication rates, or use of electronic journals. Because the survey was administered online, respondents may be more comfortable with electronic journals than those who did not respond. The survey instrument is complex and although individuals could skip any questions, scroll backwards and forwards, and exit at any time, some may have been tempted to answer as quickly as possible. The critical incident technique attempts to help respondents focus better and leads to more accurate answers, but some readers may have been tempted to tell about a more interesting reading than the “last reading” we requested.

Finally, comparing different methods has inherent limitations. Although both methods studied the same population, we cannot tie individuals together with these two methods (citation analysis and survey). Instead, we must rely on tying together academics from the same faculties or subject disciplines.
Results and Discussion

    Top of page
    Abstract
    Introduction
    Methodology
    Results and Discussion
    Conclusion
    Acknowledgements
    References

Characteristics of Source Journal Articles, Cited References, and Survey Respondents
Source journal articles.

The proportional distribution of the sample 100 journal articles from the five faculties is shown in Figure 1 . Nearly three-quarters of the sample journal articles are from medicine and science. Tables 1 and 1a show the distribution of the total number of authors per faculty (and the mean, median, and range of the numbers of authors per article in each faculty) in the sample 100 and the total 1,933 journal articles. The mean number of authors per article in both datasets was about four, with variations among the faculties. Because many distributions in citation analysis are highly skewed, the medians and ranges for each unit are given in Tables 1 and 1a . Although the medians for each faculty are close in both datasets, the median for the 100 sample dataset of all five faculties is higher (4) than that of the 1933 dataset (3). In all faculties, the range of the number of authors was higher in the total dataset. Of the 100 sample articles, 71 had first authors from UNSW and of these, 57 were academics and 14 were students.
thumbnail image

Figure 1. Percentage distributions of sample journal articles ( n = 100) and of survey respondents ( n = 190) in five UNSW Faculties.

Download figure to PowerPoint
Table 1.  Distribution of 100 sample journal articles by faculty: Number of articles, number of authors, mean, median and range of number of authors per article, number of cited references, and mean, median and range of number of cited references per article.   	No. of journal articles 	No. of authors 	Mean / median & [range] no. of authors per article 	No. of cited references 	Mean / median & [range] no. of cited references per article
Arts & social sciences 	6 	11 	1.8/1 	177 	29.5/28
  	  	  	[1–4] 	  	[2–61]
Commerce & economics 	7 	15 	2.1 / 2 	237 	33.9/23
  	  	  	[2–3] 	  	[4–72]
Engineering 	16 	55 	3.4/3 	322 	20.1/18.5
  	  	  	[1–6] 	  	[5–59]
Science 	34 	130 	3.8/4 	1032 	30.4/26
  	  	  	[1–7] 	  	[7–84]
Medicine 	37 	200 	5.4 / 4.5 	1327 	35.9 / 31.5
  	  	  	[1–17] 	  	[6–106]
All five faculties 	100 	411 	4.1 / 4 	3095 	31 / 26
  	  	  	[1–17] 	  	[2–106]
Table 1a.  Distribution of total number ( n = 1933) of journal articles by faculty: Number of articles, number of authors and mean, median and range of number of authors per article.   	Total no. of journal articles 	Total no. of authors 	Mean/median & [range] no. of authors per article
Arts & social sciences 	142 	278 	2 / 1
  	  	  	[1–12]
Commerce & economics 	141 	282 	2 / 2
  	  	  	[1–5]
Engineering 	293 	880 	3 / 3
  	  	  	[1–11]
Science 	649 	2538 	3.9 / 4
  	  	  	[1–30)
Medicine 	708 	3757 	5.3 / 4
  	  	  	[1–75]
All five faculties 	1933 	7735 	4 / 3
  	  	  	[1–75]
Cited references.

Table 1 also provides the distribution of the cited references for the 100 sample articles: The total, mean, median and range of the numbers of cited references by faculties. Overall, the mean number of cited references is about 31 with a low of 20 for papers in engineering and a high of nearly 36 for medicine. The medians are lower than the means in all units: The overall number of cited references is 26 with commerce & economics having the greatest mean/median difference (about 34/23). The ranges for each faculty span considerably; for example, medicine has from 6 to 106 cited references with a mean/median of 36/32. Similar to the proportional distribution of the 100 sample articles, Figure 2 shows that the faculties of medicine and science had slightly over three-quarters of the cited references. A recent study by Kraus ( 2005 ) looked at 90 journal articles by academics in the biological sciences department at the University of Denver and reported, inter alia, 3,942 cited references and an average of nearly 44 per paper, considerably more than any of the means/medians given in Table 1 .
thumbnail image

Figure 2. Cited references: Numbers and percentages by document types in each of the five faculties.

Download figure to PowerPoint

Figure 2 shows the numbers and percentages of the document types of the 3,095 cited references across the five faculties. Overall, there were 2,518 (81%) serial cited references. As expected, arts & social sciences was the only faculty in which the percentage of monographs (52%) exceeded that of serials (43%); it also had the fewest number of total cited references (177). The faculty of medicine not only has the greatest number of cited references (1,327), it also had the highest percentage of cited serials (nearly 92%). In all the five faculties, there were 475 monographic cited references, with science citing the most—about one-third (160). There were only 102 “other” cited references (mostly conference papers and dissertations), with engineering citing the most—about one-third (34). The relatively high numbers of cited monographs by science is somewhat surprising; however, proportionally, it is comparable to that of engineering and substantially lower than either commerce & economics or arts & social sciences. Engineering's number and percentage of “other” cited references corresponds to their use of technical reports for much of their research.
Survey respondents.

The respondents to the survey came from all faculties and all academic disciplines, as shown in Figure 1 . Although 230 respondents answered at least one question, only 217 chose to give their academic affiliation; and of these, only 190 (88%) respondents were from the five large faculties. Although this closely corresponds to the 1,933 (88%) of journal articles by authors in the five faculties, the proportional representation of respondents differed somewhat: Just as medicine dominated the journal article sample (37%), they accounted for the largest number of survey respondents (66 or 35%). Science with 43 (23%) respondents was under-represented, while commerce & economics with 26 (14%) and arts & social science with 24 (13%) were over-represented. Engineering was represented equally with 31 (16%).

UNSW respondents split most of their time between research/writing and teaching, with less time spent on other work responsibilities. On average, respondents spend almost half of their time on research and writing and only about a quarter of their time on teaching. Table 2 shows that for respondents in commerce & economics (31%) and arts & social science (28%), the time spent on teaching exceeds the average, while medicine is considerably below with 14%.
Table 2.  Survey respondents: mean percentage of work time by five faculties and academics in “other” units ( n = 216).   	Research & writing 	Teaching 	Administrative 	Service 	Consulting/advising 	Other
Arts & social sciences 	40.7 	28.0 	16.7 	10.0 	3.8 	0
Commerce & economics 	33.0 	31.4 	19.4 	9.0 	6.6 	0
Engineering 	49.1 	21.1 	19.5 	6.0 	3.0 	1.6
Science 	49.3 	23.0 	11.9 	7.6 	4.3 	3.5
Medicine 	44.6 	14.4 	16.3 	13.1 	6.5 	3.7
Others 	37.6 	32.0 	11.9 	8.1 	7.9 	2.6

Respondents from the faculties of science (49%) and engineering (49%) spend the highest percentage of their time on research and writing, followed by medicine (45%), arts & social sciences (41%), and commerce & economics (33%). This spread in time allotted to research and writing may explain part of the differences in publication rates, with engineering proportionally contributing considerably less than half of the journal articles (Figure 1 ). We can tentatively surmise that the research and writing reported relate to that for technical reports and conference papers as well as for journal articles. For arts & social sciences, the research and writing activities would be related mostly to books rather than to journal papers.
Publishing Patterns of Academics
Source journal articles.

The five faculties account for over three-quarters of the 2,012 full-time equivalent (FTE) academic staff (UNSW, 2003 ). The 100 sample articles came from 1,933 (87%) journal articles authored or coauthored by academics from one of the five faculties. Using a “crude” measure of research productivity based on the total 3,381 DEST research publications (including books, book chapters, journal articles, and conference publications) divided by the number of FTE academics in each of the five faculties, we find that the five faculties produced 86.1% of all research publications: medicine contributed to nearly one-quarter (25%), followed by science (23%), engineering (22%), commerce & economics (9%) and arts & social sciences (8%).

Using only the 2,215 DEST “journal articles” published in 2003 and the number of academic staff in each of the five faculties, we can provide an average number of journal articles per member of staff. The faculties of science and medicine are the most productive with 1.68 and 1.64 papers per academic. Considering that medicine has more academic staff than science (433 versus 386) and considerably fewer students (2,605 versus 4,732), science academics appear to be somewhat more productive (UNSW, 2003 ). Table 2 provides some supportive evidence in that science academics reported spending slightly more time (49%) on research and writing than do their counterparts in medicine (45%).

To understand why this was the case in 2003, we looked into other factors, such as the amount of time medical academics spend in clinical practice versus that of the near-equivalent activity, consulting, among the science academics. Table 2 provides some clues: Medical academics reported spending nearly 40% of their time on activities other than teaching, research, and writing, while academics in science only 27%. We did not find it surprising that the mean/median number of authors per paper in the 100 sample journal articles (Tables 1 and 1a ) is higher in medicine (ca. 5) than in science (ca. 4). In addition to medicine having more academic staff than science, the higher author count in medical articles could be attributed to the greater number of research staff employed in the faculty of medicine; in fact, of the 556 FTE casual “research only” staff, 237 (43%) were in medicine while only 154 (28%) were in science (UNSW, 2003 ).

The faculty of engineering's total DEST number of journal articles per academic staff is nearly one (0.97), while that of commerce & economics and arts & social sciences are less than one (0.65 and 0.62, respectively). As shown above, however, engineering's proportional productivity over all DEST publications is close to that of science (22% versus 23%) and not far behind medicine (25%). Over half (52%) of the DEST publications in engineering were in the category of “conference publications,” which is typical (Tenopir & King, 2004 ). In contrast, science and medicine contribute small numbers of conference publications to the research quantum of UNSW, 9% and 2%, respectively. Commerce & economics also had a reasonably high proportion (38%) of conference proceedings, while arts & social sciences had few (5%). Books and book chapters, as opposed to journal or conference papers, make up over one-quarter (27%) of the research publications for the arts & social sciences. In commerce & economics, however, the proportion is small (12%), smaller still for medicine (7%), and negligible for engineering and science (4% each).
Cited references.

Ranking the “number of references” field on Dialog ( http://www.dialog.com ) for the 2003 publications of UNSW in the three Thomson Scientific citation databases— Arts & Humanities Citation Index (A&HCI), Social Sciences Citation Index (SSCI), and Science Citation Index (SCI)—showed that the figures in Table 1 for the “mean/median number of cited references” column are reasonable. For 1,940 publications in the Dialog search consisting of the document types “article” or “review,” the average number of cited references across all three databases was 38 (versus 31 for the 100 sample journal articles); 31 for the A&HCI (versus 30 for the faculty of arts & social sciences), 42 for SSCI (versus 34 for the faculty of commerce and economics), and 33 for SCI (versus 20, 30, and 36 for engineering, science and medicine, respectively). The mapping of the five faculties into one of the three citation databases is “loose” as the journal articles from the five faculties can span more than one of the three broad disciplinary areas of the Thomson Scientific citation indexes. Nevertheless, the results of this study do match the reality of the “near-total” number of journal papers produced by UNSW academics in 2003 .

The percentage distribution of the cited references by document types (serials, monographs, and others) in Figure 2 shows similarities to use patterns of academics in various disciplines (Tenopir & King, 2000 , 2004 ). Scientists and technologists (including the UNSW academics primarily in the three faculties of medicine, science and engineering) tend to read and use or cite mostly serials for professional activities; hence, the high percentages of serial cited references: from about 74% to 92% in these three faculties. On the other hand, humanists (mainly academics in the arts & social sciences faculty) rely more heavily on books; hence, over half (52%) of the cited references are to monographs. Social scientists (academics in both the arts & social sciences and commerce & economics faculties) sit somewhere in the middle; the proportions of serial cited references are about 43% and 59%, respectively, and 52% and 34%, respectively, for monographic cited references. The use of monographs by UNSW scientists and technologists was appreciably low; 7% by medical researchers and about 16% by academics in both science and engineering.
Self-reported publishing in the survey.

Scholars who publish more can be expected to read more. The UNSW research office data show actual amounts of publishing by UNSW academics. In the survey, we also asked them to estimate how much they had published in the last 2 years (which can variously be interpreted as 2002–2003 or 2003–2004). If their recollections are correct, the UNSW research office rankings of top publishing faculties and the survey rankings should be the same. Results ( n = 201) of the survey show that members of the faculty of medicine claim the most articles (6.0) in refereed scholarly journals, more than twice as many as members of the faculties of commerce & economics (2.7) and arts & social sciences (2.7). Members of the faculty of science claim 5.3 and “others,” 5.4. Only 18% of all respondents reported that in the past 2 years they had not published any articles in refereed scholarly journals. The majority (55%) had published more than two articles in the past two years (Table 3 ). There were 16 respondents who had published more than 10 articles in two years and one reported publishing 67. Such outliers are common in academia.
Table 3.  Number and percentage of refereed scholarly journal articles published by respondents in the past two years.   	No. and % of no (‘0’) articles 	No. and % of 1 or 2 articles 	No. and % 2 articles 	Total no. and % of respondents 	Mean number of articles
Arts & social sciences 	5 	11 	7 	23 	2.7
  	21.7% 	47.8% 	30.4% 	100.0% 	 
Commerce & economics 	6 	7 	11 	24 	2.7
  	25.0% 	29.2% 	45.8% 	100.0% 	 
Engineering 	4 	7 	17 	28 	3.5
  	14.3% 	25.0% 	60.7% 	100.0% 	 
Science 	7 	6 	29 	42 	5.3
  	16.7% 	14.3% 	69.0% 	100.0% 	 
Medicine 	9 	13 	39 	61 	6.0
  	14.8% 	21.3% 	63.9% 	100.0% 	 
Others 	6 	9 	8 	23 	5.4
  	26.1% 	39.1% 	34.8% 	100.0% 	 
Total 	37 	53 	111 	201 	4.6
  	18.4% 	26.4% 	55.2% 	100.0% 	 

Peer reviewed journal articles are not the only types of publications by academic staff, in particular in fields such as humanities. The survey respondents also reported non-refereed articles, chapters in books, proceedings, etc., and books. For these document types, UNSW academic staff reported an average of 7.0 publications in the last 2 years: 3.8 for commerce & economics, 5.4 for arts & social sciences, 6.2 for science, 8.7 for engineering, and 9.3 for medicine.

Securing funding for the research that resulted in their last publication is relatively rare at UNSW, but it is of course more likely in medicine, engineering, and science. Only 138 respondents answered this question and most (91%) were from the five faculties of this study. Nearly half of the funding sources were reported as “government” or “university” (including those from faculties of UNSW). The availability of research funds is probably directly related to the amount of reading done for writing proposals and the subsequent amount of publishing in higher impact journals.

Respondents were also asked to provide the number of coauthors in their most current publication, which is another second-stage random sample, this time of publications. The average overall was 2.1 coauthorships per article and slightly lower for the five faculties, with Medicine having the most (3.3).
Comparison of actual versus recalled.

In Table 4 , we took half of the “mean number of articles” published by UNSW respondents in the last 2 years from Table 3 to represent approximately the number of articles for one year, most likely 2003. We then compared these “recalled” figures with “actual” 2003 DEST figures for journal articles per academic in each of the five faculties (see above). Self-reported publishing of refereed journal articles by respondents is from 1.6 to 2.2 times higher than actual productivity of UNSW academics in the five faculties. Although medicine's recalled figures were the highest for journal articles as well as for all publications, science academics' actual figures are slightly higher; they were also more likely to recall more accurately.
Table 4.  Comparative numbers between “actual” citation analysis results and “recalled” (and derived) survey responses. Faculty 	Actual mean no. journal articles for 2003 	Recalled mean no. journal articles in one year 	Actual mean no. authors per journal article in (100) sample 	Recalled mean no. co-authors for ‘last’ refereed journal article
Arts & social sciences 	0.62 	1.35 	1.8 	0.8
Commerce & economics 	0.65 	1.35 	2.1 	1.0
Engineering 	0.97 	1.75 	3.1 	1.9
Science 	1.68 	2.65 	3.7 	2.0
Medicine 	1.64 	3.00 	5.3 	3.3

Although we suspected a slight inflation in the number of coauthors reported by respondents due to the way the question was worded, the comparative figures in Table 4 show just the opposite. In all five faculties, the actual numbers of authors per journal article in the sample are from 1.6 to 2.3 times higher than the recalled mean numbers of coauthors reported in the survey. (Unlike the “number of references” field, there is no “number of authors” field in the citation indexes of ISI; hence, a check on nearly all the refereed journals articles for 2003 was not feasible.) We can only speculate as to possible explanations for the undercounting of coauthors in the survey. Perhaps academics view only their research colleagues (“equals”) as coauthors and forget that research assistants and/or research students may also have been coauthors.
Citing and Reading Practices of Academics
Quality of source journals.

Table 5 provides a summary of the average journal impact factors (IFs) and the range of IFs for each of the five faculties. The overall ranges of IFs for 1,714 social sciences journals and 5,907 science journals in the 2003 JCR are also given; arts & social sciences and commerce & economics faculties have IF ranges from the JCR Social Sciences Edition , while the other three faculties have IF ranges from the JCR Science Edition . (All IFs are to two decimal places.)
Table 5.  The 2003 mean impact factors (IFs) of 100 sample journals and their ranges of IFs. (Ranges of IFs are from the 2003 social sciences & science editions of the Journal Citation Reports and are rounded to two decimals.) Faculty* 	No. of journal articles 	No. of journals with 2003 impact factors (IFs) 	Mean impact factor 	Range of impact factors (IFs) 	Range of IFs in 2003 social science journals ( n = 1714) & science journals ( n = 5907)

    *See text for comments accompanying superscripts a – f. (IF ranges in parenthesis were derived to approximate subject categories appropriate to three S&T faculties at UNSW.)

Arts & social sciences 	6 	2 	0.96 	1.76–0.16 	10.64–0.00 a
Commerce & economics 	7 	7 	0.59 	0.98–0.39 	10.64–0.00 b
Engineering 	16 	14 	1.73 	7.60–0.48 	52.28–0.00 c
  	  	  	  	  	(8.88–0.00)
Science 	34 	32 	2.16 	7.04–0.24 	52.28–0.00 d
  	  	  	  	  	(28.17–0.40)
Medicine 	37 	32 	3.77 	10.52–0.88 	52.28–0.00 e
  	  	  	  	  	(34.83–0.60)
All five faculties 	100 	87 f 	  	  	 

Due to the small number of journals with IFs in the faculty of arts & social sciences (only two) and with only seven journal articles (all with IFs) in the faculty of commerce & economics, the values given in Table 5 are only indicators and as such should be interpreted cautiously. For the other three faculties whose sampled articles were in journals that all had IFs, we can be more secure in some limited interpretations. The comments for superscripts a–f in Table 5 are provided below.

    a.
    There is no JCR edition for the arts & humanities; however, history and education are represented in the JCR Social Sciences Edition .
    b.
    When only subject categories for each school in the faculty are considered, the IFs are lower: for example, economics from 5.24–0.00; business and business, finance from 4.42–0.02.
    c.
    Engineering was represented by 14 subject categories and IFs from 8.88–0.00.
    d.
    Science was represented by 30 subject categories and IFs from 28.17 to 0.40.
    e.
    Medicine was represented by 21 subject categories and IFs from 34.83 to 0.60.
    f.
    Four journals were not among the 1,714 JCR Social Sciences Edition , but they were indexed in the Web of Science. Other discrepancies were due to sample articles from the same journal.

To assess the quality of the journals in which UNSW researchers published, the journal IFs were obtained for the 100 sample journal articles. As mentioned above, two faculties (arts & social sciences and commerce & economics) had so few journals that they will not be discussed in this section. For engineering, comment “c” above suggests that for journals within the 14 journal subject categories containing engineering, IFs ranged from 8.88–0.00. In Table 5 , the 14 journals with 2003 IFs in engineering ranged from a high of 7.60 to a low of 0.48. This would mean that academics in the engineering faculty are publishing in the medium to top journals in the engineering journal subject categories.

For Science, we identified 30 subject categories broadly representing the discipline of science as opposed to medicine, which had around 21 subject categories. Unlike engineering journal subject categories that contained the word engineering, those for science and medicine were more subjectively chosen; hence, more caution is in order in the following interpretation. Even when the two top review journals are removed, science with IFs from 7.04–0.24 is well below the IFs of 28.12–0.40 in Table 5 . For medicine, we omitted four review journals with IFs > 34.83. Although medicine had the highest range of IFs (10.52–0.88), the overall range of IFs for the medical disciplines are also amongst the highest.
Quality of journal cited references.

Impact factors for journals cited four or more times were obtained from the 2000 Journal Citation Reports. Of the 2,518 journal cited references in 1,012 journal titles, there were 168 unique journal titles cited at least four times for a total of 1,334 cited references. That is, nearly 17% of the journal titles accounted for over half (53%) of the serial cited references. The remaining 1,184 (47%) serial cited references were scattered over 844 (83%) journals. The relatively high percentage (81%) of cited references to journal articles in our study approximates Gooden's ( 2001 ) citation analysis of chemistry dissertations. However, the “high” journal title dispersion, 17% journal titles for 53% of the journal cited references, is closer to Sinn's ( 2005 ) study of the mathematical and statistics disciplines, which showed that 31% of the journal titles accounted for 80% of the citations to journal articles. In contrast, LaBonte's ( 2005 ) citation analysis of the nanotechnology literature showed a “low” journal title dispersion—only 8% of journals accounting for nearly two-thirds (66%) of the cited journal articles. The distribution of 2,518 serial cited references over 1,012 journals is highly skewed with 587 (58.0%) journals cited only once, another 178 (17.6%) cited twice, and 79 (7.8%) cited three times. There were only 168 journals (16.6%) cited over three times (Table 6 ). The eight most highly cited journals (cited from 20 to 60 times) include Journal of Biological Chemistry, Aids, Proceedings of the National Academy of Science, Nature, Neurology, Applied and Environmental Microbiology, Lancet and Science. As the faculties of medicine and science had the largest numbers of cited references, it is not surprising to find all eight of the most highly cited journals in the journal subject categories of the Science Citation Index. The scatter of nearly one-quarter of the cited references over 587 journals is perhaps not too surprising in that, unlike other local citation analysis studies of generally one subject area, our study spans a number of disciplines, albeit a high concentration in medicine and science.
Table 6.  Mean impact factors for 168 journals cited > 3 times within a range of the number of citations per journal. Mean impact factor (IF) 	No. of citations per journal 	No. of journals in citation range
11.78 	20 to 60 	8
7.75 	15 to 19 	6
5.21 	11 to 14 	18
4.43 	9 to 10 	15
3.91 	7 to 8 	26
3.51 	6 	23
5.54 	5 	22
4.30 	4 	50
Mean IF for 168 	  	Total number of
Journals = 4.88 	  	Journals = 168

For the eight most highly cited journals listed above, the average IF is 11.78. For all the 168 journals cited at least four times, the IF is 4.88, which is considerably higher than the average IFs of journals used by UNSW researchers to publish their papers (Table 5 ). This is due, in part, to the fact that, for the 100 source journal articles, six were in four journals published in Australia with IFs ranging from 0.29 to 1.43. In contrast, there were only five cited Australian journals among the 168 titles cited at least four times with IFs from 0.67 to 1.52. These five were cited from four to seven times only. The proportion of Australian to non-Australian journals would predictably be higher for UNSW researchers, while cited references would most likely lean toward non-Australian journals, many of which have higher impact factors than their Australian counterparts. In fact, most of the 168 highly cited journals are published either in the U.S. (107) or the UK (31); this could account for the higher average IF in the journals cited. A previous study supports the notion that local researchers tend to cite journals with higher IFs than those of the journals in which they published (Wilson & Osareh, 2003 ). One is tempted to conclude that the remaining 844 (83%) unique journal titles cited three times or fewer would have average IFs lower than that of 4.88 for the 168 top cited journals.
Amount and value of readings.

Of the 215 participants who responded to the survey question—how many scholarly articles have you read in the last 4 weeks?—answers ranged from 1 to 400 articles. After 13 outliers were deleted, participants reported that they read on average about 15 articles with a standard deviation of 10.3. We have 95% confidence to say the staff at UNSW read on the average between 14 and 17 articles in the last 4 weeks, or extrapolating up to the year, between 168 and 204 articles per year. When only a single outlier of 400 is omitted, the average number of articles read increases to 18 per month or 216 per year.

Amounts of reading vary by academic and subject discipline. In surveys from 1977 to 2003, medical academics consistently report more article readings than academics in other disciplines (Tenopir, King, Clarke, Na, & Zhou, 2007 ). This is also true at UNSW. Table 7 shows amount of reading by UNSW academics; the faculty of medicine reports reading twice as many articles per month as the faculty of commerce & economics. The high number of article readings by the UNSW faculty of engineering is quite different from all surveys done by Tenopir & King ( 2004 ) in the U.S., where engineering academics consistently report fewer readings than academics in medicine, social sciences, and sciences. However, academic staff in engineering reported that they spent nearly half (49%) of their work time on research & writing (Table 2 ) and presumably most of that time in reading for research (65%; Table 7 ).
Table 7.  Number of articles read in the past four weeks and the number and percentage of readings by principal purpose of readings by UNSW academics.   	  	No. of respondents and % of readings by principal purpose of reading by UNSW academics ( n = 217)
  	No. articles read in past 4 weeks ( n = 215) 	Research 	Teaching 	Current awareness 	Writing proposals 	Other 	Total
Arts & social sciences 	15.8 	(8) 33.3% 	(11) 45.8% 	(1) 4.2% 	(4) 16.7% 	(0) 	(24) 100%
Commerce & economics 	12.2 	(14) 53.8% 	(3) 11.5% 	(2) 7.7% 	(3) 11.5% 	(4) 15.4% 	(26) 100%
Engineering 	32.2 	(20) 64.5% 	(1) 3.2% 	(2) 6.5% 	(5) 16.1% 	(3) 9.7% 	(31) 100%
Science 	17.4 	(26) 60.5% 	(6) 14.0% 	(6) 14.0% 	(5) 11.6% 	(0) 	(43) 100%
Medicine 	23.7 	(38) 57.6% 	(5) 7.6% 	(8) 12.1% 	(12) 18.2% 	(3) 4.5% 	(66) 100%
Others 	14.8 	(12) 44.4% 	(7) 25.9% 	(5) 18.5% 	(1) 3.7% 	(2) 7.4% 	(27) 100%
Total 	20.3 	(118) 54.4% 	(33) 15.2% 	(24) 11.1% 	(30) 13.8% 	(12) 5.5% 	(217) 100%

UNSW academics read for many purposes, including research, teaching, writing proposals, and others (Table 7 ). More than half of all readings by UNSW academics (54%) were for research purposes, with an additional 14% for writing proposals. As the reading for research and writing is more likely to lead to publications, we do not find it surprising that those academics who publish more are also likely to read more. The faculties of medicine, engineering, and science report more reading for research and therefore can be expected to both publish more and cite more articles in their publications. Although academics in engineering spent the largest percentage in reading for research and writing proposals (81%), they only published on average about one journal paper in 2003 as compared to nearly two for science and medicine academics. Additionally, UNSW engineering academics cited on average the fewest references of all the five faculties and well below the overall mean of 31 for all of the 100 sample journal articles (Table 1 ). It may be that the respondents from engineering were on average those who read more and were also the most productive; our surmise is supported by a recent ranking of UNSW as the most prolific among Australian universities in the combined field of engineering (SCI-Bytes, 2006 ).

Rereadings, that is, reading a specific article more than once, are more likely to be for research purposes (Tenopir & King, 2000 ). Approximately 20% of the total readings in the survey of UNSW academics are rereadings. Rereadings might be more likely to be cited in publications as well because rereading is more likely if an article was believed to be relevant after the first reading.

The information reported or discussed in nearly half of the first-time readings (101, 46.8%) was already known to the reader. Prior knowledge came from many different sources, but we were surprised to learn that it came only very rarely from author Web sites, email, or electronic lists. Other journal articles, informal discussions with colleagues, and (in some subject disciplines) conferences or workshops were the most common methods of finding information prior to reading an article.

Older readings are also more likely to be for research purposes, and their utility for publication can be verified in citing patterns. Of the total readings by UNSW academics, more than half (52%) were from 2004 or 2005, the current year of the survey (Table 8 ). Another 24% were from 2000 to 2003. However, the age of readings ranges from 2005 back to 1926. Year of reading by faculties can be compared to the citing patterns of the same faculties (see below).
Table 8.  Numbers and percentages of readings by age of last reading in date groupings for UNSW academics ( n = 215).   	Over 15 years (1926–1988) 	11 years–15 years (1990–1994) 	6 years–10 years (1995–1999) 	2 years–5 years (2000–2003) 	1st year (2004–2005) 	Total
Arts & social sciences 	(2) 8.3% 	(4) 16.7% 	(1) 4.2% 	(11) 45.8% 	(6) 25.0% 	(24) 100.0%
Commerce & economics 	(1) 3.8% 	(1) 3.8% 	(5) 19.2% 	(4) 15.4% 	(15) 57.7% 	(26) 100.0%
Engineering 	(1) 3.3% 	(2) 6.7% 	(7) 23.3% 	(7) 23.3% 	(13) 43.3% 	(30) 100.0%
Science 	(1) 2.3% 	(2) 4.7% 	(7) 16.3% 	(7) 16.3% 	(26) 60.5% 	(43) 100.0%
Medicine 	(1) 1.5% 	(3) 4.6% 	(8) 12.3% 	(13) 20.0% 	(40) 61.5% 	(65) 100.0%
Others 	(1) 3.7% 	(3) 11.1% 	(1) 3.7% 	(10) 37.0% 	(12) 44.4% 	(27) 100.0%
Total 	(7) 3.3% 	(15) 7.0% 	(29) 13.5% 	(52) 24.2% 	(112) 52.1% 	(215) 100.0%

There is a significant difference between age of items read and the purpose of reading ( X 2 = 33.826, p = 0.006) with a weak level of association between the variables (Cramer's V value of .195). We were not surprised that readings for current awareness are almost all recent articles. On the other hand, more than half of all readings for writing proposals and teaching are 2 years old or older. Nearly half (47%) of readings for research are also older.

The value of readings to a purpose is implied in citation data, but is explicitly gathered in surveys. Respondents were asked to indicate how the reading affected their principal purpose and to rate the importance of the article on a 1 to 3 scale from “not at all important” to “absolutely essential.” Readings proved useful to the principal purpose of reading in many ways, including (in rank order) inspired new thinking, improved the result, and narrowed or broadened the focus. These three values were selected by a quarter to a half of respondents in all subject disciplines. In addition, nearly a quarter of engineering respondents indicated that their last reading helped resolve technical problems. Only a few felt the last reading wasted their time. Similarly, most of the readings were rated as “somewhat important” (66% overall) or “absolutely essential” (31%) for the principal purpose. Readings for research or teaching are significantly more likely to be rated “absolutely essential” X 2 = 18.876, p = 0.016). There is likely a relationship between these readings and those readings chosen to be cited in publications (see below).
Availability of Sources and Readings from the Library
Source journals.

The 100 sample journal articles were in 91 journal titles; that is, nine journals each had two articles. In 2005, when most of the data processing took place, the UNSW Library held all but five journal titles (in electronic, print, or both); however, by mid-2006, one title had been acquired online from 1999 onwards, another is available electronically from 1989-1994 only, and a third title is now available electronically from 2005 onwards. Two source journal titles are still unavailable from the UNSW library in 2006 . Of the remaining 95 journal articles (in 86 journals), 92 articles (in 83 journals) were available electronically and 32 journal articles (in 27 journals) in print; three articles in three journals were available in print only and 29 articles (in 24 journals) were available in both formats.

Although this study is not meant to suggest what the library should collect, it does show, however, that local citation analysis can reveal gaps in the collection, at least of those titles that researchers not only read and cite but also use as publication vehicles for their papers. One can only speculate as to whether authors who publish in journals not held in the library have private subscriptions or some other means (for example, the homepages of the journals) of judging their suitability. If we project from the sample of 100 journal articles (in 91 journal titles) to the DEST total of 2,215 refereed journals articles (in proportionally 2,016 journal titles), then there may be as many as 111 journal titles not held by the library. However, there were only 1,012 serial titles for the 2,518 cited references, nearly a 2.5-fold reduction. If this distribution is applied to the 2,215 DEST journal articles, then there would be about 45 titles not held by the library. We can therefore speculate that around 50 source journals are likely to be inaccessible from the library. For a library that has deliberately moved towards building an e-journal collection (UNSW Library, 2006 ), we do not find it surprising that the overwhelming majority of the 2003 source journals were available electronically (83 of 91). A further three journal titles were available in print only with an overlap of 24 titles in both formats. Decisions to migrate to e-journals generally mean that subscriptions to their printed counterparts would cease if there were additional subscription and storage costs. The printed collection of journals has become, in effect, “archival” in value for users needing earlier volumes not yet in electronic formats.
Cited references.

For all the five faculties, the total of 2,518 serial cited references represented only 1,012 titles; however, for a serial cited reference to be available in the library, the year, volume, and issue must be held. Of the total serial cited references, 2,294 (91.1%) were held in the library and 224 (8.9%) were not available at all. The availability breakdown by format for the 2,294 serial cited references held in the library was 1995 (79.2%) printed, 1,495 (59.4%) electronic, and 1,196 (47.5%) in both formats. For the 475 monographic cited references, only 277 (58.3%) were in the library and only 24 (23.5%) of the 102 “other” cited references were available in the library. In addition to electronic availability of serial cited references, the study also looked at the number of cited references freely available on the Web which could include, e.g., serials, monographs (in pdf format), Internet resources, software, conference papers, and other internet resources. There were 65 various resources freely available on the Web, with the faculty of commerce & economics listing the most (24) in their total number (237) of cited references. These sources were identified (mostly by chance) when we looked for cited references not held in the library; that is, only those sources not available in the library (500 of the total 3,095 cited references) were searched on the Web. As the movement to develop and implement new methods of scholarly communication accelerates (e.g., open access journals, digital e-print archives, institutional repositories), academics will most likely shift their reading and citing practices to coincide with the convenience offered by these methods (Bergman, 2006 ; Nicholas & Rowlands, 2005 ; Nicholas, Huntington, & Rowlands, 2005 a; Nicholas, Jamali, Huntington, & Rowlands, 2005 b).

Figure 3 shows by faculty the numbers and percentages of the cited references that were available in the library for each document type. For example, in the faculty of medicine, which had the greatest number of cited references overall as well as to serials, 1,097 of 1,217 (90.1%) were available; the rest (120 or 9.9%) were not held in the library. For monographs in medicine, less than 50% (44 of 92) were available, and the library had none of the remaining 18 “other” cited references. At the other end of the spectrum in Figure 3 , all but four of 76 serial cited references from the faculty of arts & social sciences were available; however, 32 of cited references to monographs and 9 from the “other” category were not available in the library. The engineering faculty had the most “other” (34) cited references, and of these, 14 were not available in the library. The science faculty had 67 (of 160) monographic cited references not available in the library; this is the highest number of monographs (by faculty) not held in the library and represents slightly over one-third of all monographic cited references.
thumbnail image

Figure 3. Availability of cited references: Percentages held in the library by document type in each faculty. Labels for each document type in each faculty represent the “availability” number of cited references in the numerator over the total number of cited references in the denominator and the “availability” percentages.

Download figure to PowerPoint

The five-yearly distribution of the 2,518 cited serial references by their cited publication years is shown in Figure 4 for each faculty from 1978 to 2002; also shown in Figure 4 are the availability numbers and percentages of each five yearly groupings (see data point labels). In all but the 1988–1992 grouping, the availability is at least 90% or greater, confirming the overall availability (91.1%) of the serial cited references discussed above.
thumbnail image

Figure 4. Distribution of serial cited references by cited year groups with data point labels for “all faculties” showing the numbers and percentages available in the library.

Download figure to PowerPoint

There were 1,055 serial cited references (with 989 or 94% availability) in the peak cited years from 1998–2002; the cited year 2000 had the most (249). Medicine generally had the greatest number of serial cited references in all the year groups; however, in the pre-1978 group, science (115) had nearly twice the number as medicine (58). There were 44 with cited years 2003–2004 (mostly “in press” references) and 41 or 93% of these were available in the library.

The overall availability of serial cited references is very high (>90%) for all faculties; however, in 2003 there were more available in print (79.2%) than electronically (59.4%). Interestingly, nearly one-half (47.5%) were available in both formats; this may be due to the library's continuing process of migration from print to e-journal. It would appear that in future, UNSW academics would be using or citing more from e-journals, particularly as the number of e-journals has now far exceeded that of print journals (UNSW Library 2006 ). However, in contrast to the “high” availability of serial cited references, the other document types, especially monographs, are very “low”: only 58.3% of all cited monographs were available. We were surprised that the availability of the arts & social sciences cited monographs was the highest (65.2%) and medicine the lowest (47.8%). This outcome is perhaps associated with the expenditure priorities of the library: meeting student needs is paramount, supporting research needs is secondary (UNSW Library, 2006 ).

Although the availability of all serial cited references is over 90%, Figure 4 shows that the pre-1978 years and 1988–1992 have the lowest percentages of availability. Because of the “electronic-preferred” policy especially for journals, we did not find it surprising to see that the availability of journals cited with publication years from 1993 to the present continue to remain over 90%.
Readings from the library.

UNSW academics report fewer personal subscriptions than their counterparts in the U.S. and therefore can be expected to rely more on the library or other sources of articles. The arts & social sciences faculty reported the highest number of personal subscriptions (mean 3.7) and faculty of engineering the fewest (mean 1.7), but there is no statistically significant difference between faculties.

Like citation analysis, surveys measure readings done both from the library and from other sources. Overall, UNSW academics report readings from many sources, with at least half of their readings coming from the library; medicine, arts & social sciences and science reported 52% to 57% and engineering and commerce & economics 37% to 39%. (Some of the readings in the “other” category may also be from the library electronic collections, as individuals may not realize when they retrieve an electronic article from their office connection that they are able to access a proprietary journal because their UNSW affiliation is automatically recognized and confirmed—see Kennan, 2007 .) Readings for teaching and current awareness are more likely to come from personal subscriptions, while readings for research (53%) and other purposes are more likely to come from the library or other sources ( X 2 = 21.318, p = 0.006).
Comparison of citing and reading from journals.

In the previous section, we noted that most UNSW academics read journal articles principally for research (54%—see Table 7 ). Only the academics in arts & social sciences read more journal articles for teaching (46%) than for research (33%). This finding corresponds with their citing patterns: Academics in the arts & social sciences faculty cited more monographs (52%) than journals (43%) in the 100 sample journal articles (Figure 2 ). The other four faculties cited journals from 59% (commerce & economics) to a high of 92% (medicine) in the 100 sample articles. Hence, one would expect that the faculties with the highest proportion of journal cited references (medicine with 92% and science with 82%) would also read more journal articles for research; in this case, academics in science read slightly more (61%) articles for research than those in medicine (58%). An anomaly remains: Academics in engineering stated that they read the most number of journals (32) and that 65% of their journal reading was for research—well over their counterparts in the faculties of science and medicine (Table 7 ). Yet, in Figure 2 , the journal cited references in engineering represent only 74% as compared to science (82%) and medicine (92%). As noted earlier, the journal reading patterns of engineering academics in UNSW are quite different from their U.S. counterparts, and further comparisons with engineering academics from other countries could unravel the discrepancy.

Figure 4 groups cited data by year for comparison with the age of respondents' last readings as reported in the survey. Table 8 shows that overall, three-quarters (76%) of the readings by UNSW academics were of articles from 2000 to the current year (2004 in this case). Medicine has the highest (82%) and engineering the lowest (67%). This correlates quite well with the 2,294 cited references from journals for all the five faculties in which nearly half (48%) were from 1998 to 2004, with the cited year 2000 having the most cited references. Although very few academics reported having read older articles (1926–1988), cited references to journals include three from the late 1800s and 14 from 1906–1922. In all, there were 226 journal cited references in the pre-1978 category in Figure 4 , with academics in science citing nearly half (115) of these older journal articles, followed by medicine with 58. The comment made above that older readings are more likely to be for research purposes does ring true; further, the two faculties (science and medicine) with the greatest number of cited references as well as to journal cited references (Figure 2 ) have also cited the most pre-1978 journal articles.
Conclusion

    Top of page
    Abstract
    Introduction
    Methodology
    Results and Discussion
    Conclusion
    Acknowledgements
    References

Nearly 88% of all 2,215 “refereed journal articles” published in 2003 by UNSW staff were in the Thomson Scientific Web of Science citation database. The 100 sample journal articles were distributed proportionally among academics in five faculties, representing 78% of all UNSW academics and 87% of all journal articles: 37 in medicine, 34 in science, 16 in engineering, 7 in commerce & economics (C&E), and 6 in arts & social sciences (A&SS). The overall mean/median number of authors per article was 4.1/4 ranging from a low of 1.8/1 in arts & social sciences to a high of 5.4/4.5 in medicine; nearly three-quarters (71) of the articles had first authors from UNSW consisting of 57 academics and 14 students. The 100 sample articles had 3,095 cited references with medicine having the most (1327) and arts & social sciences the least (177). The 190 survey respondents in 2004 were from the same five faculties, though the distribution under-represented science and over-represented the faculties of A&SS and C&E. These 190 academics reported spending on average nearly half (41%–49%) of their time on research and teaching; only those in C&E reported spending somewhat less (33%).

The citation analysis showed that academics in medicine published more than academics in the other four faculties and the survey results added supportive evidence: Respondents in medicine reported spending the least amount of time in “teaching” (14%) and 45% in “research and writing.” In addition, the UNSW statistics for 2003 showed that the faculties of C&E and engineering had the highest percentages of enrolled students (19% and 18%), medicine had only 6%, and science and A&SS around 12%. When the number of academic staff in each of the five faculties are considered, science (with 1.68 papers per academic) is slightly more productive followed closely by medicine (1.64); engineering has nearly one publication per academic (0.97); C&E (0.65) and A&SS (0.62) each has slightly less than one. When these productivity patterns were compared to the “recalled” number of articles published in the last two years, we found that all five faculties over-estimated (on average) their productivity by nearly two-fold. In contrast, all five faculties under-reported the number of coauthors for their “last” refereed journal article by about two-fold; e.g., science had mean/median of 3.8/4 authors in the 34 sample journal articles as compared to only 2.0 coauthors reported in their survey responses.

The distribution of cited references over document types in each of the five faculties differed along expected lines: academics in medicine, science, and engineering cited mostly journal papers (92%, 82% and 74%, respectively) while their counterparts in C&E (59%) and A&SS (43%) cited considerably fewer. We were not surprised to learn that monographs (mostly books) were cited heavily by academics in the faculties of A&SS (52%) and C&E (34%).

We were able to approximate the “quality” of the 100 sample journal articles and that of their cited references after adjusting for the impact factors of cited journals mapped to each of the five faculties. Because there were so few journal papers with impact factors for the faculties of A&SS and C&E, we provided very limited comments regarding these two faculties in the Quality of source journals section earlier. For the other three faculties, we comment cautiously that engineering academics are publishing in reasonably top journals with medium to high impact factors, while academics in science and medicine perhaps not so. However, the medical faculty has the highest range of journal impact factors. Because of the way that the JCR bundles journals within subject categories and across the sciences and social sciences, academics especially in science and medicine will find “their” journals scattered among a variety of subject categories, some with very narrow ranges of impact factors. Nevertheless, the analysis provided is a start and can be expanded in greater depth by schools within each of the faculty for research performance evaluation.

As noted earlier, it is not surprising to find researchers citing papers from journals with high impact factors as these would be thought to provide (in general) the most authoritative supporting evidence. UNSW researchers are no exception; the eight most highly cited journals with a mean impact factor of 11.78 account for 11% of the total number of citations in the 100 sample journal articles. The reader survey reported on average about 20 articles read in the last four weeks, excluding outliers. What we found surprising was the high number of article readings by academics in engineering; this is over twice as many articles in some of the other faculties. In addition, the engineering academics reported that they read mostly (81%) for research and for writing proposals.

Extrapolating from the number of source journals available from the library for the 100 sample journal articles, we can say that the library is likely to have most (around 95%) of the journals in which UNSW researchers are likely to publish. Likewise over 90% of the journal cited references are available in the library. At the time of the study, more of these cited references were available in print than in electronic formats; however, we expect to see the balance reversed as the library aggressively moves from print to e-journals. We also expect to see shifts in citing patterns from journals available through library subscriptions to open access journals (subscription as well as non-subscription) easily obtainable by academics from the web. We note however that the availability of monographs and “other” cited sources is quite low; in the case of the cited monographs by academics in medicine, less than half were available in the library. Over the five faculties' cited journal references, the majority were from the years 1998–2002 and most (94%) of these were readily available in the library. As stated in the Limitations section, we can not tell whether the library collection is meeting the researchers needs or if their needs are determined by what is available in the library's collection.

The survey showed that UNSW academics were less likely to have personal journal subscriptions as compared to their U.S. counterparts. Hence, we see the library's continual support of researchers, at least with subscription-based electronic journals and perhaps in the future with journals in its institutional repository. Readers reported that at least half of their readings were from library sources; this might be higher as many readings obtained electronically from the “other” category may also be from the library.

UNSW Library plays an important role in the research life of the academic staff in all faculties. Reading for research and citations rely heavily on journals made available through the library's e-collections. It is essential to scholarship that there is continued access to scholarly articles either provided through journal subscriptions or other means, such as institutional repositories.

Finally, the joint evaluation methods used in this study provided some confirmatory and some contradictory results; these results, in turn, have prompted us to ask why, and our analyses have painted a richer picture of the academic research landscape across a variety of subject areas of one university. By the same token, we hope that the results of this study will encourage academic librarians, especially from an increasing number of universities that have been surveyed using similar instruments, to consider the intermix of local citation analysis data and survey data on journal use and reading patterns when evaluating their research collections.
Acknowledgements

    Top of page
    Abstract
    Introduction
    Methodology
    Results and Discussion
    Conclusion
    Acknowledgements
    References

We thank Margaret Lo, research assistant supported by the John Metcalfe Memorial Fund, for extensive work on the local citation analysis data collection and manipulation; Andrew Wells, Rhonda Langford and Isabella Trahn of the UNSW Library, for assistance in the preparation and implementation of the reading survey; Tom Croucher, director of the UNSW research office, for provision of the 2003 research publications; and Xiang (Julie) Zhou, Lei Wu, Liuyan Yang, and Sara McCormick for technical support in the data analysis of the reading survey. The first author acknowledges the support of the John Metcalfe Visitor's Grant awarded to Dr. Carol Tenopir. Finally, we thank the reviewers for their helpful comments.
References

    Top of page
    Abstract
    Introduction
    Methodology
    Results and Discussion
    Conclusion
    Acknowledgements
    References

    Bergman, S.S. ( 2006 ). The scholarly communication movement: Highlights and recent developments . Collection Building , 25 ( 4 ), 108 – 128 .
        CrossRef
    Gooden, A.M. ( 2001 Fall ). Citation analysis of chemistry doctoral dissertations: An Ohio State University case study . Issues in Science and Technology Librarianship. Retrieved May 7, 2007, from http://www.istl.org/01-fall/refereed.html
    Hood, W.W. , & Wilson, C.S. ( 2003 ). Informetric studies using databases: Opportunities and challenges . Scientometrics , 58 ( 3 ), 587 – 608 .
        CrossRef ,
        CAS ,
        Web of Science® Times Cited: 26
    Kennan, M.A. ( 2007 ). Academic authors, scholarly publishing, and open access in Australia . Learned Publishing , 20 ( 2 ), 138 – 146 .
        CrossRef ,
        Web of Science® Times Cited: 1
    Kraus, J.R. ( 2005 Summer ). Comparing journal use between biology faculty and undergraduate students . Issues in Science and Technology Librarianship. Retrieved May 7, 2007, from http://www.istl.org/05-summer/article2.html
    LaBonte, K.B. ( 2005 Summer ). Citation analysis: A method for collection development for a rapidly developing field . Issues in Science and Technology Librarianship. Retrieved May 7, 2007, from http://www.istl.org/05-summer/refereed.html
    Nicholas, D. , Huntington, P. , & Rowlands, I. ( 2005a ). Open access journal publishing: the views of the world's most senior authors . Journal of Documentation , 61 ( 4 ), 497 – 519 .
        CrossRef ,
        Web of Science® Times Cited: 11
    Nicholas, D. , Jamali, H.H.R. , Huntington, P. , & Rowlands, I. ( 2005b ). In their very own words: Authors and scholarly journal publishing . Learned Publishing , 18 ( 3 ), 212 – 220 .
        CrossRef ,
        Web of Science® Times Cited: 5
    Nicholas, D. , & Rowlands, I. ( 2005 ). Open access publishing: the evidence from the authors . Journal of Academic Librarianship , 31 ( 3 ), 179 – 181 .
        CrossRef ,
        Web of Science® Times Cited: 4
    Schloegl, C. , & Stock, W.G. ( 2004 ). Impact and relevance of LIS journals: A scientometric analysis of international and German-language LIS journals—Citation analysis versus reader survey . Journal of the American Society for Information Science and Technology , 55 ( 113 ), 1155 – 1168 .
    Direct Link:
        Abstract
        Full Article (HTML)
        PDF(138K)
        References
        Web of Science® Times Cited: 17
    SCI-Bytes . ( 2006 ). Australian universities: Most prolific in engineering, 2001–05 . Thomson Scientific. Retrieved May 7, 2007, from http://in-cites.com/research/2006/september_18_2006-2.html
    Sinn, R.N. ( 2005 ). A local citation analysis of mathematical and statistical dissertations . Science & Technology Libraries , 25 ( 4 ), 25 – 37 .
        CrossRef ,
        PubMed
    Tenopir, C. , & King, D.W. ( 2000 ). Towards electronic journals: Realities for scientist, librarians and publishers (p. 488 ). Washington, DC : Special Libraries Association.
    Tenopir, C. , & King, D.W. ( 2004 ). Communication patterns of engineers . NY : IEEE/Wiley Interscience.
    Tenopir, C. , King, D.W. , Clarke, M.T. , Na, K. , & Zhou, X. ( 2007 ). Journal reading patterns and preferences of pediatricians . Journal of the Medical Library Association , 95 ( 1 ), 56 – 63 .
        PubMed ,
        Web of Science® Times Cited: 11
    Tenopir, C. , Zhou, X. , & King, D.W. ( 2006, February 1 ). University of New South Wales academic staff journal reading patterns . Unpublished revised report 2006, p. 66.
    University of New South Wales . ( 2003 ). The University of New South Wales 2003 statistics book . Statistics for information and planning . Sydney : University of New South Wales. Retrieved May 7, 2007, from http://www.planning.unsw.edu.au/statisticsdocs/stats_book_03.pdf
    University of New South Wales . ( 2006 ). The UNSW library's collection development policy . Retrieved May 7, 2007, from http://info.library.unsw.edu.au/monos/pdf/collectiondevpolicy082006.pdf
    Wilson, C.S. , & Osareh, F. ( 2003 ). Science and research in Iran: A scientometric study . Interdisciplinary Science Reviews , 28 ( 1 ), 26 – 37 .
        CrossRef ,
        Web of Science® Times Cited: 5

Get PDF (598K)
More content like this
Find more content:

    like this article

Find more content written by:

    Concepción S. Wilson
    Carol Tenopir
    All Authors

    Publications
    Browse by Subject
    Resources

    About Us
    Help
    Contact Us
    Agents
    Advertisers
    Media
    Privacy
    Cookies
    Terms & Conditions
    Site Map

Copyright © 1999-2014 John Wiley & Sons, Inc. All Rights Reserved.

    About Wiley
    Wiley.com
    Wiley Job Network
    Wiley

