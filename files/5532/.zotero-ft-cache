
Engaging Science, Technology, and Society

Founding Editor

 Daniel Lee Kleinman  


Managing Editor  

 Katie Vann  


Editorial Board

 Elizabeth Popp Berman  

 Wiebe Bijker  

 Tania Pérez-Bustos  

 Charles Camic  

 Nancy Campbell  

 Jennifer Croissant  

 Jason Delborne  

 John Downer  

 Steve Epstein  

 Kristen Eschenfelder  

 Rayvon Fouche  

 Scott Frickel  

 Tarleton Gillespie  

 Edward J. Hackett  

 Saul Halfon  

 Sandra Harding  

 Gabrielle Hecht  

 David Hess  

 Stephen Hilgartner  

 Steve Hoffman  

 Kenji Ito  

 Kelly Joyce  

 Christopher M. Kelty  

 Abby Kinchy  

 Vasilis Kostakis  

 Phil Macnaghten  

 Laura Mamo  

 Leandro Rodriguez Medina  

 Kelly Moore  

 Michelle Murphy  

 Helen Nissenbaum  

 Heather Paxson  

 Shobita Parthasarathy  

 Roopali Phadke  

 Martyn Pickersgill  

 Susan Silbey  

 Sergio Sismondo  

 Johan Söderberg  

 Lucy Suchman  

 Kim TallBear  

 Steve Vallas  

 Roli Varma  

 

  

    The Society for Social Studies of Science  

Follow @eSTSjournal
User
Username 	
Password 	
Remember me
Keywords STS anti-science big data care citizen science democracy evaluation fracking indicators intervention interview knowledge democracy making and doing methods pedagogy permissionless innovation post-truth reflexivity science science and technology studies technological determinism
Article Tools
Print this article
Indexing metadata
How to cite item
Finding References
Review policy
Email this article (Login required)
Email the author (Login required)

Creative Commons License
Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License

Crossref logo

 

ISSN: 2413-8053
Hosted By
Part of the
PKP Publishing Services Network

    Home
    About
    Register
    Current
    Announcements
    FAQ
    Submit
    Archives
    GENRES

Home > Vol 3 (2017) > Fochler
Implicated in the Indicator Game? An Experimental Debate
Maximilian Fochler, Sarah de Rijcke

Abstract

The rise of new modes evaluating academic work has substantially changed institutions and cultures of knowledge production. This has been reflected and criticized in the literature in STS and beyond. For STS scholars, these debates (should) however have an even more specific dimension. Many of us are experts on aspects of these changes. But at the same time, we too are part of the processes we are analyzing, and often criticizing. To put it slightly provocatively, often we cannot avoid playing the very same game that we scrutinize. This creates tensions that many of us reflect on, and it certainly has created many implicit and explicit normative stances on how to deal with them. Yet it seems that so far there has been little room in our field to reflect on and exchange this particular kind of experience-based knowledge. There are many different ways to engage with the dynamics of evaluation, measurement and competition in contemporary academia, or to play what we refer to colloquially here as the “indicator game.” With this debate, we would like to give room to the expression and discussion of some of these ways. This text is the introduction and prompt to an experimental debate. We discuss the state of the academic discussion on the impact of indicator-based evaluation on academic organization, epistemic work and identities. We use insights from these debates to raise questions for how STS and STSers themselves deal with the indicator game. In conclusion, we summarize our contributors’ arguments and propose the concept of “evaluative inquiry” as a new way of representing the quality of STS work in evaluative contexts. 

Keywords

indicators; accountability; intervention; research quality; evaluation; evaluative inquiry

Full Text:
PDF


DOI: https://doi.org/10.17351/ests2017.108

Bookmark and Share


Copyright (c) 2017 Maximilian Fochler, Sarah de Rijcke

Creative Commons License
This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License .

Annotate Highlight 