Who publishes in “predatory” journals? - Xia - 2015 - Journal of the Association for Information Science and Technology - Wiley Online Library

    Skip to Article Content
    Skip to Article Information

By continuing to browse this site, you agree to its use of cookies as described in our Cookie Policy . ×
Access by Universidad De Granada
Association for Information Science &amp; Technology
Association for Information Science &amp; Technology
Access by Universidad De Granada
Search within

    Search term
    Advanced Search Citation Search
    Search term
    Advanced Search Citation Search
    Search term
    Advanced Search Citation Search

Login / Register

    Publications
        Journal of the Association for Information Science and Technology
        Proceedings of the Association for Information Science and Technology
        Bulletin of the Association for Information Science and Technology
        Annual Review of Information Science and Technology
    THESAURUS

Journal of the Association for Information Science and Technology
Volume 66, Issue 7 Journal of the Association for Information Science and Technology banner
RESEARCH ARTICLE
Full Access
Who publishes in “predatory” journals?
Jingfeng Xia

E-mail address: xiaji@iupui.edu

http://orcid.org/0000-0001-5605-4292

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Jennifer L. Harmon

E-mail address: jenjemey@iupui.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Kevin G. Connolly

E-mail address: kevgconn@iupui.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Ryan M. Donnelly

E-mail address: rmdonnel@umail.iu.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Mary R. Anderson

E-mail address: mra4@iupui.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Heather A. Howard

E-mail address: hahoward@butler.edu

Irwin Library, Butler University, Indianapolis, IN, 46208
Search for more papers by this author
Jingfeng Xia

E-mail address: xiaji@iupui.edu

http://orcid.org/0000-0001-5605-4292

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Jennifer L. Harmon

E-mail address: jenjemey@iupui.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Kevin G. Connolly

E-mail address: kevgconn@iupui.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Ryan M. Donnelly

E-mail address: rmdonnel@umail.iu.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Mary R. Anderson

E-mail address: mra4@iupui.edu

Department of Library and Information Science, School of Informatics & Computing, Indiana University, Indianapolis, IN, 46202
Search for more papers by this author
Heather A. Howard

E-mail address: hahoward@butler.edu

Irwin Library, Butler University, Indianapolis, IN, 46208
Search for more papers by this author
First published:  06 November 2014
https://doi.org/10.1002/asi.23265
Citations: 84
About
Sections
ePDF PDF
PDF PDF
Tools

    Request permission
    Export citation
    Add to favorites
    Track citation

Share

Give access
Share full text access

Share full text access
Please review our Terms and Conditions of Use and check box below to share full-text version of article.
I have read and accept the Wiley Online Library Terms and Conditions of Use.
Shareable Link

Use the link below to share a full-text version of this article with your friends and colleagues. Learn more.
Copy URL

Share a link
Share on

    Email
    Facebook
    Twitter
    LinkedIn
    Reddit

Abstract

Many open access journals have a reputation for being of low quality and being dishonest with regard to peer review and publishing costs. Such journals are labeled “predatory” journals. This study examines author profiles for some of these “predatory” journals as well as for groups of more well‐recognized open access journals. We collect and analyze the publication record, citation count, and geographic location of authors from the various groups of journals. Statistical analyses verify that each group of journals has a distinct author population. Those who publish in “predatory” journals are, for the most part, young and inexperienced researchers from developing countries. We believe that economic and sociocultural conditions in these developing countries have contributed to the differences found in authorship between “predatory” and “nonpredatory” journals.
Introduction

A report published by Science in early October, 2013, triggered intense discussion among scholars and publishers on the issue of open access (OA) publishing and quality control (Bohannon, 2013 ). Bohannon, the author of this report, conducted an experiment by submitting a fabricated article with a deliberately flawed research design to a group of more than 300 selected OA journals. He wanted to check wehether the article would pass what some individuals believe to be a lax peer‐review process for many OA journals. The results supported the author's presumption, because more than half of the journals accepted the article and failed to notice or address the intentional flaws.

In recent years, we have seen the creation and growth of many OA journals. Various forms of publishing practices have been adopted. Some newly created OA journals lack transparency and do not identify an editorial board. Many require considerable article processing charges for authors. Such journals are considered to be primarily interested in making quick money and paying little or no attention to peer review (Beall, 2012a ). Jeffrey Beall, at the University of Colorado Denver library, has called these “predatory” journals and has maintained a list of hundreds of such journals based on his set of criteria. His goal is to raise awareness of dishonest publishing practices.

Although there has been much discussion about the definition of “predatory” journals (Anderson, 2012 ; Poynder, 2013 ), it is clear that the quality of OA journals varies considerably. Many journals, including the ones on Beall's list, demonstrate low standards for article acceptance. Ideally, one would determine the merit of these journals by assessing the quality of their articles, but such an evaluation would be difficult to implement and could easily become too subjective. Instead, we choose to examine author profiles of these “predatory” journals, concentrating on their publication and citation histories and geographic location. We selected seven journals from Beall's “predatory” journal list in the area of biomedical science, collecting data for a total of 324 articles and 941 authors. We also consulted the Web of Science for each author's total number of publications and citations as an indicator of academic reputation. The data set was then compared with that of authors in various groups of other OA journals. One group includes journals that rejected Bohannon's fake article and are not listed by Beall; another group includes journals with recognized prestige as indicated by their high journal impact factors. The purpose of this study is to determine whether the different groups of OA publications have attracted different types of authors; in other words, can author profiles indicate the scholarly standards of OA journals.
Background

There are very few scholars who have not received e‐mail spam from new OA journals and conferences attempting to recruit articles or solicit participation, often containing invitations to participate in the journal's review or become members of the journal's editorial team. Some OA publishers have been so aggressive in their marketing efforts that scholars may easily become overwhelmed by the frequency of such e‐mails and, as a consequence, may grow skeptical about OA publishing. Beall began investigating OA publishers and created a blacklist of what he calls “predatory” journals and publishers that are considered to be dishonest and of low quality. Journals that are included on Beall's list may be known to accept submissions quickly with little peer review, publish hoax or nonsensical papers, require a processing fee after a publishing agreement is signed, appoint fake scholars to the editorial board, and mimic the name of a more well‐recognized journal.

Bohannon, a journalist for Science , took a different route to verifying the quality of OA publishing. He used a false name and fictitious institution to submit 304 copies of a paper about a “wonder drug” to selected OA journals, but the paper itself contained an experimental design “so hopelessly flawed that the results are meaningless” (Bohannon, 2013 , p. 60). At the time of publication of his study in Science , Bohannon's flawed paper had been accepted 157 times and rejected 98 times. His other submissions were either still under review or had yet to receive a response. Among the 255 acceptances and rejections, 60% did not show any evidence of peer review; among those that did, not all of the peer review focused on the scientific soundness of the bogus study.

Bohannon's research received immediate attention and criticism in the media. Many blog entries started discussing the report as soon as it became available, attracting hundreds of responses (e.g., Eisen, 2013 ; Taylor, Wedel, & Naish, 2013 ). Although many people supported his “sting operations” on potentially dishonest OA publishers, some criticized his methods or arguments or the ethicality of his conduct.

Bohannon's experiment, like his fabricated paper, did not include a control group. He targeted OA journals without bringing subscription‐based journals into the study. Lax control of publication quality is not unique to OA; rather, it is a problem that has been in existence in scholarly communication for a long time (Bornmann, 2011 ; Lee, Sugimoto, Zhang, & Cronin, 2013 ). In fact, as early as 1996, Alan Sokal conducted a similar test, known as the Sokal Affair, by submitting a questionable article to Social Text , a leading scholarly journal in the United States in the area of postmodern cultural studies (Sokal, 1996a ). On the date of the article's publication, Sokal indicated that the article was a hoax (Sokal, 1996b,c ). There have also been a number of comparable experiments on non‐OA journals as well as OA journals (see en.wikipedia.org/wiki/Sokal_affair;scholarlyticken.org ; Gilbert, 2009 ; Peters & Ceci, 1982 ).

Bohannon equated low‐quality OA publications with open access in general in his argument. However, his approach to data collection is debatable because only OA journals charging a processing fee were included in the experiment. Peter Suber points to the fact that as many as 70% of journals listed in the Directory of Open Access Journals (DOAJ) in 2013 charged no author‐side fees at all (Suber, 2006 , 2013 ). Bohannon's discussion also contradicts itself in that it provides proof that some fee‐based OA journals, such as PLoS One , did conduct rigorous peer review and rejected his bogus paper.

He received further criticism on an ethical basis because authors are required to guarantee their submission represents a true scientific study. This argument appears to come from irritated publishers who did not appreciate being tricked by Bohannon and the journal Science that backed and published the study (Oransky, 2013 ).

Disagreements aside, nobody denies that there are indeed many weak and disreputable journals. Those dishonest journals have contributed to some individuals having doubts about the reputation of the OA field. Through tracing the Internet protocol (IP) addresses of journal editors and the location of their bank accounts, Bohannon ( 2013 ) found that many of the journals accepting his fake article were based in developing countries, particularly India. Four major geographical clusters of “predatory” publishers were found in India, Nigeria, the U.S., and the U.K. A common practice has emerged in which many such OA publications are run in India with branches in the latter two countries. Journals without rigorous quality control are especially harmful for developing countries “where governments and universities are filling up with people with bogus scientific credentials,” according to Ginsparg, founder of the physics e‐print repository arXiv (cited from Bohannon, 2013 , p. 65). Sociocultural and economic factors have played an important role in the geographic formation of this “predatory” OA publishing.

Young researchers and doctoral students in these developing countries are considered to be the major victims of predatory journals, a problem catalyzed by an increasing pressure for them to “publish or perish” (Shaw, 2013 ). They are anxious to expand their publication list and become recognized by the academic community and are therefore easily attracted by the quick and easy publishing model that these OA journals offer. Presumably, many authors who publish in these dubious “new ‘pay big, publish fast’ e‐journals are younger scholars based in the Global South and particularly in the Muslim world” (Truth, 2012 , p. 56).

Very few scientific studies have examined “predatory” journals, although there have been informal discussions about this topic on personal blogs (e.g., Taylor et al., 2013 ). Fewer, if any, scientific studies have been conducted to investigate the background of authors of OA journal articles. Our current project on OA authorship in predatory journals will shed light on the issues relating to journal quality control and scholar involvement in making contributions to weak and dishonest journals and will help the academic community to refine its culture in response to the changing environment of scholarly communication. We study the background variables of those authors who publish in journals that require publication fees so that the findings can be compared with what Bohannon discovered. However, we take a further step to improve our research design by introducing comparable groups, namely, authors from established OA journals that also charge author fees, including journals rejecting Bohannon's fake paper and journals with high status from the PLoS series.

Based on the existing observations and arguments, we present the following hypotheses:

1. Hypothesis One: There is no difference in author profiles, regarding their publication and citation history, between the various groups of OA journals if these journals all employ an author‐fee model.

2. Hypothesis Two: There is no difference in author profiles, regarding their geographic location, between the various groups of OA journals if these journals all employ an author‐fee model.

Research Design
Data Collection

We selected a group of 68 journals from Beall's predatory journal list to represent low‐quality publications in various areas of biomedical science, primarily pharmaceutical science, which is comparable to the subject of Bohannon's false study. We chose to investigate biomedical science because (a) open access has been an established practice among biomedical scientists, (b) many biomedical projects are sponsored by grants that could fund OA publishing, making an author‐pay model possible and popular, and (c) there are some recognized biomedical journals with the same or similar publishing models that can be used for the purpose of comparison. Among these 68 journals, 7 journals were selected for data collection of author profiles because of their focus on pharmaceutical science according to the titles (Table  1 ). We call this group 1.
Table 1. Journals selected for the study: Group 1 “predatory” journals, group 2 journals rejecting Bohannon's false paper
	Journal 	Article count 	Author count 	Frequency 	First issue 	Location a Note. a Location refers to the location of journal editor.
	Per paper b b Per paper values are presented in U.S. dollars for the sake of comparison. Currency conversions were calculated in early January, 2014.
Group 1 	American Journal of Pharmacy and Health Research (AJPHR) 	48 	102 	Monthly 	Apr, 2013 	India 	16 (50) c c The first amount is for a local submission or a submission from selected developing countries; the amount in parentheses is for a submission from the West.
Indian Journal of Pharmaceutical and Biological Research (InJPBR) 	34 	70 	Quarterly 	Jan–Mar, 2013 	India 	12 (40) c c The first amount is for a local submission or a submission from selected developing countries; the amount in parentheses is for a submission from the West.
International Journal of Life science and Pharma Research (IJLSPR) 	26 	65 	Quarterly 	Oct–Dec, 2011 	India 	Unknown
International Journal of Medical Sciences and Health Care (IJMSHC) 	19 	69 	Monthly 	Jan, 2013 	U.S. 	200
International Journal of Pharmaceutical and Biomedical Research (IJPBR) 	42 	139 	Quarterly 	Jan–Mar, 2010 	U.K. 	Unknown
International Journal of Pharmaceutical Sciences and Drug Research (IJPSDR) 	24 	96 	Quarterly 	Apr–Jun, 2009 	India 	16
International Journal of Pharmacy (IJP) 	131 	400 	Quarterly 	2011 	Turkey 	33 (225) c c The first amount is for a local submission or a submission from selected developing countries; the amount in parentheses is for a submission from the West.
Group 2 	British Journal of Pharmaceutical Research (BJPR) 	84 	327 	Quarterly 	Jan, 2011 	India 	500
Cancer Growth and Metastasis (CGM) 	5 	11 	Rolling 	2008 	U.S. 	1,699
Clinical and Molecular Hepatology (CMH) 	24 	145 	Quarterly 	1995 	Korea 	Unknown
Drugs and Therapy Studies (DTS) 	5 	22 	Rolling 	2011 	Sweden 	272
Frontiers in Pharmacology of Anti‐Cancer Drugs (PACD) 	47 	229 	Monthly 	Sept, 2010 	Switzerland 	2,176 d d This amount is for a regular submission of most types of research papers.
Total 		489 	1,675 				

    Note. a Location refers to the location of journal editor.
    b Per paper values are presented in U.S. dollars for the sake of comparison. Currency conversions were calculated in early January, 2014.
    c The first amount is for a local submission or a submission from selected developing countries; the amount in parentheses is for a submission from the West.
    d This amount is for a regular submission of most types of research papers.

To make the comparisons, two other groups of OA journals were also selected. One group includes journals that rejected Bohannon's fake paper (Table  1 ). Other criteria used to select these journals are (a) journals have a substantial review process according to Bohannon, (b) journals require author payment, (c) journals in the same biomedical areas, and (d) journals have registered with the DOAJ but are not on Beall's list. The DOAJ aims to “cover all open access scientific and scholarly journals that use a quality control system to guarantee the content” ( doaj.org/about ). Although these journals have not been rated by popular bibliometric tools such as Journal Citation Reports by Thomson Reuters or SCImago Journal & Country Rank , we consider them to be more rigorous in peer review and to represent better quality than the predatory journals in group 1. In total, five journals were selected for the study. Note that the location data in the tables are for journal editors, which is consistent with Bohannon's study. We call this group 2.

The other group contains high‐status journals from the PLoS series. PLoS (the Public Library of Science) is a nonprofit publisher, with its journals establishing OA “as an effective and sustainable way to share the latest and best research with everyone” ( http://www.plos.org/about/plos ). Since October, 2003, PLoS has launched seven journals, all of which have been widely accepted as high‐quality publications. Their impact factor and h‐index values, as shown in Table  2 , indicate the popularity of the journals in the scientific world. Among these seven PLoS journals, two were removed from our study ( PLoS Computational Biology and PLoS One ) because of their wide coverage of research subjects. These journals all charge publication fees to authors, and the cost per article is very high (Table  2 ). We call this group 3.
Table 2. Group 3: Selected PLoS journals and their rankings by impact factor and h‐index (Sources: Journal Citation Reports , Thomson Reuters; SCI mago Journal &   C ountry   R ank ; and PLoS)
Journal 	Impact fact 	h‐index 	Per paper
PLoS Biology 	12.69 	133 	$2,900
PLoS Medicine 	15.253 	105 	$2,900
PLoS Computational Biology 	4.867 	72 	$2,250
PLoS Genetics 	8.517 	93 	$2,250
PLoS Pathogens 	8.136 	78 	$2,250
PLoS neglected tropical diseases 	4.963 	40 	$2,250

Aside from the PLoS journals, data for all research articles published in 2013 were collected in a spreadsheet, resulting in a total of 324 articles for group 1 and 165 articles for group 2. The data for every author of these articles were manually entered into the spreadsheet, including the author's full name, institutional affiliation, geographical location, academic status, and corresponding authorship. In total, 1,821 authors were collected (group 1 = 1,047 and group 2 = 774). After removal of duplicates, the final number of authors was 1,675 (group 1 = 941 and group 2 = 734).

Next, we searched for each author's publications and citations in the Web of Science, with the results being further refined by the research area of biomedical science only. In other words, even if an author had published in multiple disciplines, only his publications and citations in biomedical science were counted. Given the specialization of biomedical studies, we believe such a refinement will not result in a significant variation for a researcher's overall academic reputation.

The same data‐collection strategy was applied for authors who published in 2013 in group 3 journals. For this data set, we did not select all articles in 2013 because of the large quantity. Instead, we chose the first issue of each journal, following the data‐collection strategy adopted by Finlay, Ni, Tsou, and Sugimoto ( 2013 ) and stopped data collection when the number of authors reached 300, a number that we believe sufficient for the purpose of comparison. These samples are roughly evenly distributed across all five journals.
Data Analyses

Publication and citation data for authors in the three groups of journals were categorized into strata so that statistical measurements could be conducted. The strata have intervals of 5, namely, “0,” “1–5,” “6–10,” “11–15,” “16–20,” “21–30,” and “30+,” according to the nature of the data distribution. The numbers of publications are stratified independently of the numbers of citations.

The χ 2 test of independence was selected for the analyses in order to evaluate whether paired observations on variables, expressed in a contingency table, are independent of each other between group 1 and group 2 journals and between group 2 and group 3 journals. Known also as the test of homogeneity, the test of independence seeks an χ 2 probability of less than or equal to 0.05 to reject a null hypothesis that row variable is independent of column variable. To make reliable statistical tests, we used randomly selected samples and paid special attention to the size of the samples so that no more than 25% of the cells in the contingency table for our χ 2 calculations have a value lower than 5. This sample size justification made it impossible for us to run statistical analysis against data for journals within a group. For example, we were unable to compare the difference of author profiles among the seven predatory journals. Our χ 2 analyses below are all intergroup comparisons, which is exactly what we need for this study.
Limitations

We recognize the complexity of authorship (Cronin, 2005 ), particularly in the area of biomedical research. Biomedical papers often contain many coauthors who make varying degrees of contribution. In some cases, a doctoral student, who will need first‐authored articles to compete for employment, is listed as the first author of an article even though his academic advisor initiated and contributed to the research. As a result, analyses at the level of all individual authors might not paint an accurate picture of authorship. Therefore, we conducted additional analyses by applying χ 2 calculations against the corresponding authors as a subset of our existing data.

The sample size of this research is relatively small, particularly for the comparison groups. This small size limits our analyses on the data within any group of journals. Although the limitation will not affect intergroup comparisons in this case, future studies may expect to examine more features of OA journal publishing by expanding sample size.
Analyses
All Authors

For an χ 2 analysis at the level of individual authors, Tables  3 and 4 provide counts of articles by author from the three groups of journals. A statistical analysis at the individual journal level is impossible because of the small numbers in some strata. Table  4 does not show strata at the journal level, also because of the size of the data. The total numbers of each group, rather than journal numbers, are used for the following calculations.
urn:x-wiley:23301635:media:asi23265:asi23265-math-5001
urn:x-wiley:23301635:media:asi23265:asi23265-math-5002
urn:x-wiley:23301635:media:asi23265:asi23265-math-5003

Table 3. Group 1 and 2 journals by number of authors in various publication strata (journal title acronyms are given in Table  1 )
	Journal 	0 	1–5 	6–10 	11–15 	16–20 	21–25 	26–30 	30+ 	Total
Group 1 	AJPHR 	81 	16 	2 	2 	1 	0 	0 	0 	102
InJPBR 	43 	18 	3 	2 	1 	0 	1 	2 	70
IJLSPR 	42 	17 	3 	0 	1 	1 	0 	1 	65
IJMSHC 	44 	18 	4 	0 	0 	2 	0 	1 	69
IJPBR 	98 	41 	0 	0 	0 	0 	0 	0 	139
IJPSDR 	56 	23 	5 	2 	5 	1 	0 	4 	96
IJP 	249 	90 	46 	2 	0 	0 	3 	10 	400
Total 	613 	223 	63 	8 	8 	4 	4 	18 	941
Group 2 	BJPR 	80 	127 	64 	24 	0 	16 	0 	16 	327
CGM 	2 	4 	2 	0 	2 	1 	0 	0 	11
CMH 	19 	36 	8 	6 	10 	16 	10 	40 	145
DTS 	4 	4 	2 	1 	2 	1 	2 	6 	22
PACD 	36 	85 	36 	18 	9 	5 	0 	40 	229
Total 	141 	256 	112 	49 	23 	39 	12 	102 	734
Overall total 	  	754 	479 	175 	57 	31 	43 	16 	120 	1,675
Table 4. Group 3 journals by number of authors in various publication strata
Journal 	0 	1–5 	6–10 	11–15 	16–20 	21–25 	26–30 	30+ 	Total
PLoS Journals 	16 	108 	52 	36 	13 	20 	3 	52 	300

The χ 2 test of independence indicates significant differences in the publication records of authors between group 1 and group 2 journals. The differences reject our first hypothesis. In other words, we are 95% confident that authors of these two groups have different academic reputations. The same interpretation is given to the χ 2 test between groups 2 and 3. The testing result also indicates that PLoS authors are significantly different from group 2 authors based on their publication history. Similarly, the third χ 2 test serves as supplemental evidence to support the former two sets of calculations. Differences are found among these three groups of authors.

The χ 2 model is able to test whether there is a statistical significance in data by comparing whether the variation in a set of data is due to chance or to one of the variables being tested. Although it is very powerful and useful for scientific research, the χ 2 test does not provide necessary information about the reasons for the significance or lack thereof. To understand the author profiles better, we create a simple histogram visualization to check whether certain patterns in the authorship can be detected.

Figure  1 is self‐explanatory and illustrates an obvious contrast in author publication records between the two groups. The majority of authors who publish in predatory journals have no other publications, whereas the second largest group consists of authors with fewer than five journal publications elsewhere; very few authors have published more than 10 articles. In contrast, the histogram reveals that group 2 authors, those who publish in OA journals that have a robust review process and subsequently rejected Bohannon's false submission, generally have a stronger publication record. With the exception of a few new authors, most group 2 authors have published journal articles previously; in fact, some authors have published more than 30 articles.
figure
Figure 1
Open in figure viewer PowerPoint

Comparison of journal groups by number of authors in various publication strata. [Color figure can be viewed in the online issue, which is available at wileyonlinelibrary.com .]

We attempted to examine the academic status of group 1 authors further, but the data are incomplete because many journals, particularly predatory journals, do not provide their authors' academic rank. A Google search is not helpful because the majority of these authors do not have a personal webpage, and their institutional websites are, more often than not, too poorly designed to provide the information. From the data we collected, there seems to be an indication that young researchers, including doctoral students and assistant professors, have fewer publications than authors with the title professor. However, the data are insufficient to support the assertion statistically.

Citation counts for the strata are listed in Tables  5 and 6 . Table  6 has the citation counts by author for the entire group 3. A similar χ 2 test was taken for the citation counts. The results confirm the aforementioned test for publication history and reject our first hypothesis, again at the significant level of 0.05. From this testing result, we are confident there are significant differences in citations among authors of the different groups.
urn:x-wiley:23301635:media:asi23265:asi23265-math-5004
urn:x-wiley:23301635:media:asi23265:asi23265-math-5005
urn:x-wiley:23301635:media:asi23265:asi23265-math-5006

Table 5. Group 1 and 2 journals by number of authors in various citation strata (journal title acronyms are given in Table  1 )
	Journal 	0 	1–5 	6–10 	11–15 	16–20 	21–25 	26–30 	30+ 	Total
Group 1 	AJPHR 	84 	14 	0 	2 	0 	0 	0 	2 	102
InJPBR 	55 	8 	2 	2 	1 	0 	0 	2 	70
IJLSPR 	47 	9 	1 	1 	0 	0 	3 	4 	65
IJMSHC 	50 	7 	1 	1 	2 	4 	3 	1 	69
IJPBR 	99 	11 	6 	2 	1 	0 	3 	17 	139
IJPSDR 	64 	11 	2 	2 	1 	1 	0 	15 	96
IJP 	270 	52 	14 	16 	7 	5 	11 	25 	400
Total 	669 	112 	26 	26 	12 	10 	20 	66 	941
Group 2 	BJPR 	114 	74 	25 	9 	16 	16 	16 	57 	327
CGM 	3 	2 	0 	0 	1 	0 	0 	5 	11
CMH 	39 	12 	8 	2 	3 	3 	1 	77 	145
DTS 	4 	1 	1 	1 	1 	0 	0 	14 	22
PACD 	44 	18 	4 	18 	4 	18 	13 	110 	229
Total 	204 	107 	38 	30 	25 	37 	30 	263 	734
Grand Total 		873 	219 	64 	56 	37 	47 	50 	329 	1,675
Table 6. Group 3 journals by number of authors in various citation strata
Journal 	0 	1–5 	6–10 	11–15 	16–20 	21–25 	26–30 	30+ 	Total
PLoS Journals 	16 	44 	21 	10 	10 	8 	3 	188 	300

We then followed this procedure to create a histogram for group 1 and group 2 (Figure  2 ). The data show much stronger evidence that authors who publish in group 2 journals have accumulated more extensive citations than authors in the group 1 journals. The largest number of citations falls in the stratum “30+” for group 2 authors, whereas most group 1 authors still have not received any citations.
figure
Figure 2
Open in figure viewer PowerPoint

Comparison of journal groups by number of authors in various citation strata. [Color figure can be viewed in the online issue, which is available at wileyonlinelibrary.com .]
Corresponding Authors

Because of the complexity of coauthorship in biomedical sciences, corresponding authors may not be the first author (Riesenberg & Lundberg, 1990 ; Shapiro, Wenger, & Shapiro, 1994 ), yet we believe that they usually play an important role and typically make intellectual contributions to a study. Most importantly, they may be the most senior researcher of a group and decide where to submit a research article. Their publication history may offer important information in understanding why a particular OA journal is selected, or, in other words, what relationship may exist between the status of a journal and its authorship. Because many journals in our samples have a limited number of articles and corresponding authors, we will not present data for individual journals (Tables  7 and 8 ). There are some variations in the data; for example, certain articles have more than one corresponding author, and some articles are shared by the same corresponding authors. These variations, however, are few and will not affect our test at the group level. The following χ 2 testing results also reject our first hypothesis and show significant differences among authors of the different groups.
urn:x-wiley:23301635:media:asi23265:asi23265-math-5007
urn:x-wiley:23301635:media:asi23265:asi23265-math-5008

Table 7. Group 1 and 2 journals by number of corresponding authors in various publication strata
	0 	1–5 	6–10 	11–15 	16–20 	21–25 	26–30 	30+ 	Total
Group 1 journals 	204 	83 	23 	6 	2 	0 	0 	6 	324
Group 2 journals 	13 	28 	32 	6 	19 	13 	16 	38 	165
Total 	217 	111 	55 	12 	21 	13 	16 	44 	489
Table 8. Group 1 and 2 journals by number of corresponding authors in various citation strata
	0 	1–5 	6–10 	11–15 	16–20 	21–25 	26–30 	30+ 	Total
Group 1 Journals 	233 	41 	12 	6 	2 	5 	10 	15 	324
Group 2 Journals 	15 	15 	11 	4 	7 	4 	8 	101 	165
Total 	248 	56 	23 	10 	9 	9 	18 	116 	489

Figures  3 and 4 demonstrate different patterns of publication and citation distributions across the strata for authors in each group. We especially note the considerable citation counts in the stratum “30+” for authors in group 2 (Figure  4 ). Evidently, the corresponding authors in group 2 have received far more citations than those in group 1.
figure
Figure 3
Open in figure viewer PowerPoint

Comparison of journal groups by number of corresponding authors in various publication strata. [Color figure can be viewed in the online issue, which is available at wileyonlinelibrary.com .]
figure
Figure 4
Open in figure viewer PowerPoint

Comparison of journal groups by number of corresponding authors in various citation strata. [Color figure can be viewed in the online issue, which is available at wileyonlinelibrary.com .]
Author Geographic Locations

In total, 23 countries are represented in the selected predatory journals of group 1 (Table  9 ). Most authors are concentrated in a few countries, such as India (725), Nigeria (80), and Pakistan (44). This is in contrast to authors in group 2, who are mostly from Korea (438), the U.S. (76), and Italy (59). Authors in the PLoS journals of group 3 are mainly from the U.S. (142), the U.K. (62), and Australia (26). Some authors provide multiple locations, which is especially common in the PLoS journals. For authors with multiple countries listed, we read the section “About the Authors” and used the first affiliation of the author as his country.
Table 9. Geographic location of authors
	Author country
Group 1 	Algeria, Bangladesh, Brazil, Cameroon, Egypt, Ethiopia, India, Indonesia, Iran, Italy, Kenya, Lebanon, Malaysia, Malta, Mexico, Morocco, Nepal, Nigeria, Pakistan, Saudi Arabia, Thailand, U.A.E., U.K.
Group 2 	Australia, Brazil, Canada, Egypt, Germany, India, Italy, Korea, Nigeria, Switzerland, U.S.
Group 3 	Australia, Canada, China, France, Germany, Italy, Nigeria, Switzerland, Tanzania, Uganda, U.K., U.S.

Each group of journals shows a distinct pattern in the geographic locations of the authors. For example, authors from Southeast Asian countries are found extensively in group 1 but are absent in groups 2 and 3. Because of varying sample sizes, we categorized all countries by region and calculated percentages for each region. Figure  5 is a visual presentation of the percentages. Authors in each group are clustered in different geographic regions, for example, group 1 authors are mainly in South Asia and Africa, Group 2 authors are mostly in East Asia, and Group 3 authors are largely in North America and Europe.
figure
Figure 5
Open in figure viewer PowerPoint

Comparison of journal groups by geographic location of authors. [Color figure can be viewed in the online issue, which is available at wileyonlinelibrary.com .]

To conduct an χ 2 analysis, we reclassify the numbers so that zeroes can be removed. In the reclassification, the Middle East, which is not present in groups 2 and 3 at all, is merged into Africa; Southeast Asia, which is not found in groups 2 and 3, is combined with East Asia; and South America, which contains Brazil only and is presented merely in group 2, is combined with North America to become Americas (Tables  10 and 11 ).
Table 10. Comparison of journal groups by location of authors in percentage
	Group 1 	Group 2 	Group 3
Africa 	0.14 	0.08 	0.04
Australia 	0.00 	0.01 	0.09
Europe 	0.01 	0.10 	0.33
E Asia 	0.00 	0.57 	0.03
S Asia 	0.75 	0.07 	0.00
SE Asia 	0.03 	0.00 	0.00
N America 	0.03 	0.16 	0.51
S America 	0.00 	0.01 	0.00
Middle East 	0.04 	0.00 	0.00
Total 	1.00 	1.00 	1.00
Table 11. Comparison of journal groups by location of authors in number
	Group 1 	Group 2 	Group 3
Africa 	189 	61 	13
Australia 	0 	7 	25
Europe 	14 	76 	98
E Asia 	29 	438 	10
S Asia 	784 	57 	1
Americas 	31 	135 	153
Total 	1,047 	774 	300

The χ 2 tests of independence indicate significant differences in author geographic origin among the groups. All three tests at the significance level of 0.05 reject our second hypothesis that there is no difference in author profiles with regard to geographic location, among the various groups of OA journals. The results are consistent with our casual observation in Figure  5 .
urn:x-wiley:23301635:media:asi23265:asi23265-math-5009
urn:x-wiley:23301635:media:asi23265:asi23265-math-5010
urn:x-wiley:23301635:media:asi23265:asi23265-math-5011

There is another difference among the three groups regarding the geographic location of multiple authors. In group 1, when the primary or corresponding author of an article is not from a developed country, which is standard, other coauthors are typically also not from developed countries. For group 3 journals, research collaborations between developing and developed countries are common. Group 2 falls between these two groups.
Discussion

Bohannon assumed that OA journals were dishonest and of low quality. He attempted to prove this and focused discussion in his Science paper on the negative aspects of OA publishing. The fact is that, although 60% of the OA journals accepted his false research, 40% of OA journals also rejected the article. He did not pay attention to different OA practices but instead singled out the validity of Beall's judgment for being “good at spotting publishers with poor quality control” (Bohannon, 2013 , p. 64).

We utilize Bohannon's results, not his conclusions, to stratify the OA journals for author profiles with the purpose of making statistical comparisons. Our analyses cannot reveal the level of quality of articles or journals, yet we are able to discover significant differences among various groups of OA journals with regard to authors' publication and citation histories. One of our findings is that authors who publish in so‐called predatory journals have little to no history of previous publications and citations. This may indicate that they are young researchers, which is indeed supported by the author information.

Both Bohannon's study and Beall's criteria for filtering predatory journals, as well as numerous blog posts on similar subjects, have discussed OA practices from a publisher's perspective. OA contributors have been largely ignored in this discussion. Knowing who publishes in predatory journals will be useful. Our data, for both corresponding authors and other coauthors, indicate that these researchers are young, inexperienced, and often located in developing countries. The fact that they have paid various amounts in article processing charges to publish their articles in new and low‐prestige OA journals signifies their eagerness to build publication records. We believe that sociocultural and economic conditions in the countries where most of these authors reside have played a critical role in shaping the authorship landscape.

Let us look at the two countries with the most authors who publish in predatory journals. In India, a long‐standing digital divide has created an imbalance of information access and dissemination within the scholarly community (Ghosh & Das, 2007 ). A rapid growth of the economy has helped construct necessary facilities for elite institutions and universities to support research and teaching in recent years, but other institutions have been struggling to amass new technologies and research sponsorship. There has been a shortage of platforms to fulfill the demands of scholarly publishing. The publishing market is traditionally not a huge economic entity in many developing countries, which has given OA initiatives sufficient space to expand in these areas. As the second most populous nation in the world, India has about 300 universities and nearly the same amount of government‐funded research laboratories, yet its research output in science and technology, according to the Web of Science, was only about 2.5% of the world's journal literature in 2006 (Arunachalam, 2006 ). In a geographic analysis of scholarly publishing, Haider ( 2006 ) found that India was ranked 12th in general journal publishing and 18th in publishing of online content among the top 25 publishing countries. By 2008, India was ranked fifth in OA journal publishing, with a total of 150 OA journals (Nazim & Devi, 2008 ). For researchers and scholarly publishers, “there are enormous rewards of sheer recognition and access to a broad and diverse audience; these factors overcome economic and financial inhibitions to publish on the web with open access” (Abraham & Minj, 2007 ).

The expansion of OA journal publishing in India has been very rapid since then. Today, India is ranked 10th in number of papers and 16th in number of citations according to SCImago Journal & Country Rank ( http://www.scimagojr.com/countryrank.php ), and the country is ranked fourth in OA journal publishing, with 593 OA journals appearing in DOAJ and 604 OA journals according to Ulrichsweb.

The condition of scholarly publishing in Nigeria can also help explain why so many inexperienced authors choose easy‐to‐publish OA journals. Research in Nigeria has been strongly recommended for advancement in academia and other research institutions (Adomi & Mordi, 2003 ; Mordi, 2002 ). Many Nigerian universities and research institutions require their staff to publish a specific proportion of their journal articles in foreign journals as a condition of career advancement. International visibility is considered important to help enhance the reputation of both the researcher and his institution. These requirements can be difficult to fulfill, with the country's longstanding economic and political instability.

Since the 1970s, the quantity and quality of scholarly publishing output in Nigeria have been deteriorating (Olukoju, 2004 ). The virtual collapse of the currency and the devastation caused by military powers and their civilian collaborators has led to a diminished standard of scientific conduct. Several noticeable consequences in scholarship are that (a) publishers have struggled to survive, and production of many reputable journals could not be sustained; (b) scholars have been faced with many distractions, and their focus on scientific studies has waned; and (c) the older generations of scholars “did not produce or hand over to a younger generation of successors” (Olukoju, 2004 , p. 367), creating “a lack of confidence in the ability of the younger generation” (Olukoju, 2004 , p. 367). This latter situation is especially relevant to our finding that great numbers of young Nigerian authors are publishing in the predatory journals. In response to these challenges and pressures, some Nigerian scholars have created “emergency” publications, new journals with minimal quality control that are likely unable to last for more than a few issues. The younger generation of scholars has also developed alternative pay‐to‐publish strategies by collecting monetary contributions from authors to finance publications, a strategy that might have been in practice before the gold OA model. Scholars have also sought sponsorship from social clubs, wealthy individuals, or relevant organizations to support their publications in foreign journals.

The demands stimulate a multiplying of new OA journals, particularly in developing countries. A low submission acceptance standard provides an opportunity for nonelite members of the scholarly community to survive in the “publish‐or‐perish” culture found in both the West and many developing countries. Most of the predatory journals initiated and operated in the developing countries charge a fee affordable to local submissions (see Table  1 ), allowing researchers to publish quickly. Publishing in such journals is much less costly than conducting expensive studies and attempting to publish without fees in a prestigious foreign non‐OA journal. This is by no means only an OA problem but is a prevalent dilemma in the current scholarly communication system. OA publishing is just by chance at the forefront of digital changes and is unfairly blamed. Our statistical tests confirm that OA journals have attracted various levels of authors with regard to the publication and citation history of the authors. We call for reformation of scholarly communication and believe that this restructuring is the best approach for raising the level of OA journal quality and eliminating unprofessional practices.

Many blog entries have suggested possible methods of optimizing the OA publishing market (e.g., Taylor et al., 2013 ). In addition to DOAJ's sustained efforts to maintain a quality‐control system for OA journals, the Open Access Scholarly Publishers Association has promoted “a uniform definition of OA publishing, best practices for maintaining and disseminating OA scholarly communications, and ethical standards” ( oaspa.org/about/mission‐and‐purpose ). Building an audit and reward system will be helpful in creating an environment that promotes higher quality among scholars and OA journals. The American Chemical Society recently did implement such a system on November 1, 2013, by providing a “stimulus program” with monetary credits to encourage authors to publish in its new OA journal (Bernstein, 2013 ). Someone has made a suggestion to Beall to create a white list of “transformed predatory OA publishers” so that “other lower quality predatory OA publishers will learn how to improve (if they really want to do so) and will learn how to get out of Beall's ‘bad list' ” (Khan, 2013 ).

Harnad is among the advocates who propose green OA as a way to raise the level of quality in OA journals ( openaccess.eprints.org ). He has been promoting globally‐mandated policies to require all research outcomes to be self‐archived in digital repositories for free access and use. Such policies are believed to be able to force “journals to adapt naturally to the online era by cutting obsolete costs, downsizing, and converting to Fair Gold. It is the global network of Green OA repositories that will allow publishers to phase out all the products and services associated with access‐provision and archiving, once Green OA mandates fill them” (Harnad, 2013 ). However, green OA might not eradicate those journals whose publishers have an interest only in financial gain rather than in quality improvement, which seems to be common. Recently, there has been an increasingly support for an open peer‐review process that facilitates online transparency and disclosure of the identities of those reviewing scientific publications (DeCoursey, 2006 ).

Journal publishing has been facing a series of challenges in response to the rapid development of digital technologies. Reforms at the system level may provide a more effective solution than changes to individual components. For example, if policies for tenure and promotion that emphasize quality rather than quantity can be implemented universally, predatory journals may be significantly improved. Varying political, sociocultural, and economic situations across countries and regions of the world contribute to the scholarly community's ineffectiveness in adopting common evaluation criteria. Individual participants in the scholarly communication process need to work together and take responsibility for making the appropriate changes.
Conclusions

There are green and gold roads to OA (Harnad et al., 2004 , 2008 ). Many of the gold OA publishers charge an author fee for publication, and a group of questionable journals has been identified that takes money from authors upon acceptance of their papers while maintaining a low to nonexistent standard of quality control (Beall, 2010 , 2012b ). Beall hopes that his list of predatory journals will serve to alert scholars and prevent them from doing business with these journals.

Our attempt to examine author profiles suggests that authors who publish in predatory journals are indeed distinct from authors who publish in OA journals that have a more rigorous review process. Comparisons between the predatory journals and two other groups of OA journals, a more‐selective group and a most‐selective group, have been made based on the fact that they all charge an author fee. Although we are unable to test the statistical differences among selected predatory journals in our study, we can confidently state that they, as a group, have published articles by inexperienced authors.

The second group of OA journals for comparison is from Bohannon's study, containing journals with a substantial review process. Authors who publish in this group of journals have a stronger history in terms of published articles and citations. We consider them to be more experienced authors. However, none of these journals has been indexed by Journal Citation Reports or SCImago Journal & Country Rank , which indicates the scholarly inferiority of the journals. This points to the fact that not all OA journals are equal in terms of quality control and thus challenges Bohannon's claim of the overall low quality of OA journals.

Not surprisingly, the third group of OA journals, namely the PLoS journals, contains the most experienced authors who have the strongest publication and citation records. Their high journal impact factors make them comparable to many other prestigious, non‐OA journals in the same fields. If one equates a publication‐fee model with low quality, the author profiles of the PLoS journals challenge that view.

Authors in predatory journals are mostly from developing countries, especially India, Nigeria, and some African and Middle East countries. This evidence supports Bohannon's finding regarding the geographic locations of the low‐quality publishers (Bohannon, 2013 , pp. 62–63). Noticeably, researchers from India and Nigeria rarely appear in prestigious OA journals, while authors from Australia, Europe, and North America have stronger publication and citation records. This geographic distribution of OA author profiles reflects the economic and sociocultural traditions of different countries.

The statistical analyses reject both of our hypotheses. Hence, we believe that there are differences in author profiles, based on their publication and citation history as well as their geographic locations, among the various groups of OA journals. In other words, different groups of OA publications do attract different types of authors, and author profiles do indicate the scholarly standards of OA journals.
Acknowledgment

J. Xia is grateful to Rachel Applegate for bringing the issue of “predatory journals” to his attention.

References

    Abraham, T. , & Minj, S. ( 2007 ). Scientific journal publishing in India: Promoting electronic publishing of scholarly journals in India . First Monday , 12 ( 10 ). Retrieved from http://firstmonday.org/ojs/index.php/fm/article/view/1954
    Crossref Google Scholar
    Adomi, E.E. , & Mordi, C. ( 2003 ). Publication in foreign journals and promotion of academics in Nigeria . Learned Publishing , 16 , 259 – 263 .
    Wiley Online Library Google Scholar
    Anderson, K. ( 2012 ). “Predatory” open access publishers—The natural extreme of an author pays model . The Scholarly Kitchen, March 2. Retrieved from http://scholarlykitchen.sspnet.org/2012/03/06/predatory‐open‐access‐publishers‐the‐natural‐extreme‐of‐an‐author‐pays‐model/
    Google Scholar
    Arunachalam, S. ( 2006 ). Open access—Current developments in India . Retrieved from http://arizona.openrepository.com/arizona/handle/10150/105554
    Google Scholar
    Beall, J. ( 2010 ). “Predatory” open‐access scholarly publishers . The Charleston Advisor , 10 ( 4 ), 10 – 17 .
    Google Scholar
    Beall, J. ( 2012a ). Criteria for determining predatory open‐access publishers ( 2nd ed. ). Scholarly Open Access. Retrieved from http://scholarlyoa.com/2012/11/30/criteria‐for‐determining‐predatory‐open‐access‐publishers‐2nd‐edition
    Google Scholar
    Beall, J. ( 2012b ). Internet scientific publications . The Charleston Advisor , 12 ( 4 ), 39 – 41 .
    Crossref Google Scholar
    Bernstein, M. ( 2013 ). American Chemical Society extends new open access program designed to assist authors . American Chemical Society News Releases, November 1. Retrieved from http://www.acs.org/content/acs/en/pressroom/newsreleases/2013/october/acs‐extends‐new‐open‐access‐program‐designed‐to‐assist‐authors.html
    Google Scholar
    Bohannon, J. ( 2013 ). Who's afraid of peer review? Science , 342 ( 6154 ), 60 – 65 .
    Crossref CAS PubMed Web of Science® Google Scholar
    Bornmann, L. ( 2011 ). Scientific peer review . In B. Cronin (Ed.), Annual Review of Information Science and Technology, 45 (pp. 199 – 245 ). Medford, NJ : Information Today.
    Web of Science® Google Scholar
    Cronin, B. ( 2005 ). The hand of science: Academic writing and its rewards . Landam, MD : Scarecrow Press.
    Google Scholar
    DeCoursey, T. ( 2006 ). The pros and cons of open peer review . Nature , 04991 . doi: 10.1038/nature04991
    Crossref Google Scholar
    Eisen, M. ( 2013 ). I confess, I wrote the Arsenic DNA paper to expose flaws in peer‐review at subscription based journals . Retrieved from http://www.michaeleisen.org/blog/?p=1439
    Google Scholar
    Finlay, S.C. , Ni, C. , Tsou, A. , & Sugimoto, C.R. ( 2013 ). Publish or practice? An examination of librarians' contributions to research . portal: Libraries and the Academy , 13 ( 4 ), 403 – 421 .
    Crossref Web of Science® Google Scholar
    Ghosh, S.B. , & Das, A.K. ( 2007 ). Open access and institutional repositories—A developing country perspective: A case study of India . IFLA Journal , 33 ( 3 ), 229 – 250 .
    Crossref Google Scholar
    Gilbert, N. ( 2009 ). Computer‐generated manuscript accepted for publication in open‐access journal . Nature . Retrieved from http://www.nature.com/news/2009/090615/full/news.2009.571.html
    Google Scholar
    Haider, J. ( 2006 ). The geographic distribution of open access journals . Retrieved from http://lup.lub.lu.se/record/1549482/file/3738628.pdf
    Google Scholar
    Harnad, S. ( 2013 ). Pre‐green fool's gold vs. post‐green fair gold . In R. Poynder's blogspot, Peter Suber on the state of open access: Where are we, what still needs to be done? Retrieved from http://poynder.blogspot.com/2013/07/peter‐suber‐on‐state‐of‐open‐access.html
    Google Scholar
    Harnad, S. , Brody, T. , Vallières, F. , Carr, L. , Hitchcock, S. , Gingras, Y. , Oppenheim, C. , Stamerjohanns, H. , & Hilf, E. ( 2004 ). The access/impact problem and the green and gold roads to open access . Serials Review , 30 ( 4 ), 310 – 314 .
    Crossref Google Scholar
    Harnad, S. , Brody, T. , Vallières, F. , Carr, L. , & Hitchcock, S. ( 2008 ). The access/impact problem and the green and gold roads to open access: An update . Serials Review , 34 ( 1 ), 36 – 40 .
    Crossref Web of Science® Google Scholar
    Khan, A. ( 2013 ). Reply in M. Eisen's blog: I confess, I wrote the Arsenic DNA paper to expose flaws in peer‐review at subscription based journals . Retrieved from http://www.michaeleisen.org/blog/?p=1439
    Google Scholar
    Lee, C.J. , Sugimoto, C.R. , Zhang, G. , & Cronin, B. ( 2013 ). Bias in peer review . Journal of the American Society for Information Science and Technology , 64 ( 1 ), 2 – 17 .
    Wiley Online Library PubMed Web of Science® Google Scholar
    Mordi, C. ( 2002 ). Giving a human face to appraisal criteria of academic staff in Nigerian universities . Perspectives in Education , 18 ( 3 ), 179 – 184 .
    Google Scholar
    Nazim, M. , & Devi, M. ( 2008 ). Open access journals and institutional repositories: Practical need and present trends in India . Annals of Library and Information Studies , 55 ( 1 ), 27 – 34 .
    Google Scholar
    Olukoju, A. ( 2004 ). The crisis of research and academic publishing in Nigerian universities . In P.T. Zeleza & A. Olukoju (Eds.), African universities in the twenty‐first century, knowledge and society (Vol. II , pp. 363 – 375 ). Dakar, Senegal : Council for the Development of Social Science Research in Africa.
    Google Scholar
    Oransky, I. ( 2013 ). Science reporter spoofs hundreds of open access journals with fake papers . Retraction Watch. Retrieved from http://retractionwatch.wordpress.com/2013/10/03/science‐reporter‐spoofs‐hundreds‐of‐journals‐with‐a‐fake‐paper
    Google Scholar
    Peters, D.P. , & Ceci, S.J. ( 1982 ). Peer‐review practices of psychological journals: The fate of published articles, submitted again . Behavioral and Brain Sciences , 5 ( 2 ), 187 – 195 .
    Crossref Web of Science® Google Scholar
    Poynder, R. ( 2013 ). The OA interviews: Ashry Aly of Ashdin publishing . Retrieved from http://poynder.blogspot.com/2013/01/the‐oa‐interviews‐ashry‐aly‐of‐ashdin.html
    Google Scholar
    Riesenberg, D. , & Lundberg, G.D. ( 1990 ). The order of authorship: Who's on first? Journal of the American Medical Association , 264 ( 14 ), 1857 .
    CAS PubMed Web of Science® Google Scholar
    Shapiro, D.W. , Wenger, N.S. , & Shapiro, M.F. ( 1994 ). The contributions of authors to multiauthored biomedical research papers . Journal of the American Medical Association , 271 ( 6 ), 438 – 442 .
    CAS PubMed Web of Science® Google Scholar
    Shaw, C. ( 2013 ). Hundreds of open access journals accept fake science paper . The Guardian. Retrieved from http://www.theguardian.com/higher‐education‐network/2013/oct/04/open‐access‐journals‐fake‐paper
    Google Scholar
    Sokal, A. ( 1996a ). Transgressing the boundaries: Toward a transformative hermeneutics of quantum gravity . Social Text , 46/47 ( spring/summer ), 217 – 252 .
    Crossref Google Scholar
    Sokal, A. ( 1996b ). A physicist experiments with cultural studies . Lingua Franca , May/June , 62 – 64 .
    Google Scholar
    Sokal, A. ( 1996c ). Transgressing the boundaries: An afterword . Dissent , 43 ( 4 ), 93 – 99 .
    Web of Science® Google Scholar
    Suber, P. ( 2006 ). No‐fee open‐access journals . SPARC Open Access Newsletter. Retrieved from http://legacy.earlham.edu/~peters/fos/newsletter/11‐02‐06.htm
    Google Scholar
    Suber, P. ( 2013 ). Some numbers from the Directory of Open Access Journals . Retrieved from plus.google.com/109377556796183035206/posts/iSR2spVGFUL
    Google Scholar
    Taylor, M. , Wedel, M. , & Naish, D. ( 2013 ). John Bohannon's peer‐review sting against . Science . Retrieved from http://svpow.com/2013/10/03/john‐bohannons‐peer‐review‐sting‐against‐science
    Google Scholar
    Truth, F. ( 2012 ). Pay big to publish fast: Academic journal rackets . Journal for Critical Education Policy Studies , 10 ( 2 ), 54 – 105 .
    Google Scholar

Citing Literature
Publication cover image

Volume 66 , Issue 7

July 2015

Pages 1406-1417

    Figures
    References
    Related
    Information

Close Figure Viewer
Browse All Figures Return to Figure
Previous Figure Next Figure
Caption
Association for Information Science &amp; Technology Logo
© 2019 Association for Information Science & Technology

Join ASIS&T  |  Association News  |  Events Calendar  |  Career Center  |  iConnect  |  Webinars
© 2019 Association for Information Science & Technology
Additional links
About Wiley Online Library

    Privacy Policy
    Terms of Use
    Cookies
    Accessibility

Help & Support

    Contact Us

Opportunities

    Subscription Agents
    Advertisers & Corporate Partners

Connect with Wiley

    The Wiley Network
    Wiley Press Room

Copyright © 1999-2019 John Wiley & Sons, Inc . All rights reserved
Wiley Home Page
Log in to Wiley Online Library
Email or Customer ID
Password
Forgot password?
Log in with your ASIS&T membership
Go to Asist.org
NEW USER > INSTITUTIONAL LOGIN >
Change Password
Old Password
New Password
Too Short Weak Medium Strong Very Strong Too Long
Password Changed Successfully

Your password has been changed
Create a new account
Email or Customer ID
Returning user
Forgot your password?

Enter your email address below.
Email or Customer ID

"Please check your email for instructions on resetting your password. If you do not receive an email within 10 minutes, your email address may not be registered, and you may need to create a new Wiley Online Library account.
Request Username

Can't sign in? Forgot your username?

Enter your email address below and we will send you your username
Email or Customer ID
Close

If the address matches an existing account you will receive an email with instructions to retrieve your username
Close crossmark popup
