<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


<meta name="wpd_version" content="0.2">
<meta name="wpd_baseurl" content="http://www.palgrave-journals.com/eps/journal/v8/n3/full/eps200919a.html">
<meta name="wpd_url" content="http://www.palgrave-journals.com/eps/journal/v8/n3/full/eps200919a.html">
<meta name="wpd_date" content="2014-01-05T14:19Z">
<script src="wtid.js" async="" type="text/javascript"></script><script src="webtrends.hm.js" type="text/javascript"></script><script src="17dc539f04eb2d6cacfc95a75f75921c.js" async="" type="text/javascript"></script><script src="serverComponent.php"></script>
	<!-- super head top -->	<title>European Political Science - An Outline of the Bibliometric Indicator Used for Performance-Based Funding of Research Institutions in Norway</title><!--European Political Science-->
<!-- metadata and links -->

	<meta name="robots" content="noarchive">

	
	        
                













































       
             
     










        
 

        
        
  

 



 
 


 



 
 

  
 
<meta http-equiv="Content-Style-Type" content="text/css">
<meta name="robots" content="noarchive">
<meta name="keywords" content="European political science, European Consortium for Political Research, comparative politics, political economy, international relations, public administration, political theory, European studies, European politics, political science, EPS journal">
<meta name="description" content="Published by Palgrave Macmillan since 2005, EPS: European Political Science is a journal of the European Consortium for Political Research. European Political Science (EPS) is an international journal devoted to publishing contributions by and for the political science community. Its interpretation of 'political science' is wide and encompasses comparative politics, political economy, international relations, public administration, political theory, European studies and related disciplines.">

<link rel="shortcut icon" href="favicon.ico">
<link rel="home" href="http://www.palgrave-journals.com/eps/" title="home">
<link rel="copyright" href="http://www.palgrave-journals.com/pal/copyright/" title="copyright">
<link rel="help" title="help" href="http://www.palgrave-journals.com/pal/accessibility_statement.html">




<!-- Banner Rotator added EG 14-02-2011 -->

<script type="text/javascript" src="ad_rotate.js"></script>

<!-- End Banner Rotator Script -->
<!-- end metadata and links -->
<!-- style -->

	<!--link rel="stylesheet" href="/common/no_standards.css" type="text/css" media="screen" /-->



<!-- makes IE understand css declarations min/max-width and min/max-height -->
<script type="text/javascript" src="minmax.js"></script>
<!-- end style -->

	<!-- super head bottom -->
	<!-- resource metadata -->
			
				 																							
	
		
														
			<link title="schema(PRISM)" rel="schema.prism" href="http://prismstandard.org/namespaces/1.2/basic/">
																																																			<meta name="prism.copyright" content="© 2009 Nature Publishing Group">
					<meta name="prism.rightsAgent" content="permissions@nature.com">
					<meta name="prism.publicationDate" content="2009-09-01">
					<meta name="prism.startingPage" content="364">
					<meta name="prism.endingPage" content="378">
					<meta name="prism.publicationName" content="European Political Science">
					<meta name="prism.issn" content="1680-4333">
					<meta name="prism.eIssn" content="1682-0983">
				
			<link title="schema(DC)" rel="schema.dc" href="http://purl.org/dc/elements/1.1/">
																																																			<meta name="dc.publisher" content="Nature Publishing Group">
					<meta name="dc.language" content="en">
					<meta name="dc.rights" content="© 2009 Nature Publishing Group">
					<meta name="dc.title" content="An Outline of the Bibliometric Indicator Used for Performance-Based Funding of Research Institutions in Norway">
					<meta name="dc.creator" content="Jesper W Schneider">
					<meta name="dc.identifier" content="doi:10.1057/eps.2009.19">
					<meta name="dc.date" content="2009-09-01">
					<meta name="dc.source" content="European Political Science, Published online: 01 September 2009; | doi:10.1057/eps.2009.19">
				
																																																												<meta name="citation_publisher" content="Nature Publishing Group">
					<meta name="citation_authors" content="Jesper W Schneider">
					<meta name="citation_title" content="An Outline of the Bibliometric Indicator Used for Performance-Based Funding of Research Institutions in Norway">
					<meta name="citation_date" content="2009-09-01">
					<meta name="citation_online_date" content="2009-09-01">
					<meta name="citation_volume" content="8">
					<meta name="citation_issue" content="3">
					<meta name="citation_firstpage" content="364">
					<meta name="citation_doi" content="doi:10.1057/eps.2009.19">
					<meta name="citation_journal_title" content="European Political Science">
			
																														<meta name="DCS.dcssip" content="www.palgrave-journals.com">
					<meta name="Access" content="Yes">
					<meta name="WT.cg_n" content="Palgrave Journals">
					<meta name="WT.cg_s" content="European Political Science">
			
	<script type="text/javascript" src="Bootstrap.js"></script>

<link rel="stylesheet" type="text/css" href="eps200919a.css" media="all">
</head>
<body class="www-nature-com-eps js-enabled" id="article">
	<!-- super body top -->	
	
	<div id="header">
	<!-- global links -->
<!-- header -->


																										

<div id="head-er">

<div class="header-nonad-wrapper" id="top">
				<div class="accessibility-login-wrap">
	<div class="accessibility-login">
		
				<ul class="jumplinks">
						<li class="first"><a href="#content">Jump&nbsp;to&nbsp;main&nbsp;content</a></li>
						<li><a href="#journalnav">Jump&nbsp;to&nbsp;navigation</a></li>
					</ul>
							

			<div class="logon">
		<p><a href="http://www.palgrave-journals.com/foxtrot/svc/login" class="login" title="login to Palgrave-journals.com">Login<!-- following space necessary for Mac IE --> </a><span class="onlyformacie">&nbsp;</span></p>
	</div>
		
				<div class="cleardiv"><!--  --></div>
	</div>
</div>

<div class="cleardiv"><!--  --></div>
<hr>
	
			<div class="image-user-services-wrap">
	<div class="image-user-services">
				<a href="http://www.palgrave.com/"><img src="pallogo.gif" class="journal-header" alt="Palgrave Macmillan homepage"></a>
		
								<div class="user-services div1">
								<!-- whitespace removed to deal with IE 5.0 bug --><ul class="list1"><li class="li1"><a href="http://www.palgrave-journals.com/nams/svc/mysiteaccount">Admin Login</a></li><li class="li2"><a href="http://www.palgrave-journals.com/myaccount">My account</a></li><li class="li3"><a href="http://www.palgrave-journals.com/nams/svc/myaccount/save/ealert?list_id=102" title="Sign up to receive European Political Science email alerts">E-alert sign up</a></li></ul>
							</div>
						<div class="user-services div2">
								<!-- whitespace removed to deal with IE 5.0 bug --><ul class="list2"><li class="li1"><a href="http://www.palgrave-journals.com/nams/svc/siteregister" title="Register with Palgrave-journals.com">Institutional Registration</a></li><li class="li2"><a href="http://www.palgrave-journals.com/register" title="Register with Palgrave-journals.com">Personal Registration</a></li><li class="li3"><a href="http://www.palgrave-journals.com/eps/subscribe.html" title="Subscribe to European Political Science">Subscribe</a></li></ul>
							</div>
						<div class="cleardiv"><!--  --></div>
			</div>
	<div class="cleardiv"><!--  --></div>
</div>

<div class="cleardiv"><!--  --></div>
<hr>	
			<div class="publications-search-wrap clearfix">
	<div class="publications-search">
				<ul class="publications">
			<li class="first"><a href="http://www.palgrave-journals.com/pal/site_map.html">Site Map</a></li><li><a href="http://www.palgrave-journals.com/pal/jnlsubject.html">Subject Areas</a></li>		</ul>

		<hr>
		
				<div class="search">
			<form class="search" action="http://www.palgrave-journals.com/search/executeSearch?" method="get">
				<div>
					<label for="searchtext">Search</label>
					<input name="sp-advanced" value="true" type="hidden">
					<input name="contentType" value="searchAll" type="hidden">
					<input name="interface" value="palgraveconnect" type="hidden">
					
																	<select name="sp-pal-9">
														<option value="EPS">This journal</option>
														<option value="">All content</option>
													</select>
						<input id="sp-pal-key" name="sp-pal-key" value="" type="text">
						
						
												
										
																				<input name="sp-m" value="0" type="hidden">
															<input name="sp-s" value="relevance" type="hidden">
															<input name="include-collections" value="journals_palgrave" type="hidden">
															<input name="exclude-collections" value="international_abstracts_in_operations_research,journals_nature,crawled_content,lab_animal" type="hidden">
																				<input name="sp-x-9" value="cat" type="hidden">
										
					
																									<input name="sp-a" value="sp10038c8a" type="hidden">
																											<input name="sp-sfvl-field" value="subject|ujournal" type="hidden">
																											<input name="sp-c" value="25" type="hidden">
																											<input name="sp-q-13" value="palgrave" type="hidden">
																											<input name="sp-x-1" value="ujournal" type="hidden">
																											<input name="sp-p-1" value="phrase" type="hidden">
																											<input name="sp-p" value="all" type="hidden">
																							<input name="submit" class="button" value="Go" title="search now" type="submit"> 						
										<a href="http://www.palgrave-journals.com/search/adv_search?sp-a=sp10038c8a&amp;sp-x-1=ujournal&amp;sp-q-1=EPS">Advanced&nbsp;search</a>
									</div>
			</form>
		</div>

		
		
				<div class="cleardiv"><!--  --></div>
	</div>
</div>

	
		</div>


	<!-- adboard ad -->
<div style="padding-left: 1%; padding-right: 1%; background-color: rgb(234, 234, 234);">

<div class="header-leaderboard">
		<a href="http://www.palgrave-journals.com/iga/"><img src="IGA_leaderboard_AW_static_v1.jpg" style="width: 728px; height: 90px; border: 0px none;" alt="Advertisement | Visit IGA site" title="Advertisement | Visit IGA site"></a>
	</div>

	<!--div class="header-leaderboard"></div-->
</div>
<img src="clear.gif" style="border: 0px none; width: 1px; height: 14px;" alt=""><br>
<!-- end adboard ad -->
</div>
<!-- end header -->

				</div><!-- /#header -->
		<!-- opening divs for fixed width layout -->
	<div id="constrain"><div class="constrain">
				<div style="display: none;">
	<!-- end global links -->

</div>
<div id="breadcrumb"><div><a href="http://www.palgrave-journals.com/eps/index.html">Journal home</a><span class="divider"> &gt; </span><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/index.html"> Archive</a><span class="divider"> &gt; </span><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/index.html#Profession">Profession</a><span class="divider"> &gt; </span><span class="thisitem">Full text</span></div></div>
<!-- content and journal nav --><div id="content-journalnav"><!-- content --><div id="content"><h1 class="page-header">Profession</h1>
<p id="cite"><i>European Political Science</i> (2009) <b>8,</b> 364–378. doi:10.1057/eps.2009.19</p>
	
<h2 id="atl">An Outline of the Bibliometric Indicator Used for Performance-Based Funding of Research Institutions in Norway</h2>
<p id="aug">Jesper W&nbsp;Schneider<sup><a title="affiliated with a" href="#aff1">a</a></sup></p><div id="affiliations-notes"><p id="aff"><a name="aff1"><sup>a</sup></a>Royal School of Library and Information Science, Fredrik Bajers Vej 7K, Aalborg, 9220, Denmark</p><p class="caff">Correspondence: Jesper W Schneider, E-mail: <a href="mailto:jws@db.dk">jws@db.dk</a></p></div>
<div id="abs"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>Abstract</h3><p class="abs lead">This article outlines and discusses the bibliometric indicator used for performance-based funding of research institutions in Norway. It is argued that the indicator is novel and innovative as compared to the indicators used in other funding models. It compares institutions based on <i>all</i> their publication-based research activities across all disciplines. Specific incentives are given to researchers to focus their publication behaviour on the most ‘prestigious’ publication channels within the different fields. Such aims necessitate a documentation system based on high-quality data, and require differentiated publication counts as the basic measure. Experience until now suggests that the indicator works as intended.</p><div class="keyw-abbr"><h4 class="keywords">Keywords: </h4><p class="keywords">bibliometric indicators, performance-based funding, research institutions, publication counts</p></div></div>
<!-- articlebody start --><div id="articlebody"><p class="norm">This article describes the bibliometric indicator used for performance-based funding of research institutions in Norway, commonly known as the ‘Norwegian model’ (<!--bib28--><a href="#bib28">Sivertsen, 2006</a>). We reflect upon the model's incentives, advantages and potential problems in relation to the social sciences and other models with similar purposes. Finally, we present the latest experience with the Norwegian model. The general debate with regard to the appropriateness of performance-based funding of research is not discussed in this paper. The focus here is on the mechanisms embodied in the bibliometric indicator and how it compares with other indicators used for similar purposes.</p><p class="norm">Government interest in performance-based funding of research institutions has been growing in recent years. Several European countries have implemented, or are currently implementing, such funding models, whereas other countries are considering which model to choose. It is noticeable that the current interest is especially focused on metric solutions, such as bibliometric indicators, as opposed to panel-based peer review models like that of the Research Assessment Exercise (RAE) in the United Kingdom. In fact, the RAE is to be replaced after the 2008 evaluation by the metric-oriented Research Excellence Framework (<a href="http://www.hefce.ac.uk/research/ref/">www.hefce.ac.uk/research/ref/</a>).</p><p class="norm">The Norwegian model is especially interesting in this context. It was commissioned by the Norwegian Ministry of Education and Research in 2002 and developed by the Norwegian Association of Higher Education Institutions in 2003–2004.<!--ftnote1--><a href="#ftnote1"><sup>1</sup></a> The purpose of the model is annually to redistribute basic research funding among institutions in the higher education sector (six universities and forty other institutions) based on a bibliometric indicator that counts scholarly publications. Publications have been counted since 2004. The Norwegian model was first used in connection with budget allocations for 2006 (which were based on publication counts for 2005). The funding model redistributes approximately 2 per cent of the annual budget for basic research in Norway, approximately <img src="glyph.gif" style="border: 0px none; vertical-align: middle;" alt="euro" class="glyph">3.4 billion (<!--bib29--><a href="#bib29">Sivertsen, 2008</a>).</p><p class="norm">At first, this may seem somewhat unremarkable, but the indicator is both novel and innovative. The aim is annually to count <i>all</i> scholarly publications within <i>all</i> research fields. Institutions are thus compared based on <i>all</i> their publication-based research activities. Such an aim requires publication counting as the basic indicator, and thus complete, valid and reliable publication data are necessary. In order to counter unintended publication behaviour and to encourage publication in ‘prestigious’ channels, counting in the model is differentiated. It is assumed that such a model is able to measure </p><blockquote class="pullquote">‘The aim is annually to count all scholarly publications within all research fields.’</blockquote><p class="norm">‘performance’ beyond mere productivity. This is an innovative solution, which makes the Norwegian model an appropriate alternative to traditional citation-based indicators.</p><p class="norm">The following section outlines the background to the Norwegian funding model and discusses some issues important to the indicator. We then outline the model's basic components and discuss their rationale; the section after discusses the model in relation to the social sciences, and finally we describe recent experience with the model and briefly describe how the ideas underlying the Norwegian model seem to have inspired funding models elsewhere.</p><div id="BACKGROUND"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>BACKGROUND</h3><p class="norm">Research evaluation models are often characterised as either ‘weak’ or ‘strong’ (e.g., <!--bib35--><a href="#bib35">Whitley, 2007</a>). Weak models are usually informal, private and primarily used for formative research policies and management issues. Strong models are formal, public and summative in the sense of having direct links to the allocation of resources. Research evaluation is also categorised as either <i>ex ante</i> or <i>ex post</i> (<!--bib16--><a href="#bib16">Kogan, 1989</a>). <i>Ex ante</i> evaluation is applied to research proposals, and is conducted prior to the execution of research. <i>Ex post</i> evaluation comes once research has been completed, and assesses the output and the impact. Funding of basic research is usually done through annual block grants, with project funding being allocated thorough <i>ex ante</i> evaluation by the research councils or funding agencies, such as US federal funding, or <i>ex post</i> evaluation, in which funding is either based on reviews of output and merit, or more mechanically, in which funding is directly connected to a quantitative formula. This paper focuses on the latter, as the Norwegian model is an <i>ex post</i> evaluation model directly connected to a funding formula based on a bibliometric indicator. But what do bibliometric indicators measure?</p><p class="norm">Performance-based funding of research presupposes distinct measures of performance; however these are not easily agreed upon. The principal methods are peer review, often in the form of panel rankings, and bibliometric indicators (<!--bib22--><a href="#bib22">Moed, 2005</a>). We do not consider peer review in this paper.<!--ftnote2--><a href="#ftnote2"><sup>2</sup></a> The intention in applying performance-based bibliometric indicators has traditionally been either to identify ‘high quality’ research or to find out which research is ‘better’ (<!--bib22--><a href="#bib22">Moed, 2005</a>). Not surprisingly, application of quantitative indicators has generated a debate about what is meant by ‘research quality’, and how various indicators are related to it.</p><p class="norm">A simple undifferentiated count of a unit's number of publications is usually viewed as a measure of the productivity of research, in other words, ‘quantity’ rather than ‘quality’ (<!--bib24--><a href="#bib24">Moravcsik, 1973</a>). Indicators based on publication counts have not received the same attention as citation-based indicators in discussions of validity because their connection to ‘research quality’ has been quite remote. The peer review process that scholarly publications undergo may be interpreted as a sign of ‘quality’. But to many, a publication constitutes nothing more than an ‘offer’ to the scientific community. It is the subsequent reception of that offer that certifies the actual ‘impact’ of a publication (e.g., <!--bib22--><a href="#bib22">Moed, 2005</a>; <!--bib7--><a href="#bib7">Glänzel, 2008</a>).</p><p class="norm">The most important instance in which research funds were linked, at least in part, to productivity measures, undifferentiated by any measure of ‘quality’, is the </p><blockquote class="pullquote">‘The most important instance in which research funds were linked, at least in part, to productivity measures, undifferentiated by any measure of “quality”, is the Australian funding model from the 1990s.’</blockquote><p class="norm">Australian funding model from the 1990s (<!--bib2--><a href="#bib2">Butler, 2004</a>). A striking effect of the model was a dramatic increase in the number of research publications from Australia. The largest proportion of this increase came, however, in lower-impact journals (<!--bib2--><a href="#bib2">Butler, 2004</a>). The latter effect was clearly unintentional and suggested that a general increase in research output may have come with a lower overall impact (<!--bib2--><a href="#bib2">Butler, 2004</a>). Undoubtedly, publication behaviour among a considerable number of researchers in Australia underwent a change that reflected an overriding emphasis upon quantity. This is what <!--bib34--><a href="#bib34">Weingart (2005</a>: 125) calls a ‘reactive measure’. Bibliometric indicators linked to funding models inadvertently become reactive measures when researchers alter their behaviour in ways unintended by those applying the indicator (<!--bib34--><a href="#bib34">Weingart, 2005</a>). Notice that behavioural changes are indeed anticipated and intended politically when bibliometric indicators are linked to research funding. The problem arises when behavioural change has negative effects for the funding model as a whole, inducing ‘game playing’ by researchers without necessarily improving performance. In Australia, publication counts were conceived as a means of distributing research funds on the basis of the ‘quality’ of research. But undifferentiated publication counts are not measures of ‘quality’. Institutions were rewarded for publication activity only – to which they and their researchers obviously adapted.</p><p class="norm">The Norwegian funding model also focuses upon productivity. Contrary to the Australian model, the Norwegian model is based on differentiated counting of publications. Differentiated counts mean that some publication activities are favoured and therefore given greater weights. The Norwegian model encourages institutions and their researchers to publish through the most ‘prestigious’ publication channels within different fields of research. ‘Prestige’ is linked to such characteristics of the publication channels as ‘having a tough peer review process’, ‘publication competition’, ‘visibility to the widest relevant audience’, ‘general reputation of the channel’, etc. (<!--bib29--><a href="#bib29">Sivertsen, 2008</a>). Notice that the model does not determine ‘quality’ or predict the ‘impact’ of individual publications. The model gives incentives to publish through a selected number of publication channels, somehow deemed ‘qualitatively’ better than the majority of channels within the specific field of research. At the same time, these incentives should counter excessive publication activity through less ‘prestigious’ channels, as happened in Australia. The notion that some publication channels are ‘more prestigious’ than others may seem controversial. Nevertheless, in many fields of research, different publication channels do have noticeably more or less status among researchers. This is made explicit in the Norwegian model. It is important to emphasise that publication through a ‘less prestigious’ channel is not the same as ‘poor research’. It is merely a division between ‘normal’ and ‘selective’ publication patterns within the fields. The ‘selective’ patterns are weighted higher because they are deemed more competitive and attractive. It is assumed that this incentive can motivate researchers to publish more and <i>better</i> research, while at the same time countering negative influences in publication patterns.</p><p class="norm">Some critics of the Norwegian model have argued that a proper quantitative performance measure should be based on citations (e.g., <!--bib26--><a href="#bib26">Sandström and Sandström, 2007</a>). What the critics argue is that citations measure ‘impact’, which is often considered a proxy for ‘research quality’. Obviously the use of bibliometric indicators presuppose that they are able to measure aspects of ‘research quality’ (e.g., <!--bib10--><a href="#bib10">Gläser and Laudel, 2007</a>). However, faith in the possibility of measuring the scientific quality of individual publications through citations alone is misplaced (<!--bib31--><a href="#bib31">Van Raan, 1996</a>; <!--bib32--><a href="#bib32">2000</a>; <!--bib22--><a href="#bib22">Moed, 2005</a>; <!--bib7--><a href="#bib7">Glänzel, 2008</a>). Within the bibliometric community, there is consensus that its complexity is such that ‘research quality’ can only be judged by peers (e.g., <!--bib31--><a href="#bib31">Van Raan, 1996</a>). Citations, in general, and impact factors, in particular, are and remain primarily the indicators of the <i>reception</i> of scientific information (<!--bib7--><a href="#bib7">Glänzel, 2008</a>). The observation that citations indicate reception, use and, therefore, usefulness, as well as impact, is the basic argument for using them as proxies for ‘quality’ at levels above individual publications. Bibliometric indicators may therefore be more or less related to ‘quality’, and perhaps measure certain aspects of it, but they cannot exhaustively represent ‘research quality’ (<!--bib20--><a href="#bib20">Martin and Irvine, 1983</a>, <!--bib31--><a href="#bib31">Van Raan, 1996</a>). The question is to what extent do publication-based indicators reflect ‘research quality’? In the Norwegian model incentives are given to continue to focus on, or to shift the focus of, publication efforts towards the ‘most prestigious’ journals within the different fields of research. It is reasonable to suggest that such an incentive is related in some way to ‘quality’ as it rewards more than simple productivity. This is one of the reasons why the model is both novel and innovative compared to the existing <i>ex post</i> funding models. But it is unlikely that publication incentives reflect the same aspects of ‘quality’ that citations are supposed to reflect.</p><p class="norm">Obviously, the ‘reception’ of publications within a research field is an interesting metric for research evaluation. And perhaps our perception of citations is that it is closer to measuring ‘quality’. Nonetheless, it is generally accepted that at least six modalities restrict the conditions under which citation-based indicators can be applied in order to produce valid and reliable results (<!--bib10--><a href="#bib10">Gläser and Laudel, 2007</a>). These include first and foremost the aforementioned limitation that citations do not measure quality <i>per se</i>, but is rather ‘an important aspect of quality’ (<!--bib31--><a href="#bib31">Van Raan, 1996</a>: 404). Second, bibliometric indicators must be applied to a large number of publications for the statistics to be reliable (e.g., <!--bib32--><a href="#bib32">Van Raan, 2000</a>; <!--bib1--><a href="#bib1">Butler, 2001</a>). Third, there is the issue of coverage; for valid conclusions about research performance to be drawn, the whole research output of evaluated units must be covered (<!--bib23--><a href="#bib23">Moed <i>et al</i>, 1985</a>). Fourth, time frames are essential in citation analysis, as publications within different fields need different lengths of time to accumulate citations (<!--bib23--><a href="#bib23">Moed <i>et al</i>, 1985</a>). Fifth, publication and reference patterns vary between fields of research. Bibliometric indicators are therefore field-specific and need to be normalised when aggregated and compared to each other (<!--bib22--><a href="#bib22">Moed, 2005</a>). Furthermore, the delineation of fields affects the validity of bibliometric evaluations and therefore becomes a crucial task. Sixth, there are the critical technical issues with regard to access, coverage, quality and the limitations of bibliometric data (e.g., <!--bib8--><a href="#bib8">Glänzel and Schoepflin, 1994</a>; <!--bib22--><a href="#bib22">Moed, 2005</a>). Public access to bibliometric data suitable for research evaluation is severely restricted; such data are commercial to vendors like Thompson Reuters and Scopus. As a consequence, qualified research evaluation based on citation analysis is commercialised and carried out by a few institutions worldwide that have access to a sufficient number of bibliometric data. Some of these constraints or modalities apply to all bibliometric indicators, whereas all of them apply to citation-based indicators.</p><p class="norm">As a result, citation-based indicators have several limitations that disqualify them for the purposes of the Norwegian funding model, as outlined above. Limitations include, for example, a lack of complete data reliable enough to enable comparison of institutions based on all their research activities across all fields, and the different time frames needed for citation counting. The latter is especially important in relation to funding models. In order for citation patterns to be reliable within a field of research, indicators based on citation counts require longer time spans compared to indicators based on publication counts (<!--bib22--><a href="#bib22">Moed, 2005</a>). Accordingly, if citation-based indicators are used in a funding model, the performance measured is not that of the most recent research, but research of some age (often published 3–5 years prior to the year of evaluation) (e.g., <!--bib4--><a href="#bib4">Debackere and Glänzel, 2004</a>). In some situations, and within some fields, this may be considered appropriate; in other situations, however, it may be seen as static and inflexible. An alternative is therefore a dynamic and flexible funding model, in which the most recent research determines the forthcoming year's or years’ budget allocation(s). Such an approach disqualifies the use of citation counts due to the limited time span. Citation-based indicators are perhaps most useful for retrospective <i>ex post</i> evaluations.</p><p class="norm">A question remains whether <i>Google Scholar</i>, or other freely available citation databases, could be used for research evaluation in the future. Some studies have reported good correlations between traditional journal impact factors and citation data obtained through <i>Google Scholar</i> (e.g., <!--bib12--><a href="#bib12">Harzing and van der Wal, 2008</a>). Although there are certainly several things to commend about <i>Google Scholar</i>, such as its free access to data and its coverage of proceedings, books and international and non-English language journals, the fact remains, however, that the data quality is extremely poor and publication inclusion criteria are obscure. We therefore have no knowledge of coverage, and an extremely time-consuming task of data cleaning lies ahead of us if <i>Google Scholar</i> is to be used. <!--bib21--><a href="#bib21">Meho and Yang (2007)</a> report a comparison of data cleaning between <i>Web of Science</i> and <i>Google Scholar</i> for the same citation analysis. It took 100 hours in <i>Web of Science</i> and a gruelling 3,000 hours in <i>Google Scholar</i>. More generally, <i>Google Scholar</i>, and other citation databases for that matter, are still restricted by the six intrinsic modalities mentioned above. In fact, the case of <i>Google Scholar</i> emphasises the need for complete and good quality data in order to produce valid and reliable indicators.</p><p class="norm">We now turn to the components of the Norwegian bibliometric indicator and discuss, in the following section, their rationales and purposes.</p></div><div id="THE-COMPONENTS-OF-THE-MODEL"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>THE COMPONENTS OF THE MODEL</h3><p class="norm">Bibliometric indicators tend to be aggregated constructs that often comprise complex formulae applied to data to which public access is restricted. Although their mechanisms are well understood, such complex indicators can be challenging for funding purposes due to their lack of transparency. It is difficult to perceive the extent to which individual publications, publication strategiesor relative citation impacts affect the outcome of such funding models (see e.g., <!--bib4--><a href="#bib4">Debackere and Glänzel, 2004</a>).</p><p class="norm">A priority in the development of the Norwegian model has been simplicity and </p><blockquote class="pullquote">‘A question remains whether Google Scholar, or other freely available citation databases, could be used for research evaluation in the future.’</blockquote><p class="norm">transparency. It has been essential to construct an indicator that clearly delineates the different effects of publishing strategies within the model. The goal is threefold: (1) to give researchers and institutions incentives to publish in the most rewarding channels; (2) to create valid and reliable national publication data; and (3) to provide public insight into the model, its underlying data and reward mechanisms. The Norwegian model clearly specifies the actual number of points a specific publication contributes to the annual total number of points for an institution (see <a href="http://dbh.nsd.uib.no/pub/">http://dbh.nsd.uib.no/pub/</a>). Notice that these points are comparable across divergent fields from art history to astrophysics, as the model in Norway comprises all scholarly fields (with a few exceptions) and all scholarly publications within these fields.</p><p class="norm">The model has two interrelated components: (1) a transparent national research documentation system and (2) a simple bibliometric indicator. In the following section we will outline the two components and the rationale behind them.</p><h4 class="norm">THE NATIONAL RESEARCH DOCUMENTATION SYSTEM</h4><p class="follows-h4">A common predicament in all bibliometric analyses is the nature and coverage of the bibliographic data (e.g., <!--bib30--><a href="#bib30">Smith, 1981</a>; <!--bib22--><a href="#bib22">Moed, 2005</a>). This applies to citation databases, such as Thompson Reuters or Scopus, as well as national or institutional research databases that index scholarly publications. Perhaps the most novel, and certainly the most innovative aspect, in our view, of the Norwegian model is the construction of a national research documentation system that supports the bibliometric indicator. Norwegian scholarly publications are not only all registered in the system, but the data describing them are also validated and standardised. As a result, Norway currently has one of the richest bibliographic databases used for bibliometric purposes. The system and its data are publicly transparent. It further secures complete, verifiable and structured metadata for all scholarly publications from all Norwegian research institutions.</p><p class="norm">Essential for the model and the registration of scholarly publications in the documentation system is the dynamic authority file of accepted scholarly publication channels. The authority file ensures that no ‘non-scholarly’ publications are entered into the system. Publication channels are defined as ISSN-titles (journals, e-journals and series) or publishers of ISBN-titles. Two criteria determine whether publication channels can be accepted for the model: (1) they must use external peer review, and (2) no more than two thirds of the authors that publish through a channel can be from the same institution. The reason this requirement is applied is that it is likely in such cases that authors with close professional relationships publish and review each others’ works, and it is questionable whether such local, non-national peer-review processes function optimally. In addition, contrary to the intentions of the model, opportunities for publication through local channels may be linked to remuneration incentives, and thus stimulate high publication rates for that reason only.</p><p class="norm">Consequently, the scholarliness of publications is determined according to the status of the publication channel. Currently, some 18,000 publication channels are accepted for the Norwegian model (for an overview, see <a href="http://dbh.nsd.uib.no/kanaler/">http://dbh.nsd.uib.no/kanaler/</a>).</p><p class="norm">Institutions are responsible for the quality of the data relating to their registered scholarly publications. Several measures are implemented to support this process. Bibliographic data from external sources, such as Thompson Reuters and the Norwegian National Library, are imported to the documentation system in order to facilitate registration and validation of publications. The primary validations and standardisations of the registered data include names of publication channels, document types, institutional affiliations of authors and institutional names. These procedures are crucial, not just for the present publication-based indicator, but for bibliometric analyses in general. They are an excellent basis for future citation analyses in areas where such measures would be appropriate. Authority files containing accepted publication channels, document types and institutional names ensure a predominantly automatic validation and standardisation process. However, manual procedures are necessary to some extent. According to <!--bib29--><a href="#bib29">Sivertsen (2008)</a>, the actual cost of running the model is low compared to the national gains achieved in data registration and data quality.</p><h4 class="norm">THE BIBLIOMETRIC INDICATOR</h4><p class="follows-h4">In order to make fields comparable, the simple bibliometric indicator delimits and weights publications in a way that balances field-specific publication patterns. The indicator's formula consists of two dimensions (see <!--tbl1--><a href="#tbl1">Table 1)</a>. The first dimension classifies publication types into three categories (papers in ISSN-titles, papers in ISBN-titles and ISBN-titles). The second dimension divides publication channels into two levels. Publication points are thus weighted according to publication type and level of publication channel.</p><div id="tbl1" class="figure-table"><h5 class="norm"><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/fig_tab/eps200919t1.html#figure-title">Table 1 - Publication points.</a></h5><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/fig_tab/eps200919t1.html#figure-title"><img alt="Table 1 - Publication points - Unfortunately we are unable to provide accessible alternative text for this. If you require assistance to access this image, please contact help@nature.com or the author" class="thumb" src="table_thumb.gif"></a><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/fig_tab/eps200919t1.html#figure-title" class="full">Full table </a><div class="cleardiv"><!-- clearing div --></div></div><br class="clear"><p class="norm">Level 1 corresponds to publication channels on ‘a normal level’ according to publication patterns within a specific field, whereas level 2 embraces the ‘most selective’ and ‘prestigious’ channels within the field. The latter is given extra weight. As stated above, the division of publication channels is made in order to give researchers incentives to focus their publication activity on a ‘selected number of prestigious channels’ within the research fields and to counter unintended publication behaviour. At any one time, publication channels on level 2 can account for a maximum of 20 per cent of the world's publications within a specific field. The intention behind this rule is to make the division of publication channels dynamic in response to changing publication behaviours among researchers.</p><p class="norm">The Norwegian national research councils in each field of research determine which channels are to belong to level 2. Evaluation and revision are carried out annually and on the basis of specific guidelines that consider primary field publication patterns.</p><p class="norm">Journal rankings of this sort are often controversial. Results are often contested and representatives of emergent fields especially are critical of lack of visibility or lower rankings that such processes accord to them. Nevertheless, the process of journal ranking in Norway has been relatively smooth, in contrast with, for example, a similar process recently carried out in Denmark. The main reason for the difference is likely to be found in the way the ranking process was approached in the two countries. In Norway, a top-down approach was used. A detailed empirical study of all research fields identified three main groups of publication patterns. Notice that the groups do not completely correspond to the traditional divisions among scientific disciplines. As a result, the three groups were issued different guidelines for use in allocating publication channels to level 2. For example, fields belonging to group A have primarily international journal publication patterns, in which the most significant journals have high annual volumes, high rejection ratesand cover a broad range of topics compared to other journals. Most journals in group A are included in Thompson Reuters, and calculations of field-specific citation indicators for journals are somewhat useful for creating a draft of publication channels for level 2. Consequently, provisional draft lists of journals were issued to the Norwegian research councils for each field belonging to group A. These lists were then used as a starting point for negotiation and nomination to level 2 based on the specific guidelines. The same procedure was followed for the other two groups of publication patterns (for further details see the link in note 1). Notice that the classification of publication patterns is only necessary for formulating different guidelines for use in nominating publication channels to level 2. The end result is a common list of publication channels at level 2, which is not divided by research fields. Researchers in all fields may use all channels included in level 2. This approach undoubtedly eliminated some of the potential conflicts usually experienced in journal rankings. The controversies and problems experienced with journal rankings in Denmark supports this. Denmark implemented an <i>ex post</i> funding model very similar to the Norwegian model. Surprisingly, the journal-ranking process in Denmark did not follow the Norwegian top-down approach with a thorough basis for negotiation and nomination to level 2. Instead, a less coordinated bottom-up approach was used. Members of the field-specific research committees were required both to identify relevant publication channels for their specific fields and subsequently to nominate candidates for level 2. Not surprisingly, this uncoordinated process created much confusion, frustration and fierce debate in the Danish research community.</p><p class="norm">Finally, the indicator uses fractional counting. Publications are attributed to institutions according to author affiliations. All institutions are given equal weight. If an author is affiliated with two or more institutions in a publication, the publication will be divided equally among the institutions. Consequently, a publication with one author is worth 1 point. A publication with <i>n</i> authors is worth 1<span class="mb">/</span><i>n</i> point for each author. It was originally suggested that the maximum fraction should be 1<span class="mb">/</span>10 point for publications with more than ten authors. This is not the practice in Norway at the moment. Consequently, an institution is granted publication points according to the following formula: Fraction of authors credited to the institution × publication points for the individual publication (publication type and level of channel).</p><p class="norm">Fractionalised counting is a vital feature in the indicator. It is a provision that should prevent a focus on productivity only, as happened in Australia. If whole counting is applied, in which each participating institution gets full credit, one can easily imagine that the number of co-authored papers will increase </p><blockquote class="pullquote">‘The main argument levelled against fractional counting has been that such a scheme may diminish the incentives to collaboration between institutions, especially international collaboration.’</blockquote><p class="norm">dramatically due to unintended reactive behaviour by authors and institutions.</p><p class="norm">The use of fractionalised counting in the indicator has nevertheless caused some debate. The main argument levelled against fractional counting has been that such a scheme may diminish the incentives to collaboration between institutions, especially international collaboration. However, the argument against such counting is partly based on a myth. Research co-operation is certainly a necessary and positive phenomenon in the era of ‘big science’, but the idea that collaboration is a recipe for guaranteed success is not true (<!--bib7--><a href="#bib7">Glänzel, 2008</a>). It is generally accepted that the visibility and impact of collaborative research is on average moderately higher than that of non-collaborative research (<!--bib25--><a href="#bib25">Persson <i>et al</i>, 2004</a>). But numerous counter-examples confirm that multi-authorship, and above all international collaboration, does not in itself guarantee increases in productivity, visibility or impact, and neither does it facilitate publication in high-impact journals (<!--bib6--><a href="#bib6">Glänzel, 2001</a>; <!--bib9--><a href="#bib9">Glänzel and Schubert, 2001</a>).</p><p class="norm">Hitherto, the position in Norway has been that ‘invisible colleges’ and social networks within research specialties have eventually ensured collaboration, where collaboration has been needed and wanted. Much research depends on collaboration and it is assumed that the funding model will generally not undermine such behaviour. Until now there has been no empirical indication that the Norwegian model causes a drop in national or international collaboration.</p><p class="norm">No optimal counting scheme exists. Fractional counting serves an important function in the Norwegian model, as described above. As no adverse effects can be seen, there is no reason to give special incentives to collaboration.</p><p class="norm">The following section discusses the problems related to the use of bibliometric indicators for research evaluation in the social sciences, and outlines the advantages of the Norwegian model in that respect.</p></div><div id="THE-NORWEGIAN-MODEL-AND-THE-SOCIAL-SCIENCES"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>THE NORWEGIAN MODEL AND THE SOCIAL SCIENCES</h3><p class="norm">Existing bibliometric approaches to research evaluation most often characterise the social sciences according to the data coverage of Thompson Reuters or more recently Scopus. They usually either compare institutions based on this coverage, or simply exclude social-science fields all together in the evaluation of institutions. The former approach has validity problems. The latter approach is clearly limited and also deficient, in as much as it restricts the research fields that come to characterise an institution's research activity and perhaps impact. Indeed, there has been considerable debate about the usefulness of bibliometric indicators as an evaluative tool for the social sciences (<!--bib15--><a href="#bib15">Katz, 1999</a>: 1). There is consensus in the literature that application of bibliometric indicators to the social sciences (and humanities) is difficult primarily due to the limitations of publication coverage in the citation database (e.g., <!--bib13--><a href="#bib13">Hicks, 1999</a>; <!--bib14--><a href="#bib14">2004</a>; <!--bib15--><a href="#bib15">Katz, 1999</a>). Citation databases are usually required for bibliometric analyses whether they are publication- or citation-based or both. The reason is that these databases contain country and institutional affiliations for <i>all</i> authors in contrast with most domain-specific databases. But bibliometric indicators are only appropriate when the database being analysed adequately covers the publications that are the principal carriers of knowledge within a field. The coverage is good in Thompson Reuters and Scopus for most natural- and life-science fields, but not nearly sufficient in the social sciences and humanities. The databases lack coverage of monographs, book chapters and conference proceedings, and they have a highly selective language and geographical coverage as well. This fact undoubtedly throws doubt on the validity of evaluations of performance in the social sciences and humanities relying on these databases. <!--bib14--><a href="#bib14">Hicks (2004</a>: 474) has observed that ‘<span class="mb">[</span>w<span class="mb">]</span>hen challenged to evaluate scholarly work in the social sciences and humanities we are rudely forced to work outside this comfort zone in a frankly messy set of literature’.</p><p class="norm">The national research documentation system in Norway provides a ‘comfort zone’ of reliable and highly structured bibliographic data. Here we have complete annual research publication data for the social sciences and the humanities. The documentation system is not a citation database; instead, complete publication activity for all scientific fields can be measured, and publication behaviour and profiles can be monitored and influenced through the model. From the point of view of the social sciences (and humanities for that matter), the Norwegian model clearly has advantages compared to existing bibliometric approaches to research evaluation at the level of institutions. The most obvious advantage is the emergent visibility of the research activity of these major scientific fields. This enables comparison of institutions based on all their research activity, and likewise direct comparison among different fields of research within and among such institutions.</p><p class="norm">The final section briefly presents some recent experience with the model in Norway, and describes how the Norwegian model seems to have inspired other funding models around the world.</p></div><div id="BIBLIOMETRIC-EXPERIENCE-IN-NORWAY-AND-INFLUENCE-UPON-OTHER-COUNTRIES"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>BIBLIOMETRIC EXPERIENCE IN NORWAY AND INFLUENCE UPON OTHER COUNTRIES</h3><p class="norm">Information about the effects of the funding model in Norway is gradually beginning to appear. According to <!--bib29--><a href="#bib29">Sivertsen (2008)</a>, there has been a substantial growth in publications from the higher education sector in Norway. Notably, the growth in publication output has affected both levels of publication channels. Validation studies on a subset of Norwegian publication data indexed in Thompson Reuters' <i>Web of Knowledge</i> show that the increased publication rates are distributed evenly between high impact journals and other journals (<!--bib29--><a href="#bib29">Sivertsen, 2008</a>). In fact, Norway's relative citation rate has been stable at 25 per cent above the world's average, according to data from Thompson Reuters' <i>National Science Indicators</i> (<!--bib29--><a href="#bib29">Sivertsen, 2008</a>). While there may be several explanations for this increase in production, and the stability in citation rates, it appears that the model seems to work as intended. Until now we have not seen the adverse effects experienced in Australia with their undifferentiated publication-based indicator. We should of course be careful when assessing the immediate effects of the Norwegian model. Bibliometric analyses may show that Norway's performance has increased in comparison to other countries. The problem is that attribution of this improvement to the Norwegian model may turn out to be a <i>post hoc ergo propter hoc</i> fallacy. Experience from the RAE in the United Kingdom suggests this. While </p><blockquote class="pullquote">‘Several comparative studies indicate that the absolute amount of money invested in university research is a much stronger predictor of research performance than any research evaluation model.’</blockquote><p class="norm">the United Kingdom improved its relative performance, so did other countries without research evaluation models. Several comparative studies indicate that the absolute amount of money invested in university research is a much stronger predictor of research performance than any research evaluation model (e.g., <!--bib19--><a href="#bib19">Liefner, 2003</a>). Hence, the RAE was not the only factor influencing improved performance in the United Kingdom. More generally, it is important to monitor performance-based funding models because they may over time lead to ‘homogenisation’ of research, discouraging experiments with new approaches, and rewarding ‘safe’ research, irrespective of its benefits to society. The resulting decrease in diversity may be harmful (<!--bib11--><a href="#bib11">Guena and Martin, 2003</a>). There is also a danger with models that focus on a one-dimensional concept of research ‘quality’ and link the results directly to funding. In the Netherlands, by contrast, performance is assessed along four dimensions – ‘scientific quality’, ‘scientific productivity’, ‘scientific relevance’ and ‘long-term viability’ – and results are not directly linked to funding.</p><p class="norm">Nevertheless, based on the 4 years of experience with the model in Norway, it is reasonable to conclude that it is indeed possible to include <i>all</i> scholarly publications within <i>all</i> scientific fields in a bibliometric indicator. It is particularly important that institutions with different research profiles can be compared based on all their research activity, and thus the different publication patterns among fields are comparable with the Norwegian model.</p><p class="norm">Current approaches to <i>ex post</i> funding models can be classified as to (1) whether they are based on peer review (panel evaluation), bibliometric indicators or a combination of these; (2) whether all or only some research fields are included; and finally (3) whether some or all publications (usually data from Thomson Reuters) are included. In a survey of fourteen countries, <!--bib11--><a href="#bib11">Guena and Martin (2003)</a> identified three countries that at the time had implemented <i>ex post</i> evaluation models for allocating research funds: Britain, Australia and Finland. Only Australia had a model based on a bibliometric indicator directly linked to funding. Today, more countries have implemented, or are considering implementing, such directly linked <i>ex post</i> funding models. Norway and Belgium (Flanders) have implemented, and Denmark and Sweden are in the process of implementing, such models. Britain and Finland are changing their current models, but maintaining <i>ex post</i> funding. Only Australia has for the time being given up <i>ex post</i> funding of research.</p><p class="norm">Obviously, the model in Norway is based on a bibliometric indicator, and includes all fields and all publications. The RAE in the United Kingdom has been re-considering the standard panel evaluation, where in principle all fields are included and the institutions are allowed to submit a selected number of publications within each field for evaluation. As stated above, the RAE is to be replaced after the 2008 evaluation with a metric-oriented model. Denmark is currently implementing a model profoundly influenced by the Norwegian model. It seems that there will be only minor differences between the two models. One difference might be the extra incentive to collaboration in the Danish model. Finland has not yet decided upon whether to use a panel- or bibliometric-based model. Flanders currently relies upon a model based on bibliometric indicators (both publication- and citation-based indicators) for selected fields using data from Thompson Reuters.<!--ftnote3--><a href="#ftnote3"><sup>3</sup></a> However, the model is to be modified due to the above-mentioned problems, with measuring performance in the social sciences and humanities (<!--bib5--><a href="#bib5">Debackere and Glänzel, 2008</a>). Most interestingly, the Norwegian model is to be the basis for the modification in Flanders. For the time being, Australia has turned down a performance-based funding model; however, an initiative has been implemented that will evaluate Australian research in general. This initiative is inspired by the Norwegian model, as a comprehensive list of publication channels is compiled and the channels weighted. Finally, Sweden has recently chosen a model comparable to the one that is to be modified in Flanders, based on bibliometric indicators for selected fields using data from Thompson Reuters. In fact, the indicator in Sweden is rather unorthodox as it tries to <i>estimate</i> and <i>predict</i> performance for all fields based on a limited set of data from Thompson Reuters (<!--bib27--><a href="#bib27">Sandström and Sandström, 2008</a>).</p></div><div id="CONCLUSION"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>CONCLUSION</h3><p class="norm">Let us end with some general comments on bibliometric indicators and the apparently expanding ‘ranking industry’ (e. g., <!--bib33--><a href="#bib33">van Raan, 2005</a>). It is necessary to warn against the unthinking use of indicators and rankings in research policy applications and evaluations. Indicators and rankings are not natural objects. They are cultural constructs that are theoretically informed by underlying assumptions (<!--bib18--><a href="#bib18">Leydesdorff, 2008</a>). In general, such tools reduce the complexity of a multidimensional problem to a simple number. It is therefore important that users of indicators and rankings, such as policymakers and administrators, be aware of their underlying assumptions and potential effects. Different indicators have strengths and limits, and no indicator alone can express the multidimensional complexities involved in research evaluation. The choice of indicators depends on priorities and aims. In Norway priority was given to transparency and evaluation of institutions based on <i>all</i> research fields and <i>all</i> their scholarly publications. This aim determined the initial choice of indicator. However, it does not exclude the later use of alternative indicators or peer review evaluations, in which this would be appropriate. Indeed, different indicators and peer reviews should be productively combined rather than being made to compete with each other (<!--bib22--><a href="#bib22">Moed, 2005</a>). But regardless of the indicator chosen, the documentation system created in Norway sets new standards for national research registration, and thus for the quality of the publication data needed for bibliometric analyses. All countries should strive for this.</p></div><div id="footnote-endnote"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>Notes</h3><p id="ftnote1" class="footnote"><sup>1</sup>&nbsp;A detailed description of the indicator, its background and development, is available in <a href="http://www.uhr.no/documents/Rapport_fra_UHR_prosjektet_4_11_engCJS_endelig_versjon_av_hele_oversettelsen.pdf">www.uhr.no/documents/Rapport_fra_UHR_prosjektet_4_11_engCJS_endelig_versjon_av_hele_oversettelsen.pdf</a>. Most of the detailed description of the documentation system and the bibliometric indicator is based on the document.</p><p id="ftnote2" class="footnote"><sup>2</sup>&nbsp;For comprehensive reviews of subjectivity and reliability issues, see <!--bib3--><a href="#bib3">Cicchetti (1991)</a> and <!--bib17--><a href="#bib17">Langfeldt (2001)</a>, and for comparisons with bibliometric indicators, see <!--bib22--><a href="#bib22">Moed (2005)</a>.</p><p id="ftnote3" class="footnote"><sup>3</sup>&nbsp;A different model is used in the remainder of Belgium.</p></div><div id="References"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>References</h3>
	<ol class="norm"><li id="bib1"><a name="bib1"><!-- . --></a>Butler, L. (2001) <span class="journal">Monitoring Australia's Scientific Research: Partial Indicators of Australia's Research Performance</span>, Canberra: Australian Academy of Sciences.</li><li id="bib2"><a name="bib2"><!-- . --></a>Butler, L. (2004) 'What Happens When Funding is Linked to Publication Counts?', in H. F. Moed, W. Glänzel and U. Schmoch (eds.) <span class="journal">Handbook of Quantitative Science and Technology</span>, Dordrecht, The Netherlands: Kluwer Academic Publishers, pp. 340–389.</li><li id="bib3"><a name="bib3"><!-- . --></a>Cicchetti, D.V. (1991) 'The reliability of peer review for manuscript and grant submissions: A cross-disciplinary investigation', <span class="journal">Behavioral and Brain Sciences</span> <span class="jnumber">14</span>: 119–186.</li><li id="bib4"><a name="bib4"><!-- . --></a>Debackere, K. and Glänzel, W. (2004) 'Using a bibliometric approach to support research policy making: The case of the Flemish BOF-key', <span class="journal">Scientometrics</span> <span class="jnumber">59</span>(2): 253–276.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1023/B:SCIE.0000018532.70146.02" class="reftxt" title="">Article</a></li><li id="bib5"><a name="bib5"><!-- . --></a>Debackere, K. and Glänzel, W. (2008) 'Evidence-based bibliometrics: A decade of bibliometrics-based science policy in Flanders', in J. Goriaz and E. Schiebel (eds.) <span class="journal">Book of abstracts, 10th international science and technology indicators conference</span>, 17–20 September 2008, Austria: University of Vienna, pp. 123–125.</li><li id="bib6"><a name="bib6"><!-- . --></a>Glänzel, W. (2001) 'National characteristics in international scientific co-authorship', <span class="journal">Scientometrics</span> <span class="jnumber">51</span>(1): 69–115.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1023/A:1010512628145" class="reftxt" title="">Article</a></li><li id="bib7"><a name="bib7"><!-- . --></a>Glänzel, W. (2008) 'Seven myths in bibliometrics. About facts and fiction in quantitative science studies', in H. Kretschmer and F. Havemann (eds.) Proceedings of WIS 2008, Berlin, Fourth International Conference on Webometrics, Informetrics and Scientometrics and Ninth COLLNET Meeting Humboldt-Universität zu Berlin, Institute for Library and Information Science (IBI): <a href="http://www.collnet.de/Berlin-2008/GlanzelWIS2008smb.pdf">http://www.collnet.de/Berlin-2008/GlanzelWIS2008smb.pdf</a>, (accessed 7 October 2008).</li><li id="bib8"><a name="bib8"><!-- . --></a>Glänzel, W. and Schoepflin, U. (1994) 'Little scientometrics, big scientometrics ... and beyond', <span class="journal">Scientometrics</span> <span class="jnumber">30</span>: 375–384.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1007/BF02018107" class="reftxt" title="">Article</a></li><li id="bib9"><a name="bib9"><!-- . --></a>Glänzel, W. and Schubert, A. (2001) 'Double effort=double impact? A critical view of international co-authorship in chemistry', <span class="journal">Scientometrics</span> <span class="jnumber">50</span>(2): 199–214.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1023/A:1010561321723" class="reftxt" title="">Article</a></li><li id="bib10"><a name="bib10"><!-- . --></a>Gläser, J. and Laudel, G. (2007) 'The Social Construction Of Bibliometric Evaluations', in R. Whitley and J. Gläser (eds.) <span class="journal">The Changing Governance of the Sciences: The Advent of Research Evaluation Systems, Sociology of Sciences Yearbook 26</span>, Dordrecht, The Netherlands: Springer, pp. 101–123.</li><li id="bib11"><a name="bib11"><!-- . --></a>Guena, A. and Martin, B.R. (2003) 'University research evaluation and funding: An international comparison', <span class="journal">Minerva</span> <span class="jnumber">41</span>(4): 277–304.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1023/B:MINE.0000005155.70870.bd" class="reftxt" title="">Article</a></li><li id="bib12"><a name="bib12"><!-- . --></a>Harzing, A.-W.K. and van del Wal, R. (2008) 'Google scholar as a new source for citation analysis', <span class="journal">Ethics in Science and Environmental Politics</span> <span class="jnumber">8</span>: 61–73.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.3354/esep00076" class="reftxt" title="">Article</a></li><li id="bib13"><a name="bib13"><!-- . --></a>Hicks, D. (1999) 'The difficulty of achieving full coverage of international social science literature and the bibliometric consequences', <span class="journal">Scientometrics</span> <span class="jnumber">44</span>(2): 193–215.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1007/BF02457380" class="reftxt" title="">Article</a></li><li id="bib14"><a name="bib14"><!-- . --></a>Hicks, D. (2004) 'The Four Literatures of Social Science', in H. F. Moed, W. Glänzel and U. Schmoch (eds.) <span class="journal">Handbook of Quantitative Science and Technology</span>, Dordrecht, The Netherlands: Kluwer Academic Publishers, pp. 473–496.</li><li id="bib15"><a name="bib15"><!-- . --></a>Katz, J.S. (1999) 'Bibliometric Indicators and the Social Sciences', Report prepared for UK Economic and Social Research Council, <a href="http://www.sussex.ac.uk/Users/sylvank/pubs/ESRC.pdf">www.sussex.ac.uk/Users/sylvank/pubs/ESRC.pdf</a>, (accessed 7 October 2008).</li><li id="bib16"><a name="bib16"><!-- . --></a>Kogan, M. (1989) 'The Evaluation of Higher Education: An Introductory Note', in M. Kogan (ed.) <span class="journal">Evaluating Higher Education</span>, London: Jessica Kingsley Publishers, pp. 11–25.</li><li id="bib17"><a name="bib17"><!-- . --></a>Langfeldt, L. (2001) 'The decision-making constraints and processes of grant peer review, and their effects on the review outcome', <span class="journal">Social Studies of Science</span> <span class="jnumber">31</span>: 820–841.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1177/030631201031006002" class="reftxt" title="">Article</a></li><li id="bib18"><a name="bib18"><!-- . --></a>Leydesdorff, L. (2008) 'Caveats for the use of citation indicators in research and journal evaluations', <span class="journal">Journal of the American Society for Information Science and Technology</span> <span class="jnumber">59</span>(2): 278–287.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1002/asi.20743" class="reftxt" title="">Article</a></li><li id="bib19"><a name="bib19"><!-- . --></a>Liefner, I. (2003) 'Funding resources allocation and performance in higher education systems', <span class="journal">Higher Education</span> <span class="jnumber">46</span>: 469–489.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1023/A:1027381906977" class="reftxt" title="">Article</a></li><li id="bib20"><a name="bib20"><!-- . --></a>Martin, B.R. and Irvine, J. (1983) 'Assessing basic research. Some partial indicators of scientific progress in radio astronomy', <span class="journal">Research Policy</span> <span class="jnumber">12</span>: 61–90.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1016/0048-7333(83)90005-7" class="reftxt" title="">Article</a>&nbsp;|&nbsp;<a href="http://links.isiglobalnet2.com/gateway/Gateway.cgi?&amp;amp;GWVersion=2&amp;amp;SrcAuth=Nature&amp;amp;SrcApp=Nature&amp;amp;DestLinkType=FullRecord&amp;amp;KeyUT=A1983QR82000001&amp;amp;DestApp=WOS_CPL" class="reftxt" title="Article on ISI - ">ISI</a></li><li id="bib21"><a name="bib21"><!-- . --></a>Meho, L.I. and Yang, K. (2007) 'Impact of data sources on citation counts and rankings of LIS faculty: Web of Science versus Scopus and Google scholar', <span class="journal">Journal of the American Society for Information Science and Technology</span> <span class="jnumber">58</span>(13): 2105–2125.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1002/asi.20677" class="reftxt" title="">Article</a></li><li id="bib22"><a name="bib22"><!-- . --></a>Moed, H.F. (2005) <span class="journal">Citation Analysis in Research Evaluation</span>, Dordrecht: Springer Verlag.</li><li id="bib23"><a name="bib23"><!-- . --></a>Moed, H.F., Burger, W.J.M., Frankfort, J.G. and Van Raan, A.F.J. (1985) 'The use of bibliometric data for the measurement of university research performance', <span class="journal">Research Policy</span> <span class="jnumber">14</span>: 131–149.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1016/0048-7333(85)90012-5" class="reftxt" title="">Article</a></li><li id="bib24"><a name="bib24"><!-- . --></a>Moravcsik, M.J. (1973) 'Measures of scientific growth', <span class="journal">Research Policy</span> <span class="jnumber">2</span>: 266–275.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1016/0048-7333(73)90006-1" class="reftxt" title="">Article</a></li><li id="bib25"><a name="bib25"><!-- . --></a>Persson, O., Glänzel, W. and Danell, R. (2004) 'Inflationary bibliometric values: The role of scientific collaboration and the need for relative indicators in evaluative studies', <span class="journal">Scientometrics</span> <span class="jnumber">60</span>(3): 421–432.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1023/B:SCIE.0000034384.35498.7d" class="reftxt" title="">Article</a>&nbsp;|&nbsp;<a href="http://chemport.cas.org/cgi-bin/sdcgi?APP=ftslink&amp;action=reflink&amp;origin=npg&amp;version=1.0&amp;coi=1:CAS:528:DC%2BD2cXnt1Kmt74%3D&amp;pissn=1680-4333&amp;pyear=2009&amp;md5=ce92c6eed600f597147fe65bb6b8ae29" class="reftxt" title="Article on ChemPort - ">ChemPort</a>&nbsp;|</li><li id="bib26"><a name="bib26"><!-- . --></a>Sandström, U. and Sandström, E. (2007) 'A Metrics for academic science applied to Australian Universities', <a href="http://eprints.rclis.org/archive/00011776/">http://eprints.rclis.org/archive/00011776/</a>, (accessed 7 October 2008).</li><li id="bib27"><a name="bib27"><!-- . --></a>Sandström, U. and Sandström, E. (2008) 'Resurser för citeringar', Högskoleverkets rapportserie 2008:18 R, Utgiven av Högskoleverket 2008: <a href="http://forskningspolitik.se/DataFile.asp?FileID=15">http://forskningspolitik.se/DataFile.asp?FileID=15</a>, (accessed 7 October 2008).</li><li id="bib28"><a name="bib28"><!-- . --></a>Sivertsen, G. (2006) 'A bibliometric model for performance based budgeting of research institutions', in K. Debackere and W. Glänzel (eds.) <span class="journal">Book of abstracts, 9th international science and technology indicators conference</span>, 7–9 September 2006, Leuven, Belgium: Katholieke Universiteit, pp. 133–135.</li><li id="bib29"><a name="bib29"><!-- . --></a>Sivertsen, G. (2008) 'Experiences with a bibliometric model for performance based funding of research institutions', in J. Goriaz and E. Schiebel (eds.) <span class="journal">Book of abstracts, 10th international science and technology indicators conference</span>, 17–20 September 2008, Austria: University of Vienna, pp. 126–128.</li><li id="bib30"><a name="bib30"><!-- . --></a>Smith, L. (1981) 'Citation analysis', <span class="journal">Library Trends</span> <span class="jnumber">30</span>: 83–106.</li><li id="bib31"><a name="bib31"><!-- . --></a>van Raan, A.J.F. (1996) 'Advanced bibliometric methods as quantitative core of peer review based evaluation and foresight exercises', <span class="journal">Scientometrics</span> <span class="jnumber">36</span>: 397–420.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1007/BF02129602" class="reftxt" title="">Article</a></li><li id="bib32"><a name="bib32"><!-- . --></a>van Raan, A.J.F. (2000) 'The Pandora's Box of Citation Analysis: Measuring Scientific Excellence – The Last Evil?', in B. Cronin and H. B. Atkins (eds.) <span class="journal">The Web of Knowledge</span>, Medford, NJ: Information Today Inc, pp. 301–319.</li><li id="bib33"><a name="bib33"><!-- . --></a>van Raan, A.F.J. (2005) 'Fatal attraction: Conceptual and methodological problems in the ranking of universities by bibliometric methods', <span class="journal">Scientometrics</span> <span class="jnumber">62</span>(1): 133–143.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1007/s11192-005-0008-6" class="reftxt" title="">Article</a>&nbsp;|&nbsp;<a href="http://chemport.cas.org/cgi-bin/sdcgi?APP=ftslink&amp;action=reflink&amp;origin=npg&amp;version=1.0&amp;coi=1:CAS:528:DC%2BD2MXit1Wguro%3D&amp;pissn=1680-4333&amp;pyear=2009&amp;md5=dfac76751c487c7d256ca2527996d787" class="reftxt" title="Article on ChemPort - ">ChemPort</a>&nbsp;|</li><li id="bib34"><a name="bib34"><!-- . --></a>Weingart, P. (2005) 'Impact of bibliometrics upon the science system: Inadvertent consequences?' <span class="journal">Scientometrics</span> <span class="jnumber">62</span>(1): 117–131.&nbsp;|&nbsp;<a href="http://dx.doi.org/10.1007/s11192-005-0007-7" class="reftxt" title="">Article</a>&nbsp;|&nbsp;<a href="http://chemport.cas.org/cgi-bin/sdcgi?APP=ftslink&amp;action=reflink&amp;origin=npg&amp;version=1.0&amp;coi=1:CAS:528:DC%2BD2MXit1Wgur0%3D&amp;pissn=1680-4333&amp;pyear=2009&amp;md5=39dd3d457a6830dcdb79b8ab79da15c3" class="reftxt" title="Article on ChemPort - ">ChemPort</a>&nbsp;|</li><li id="bib35"><a name="bib35"><!-- . --></a>Whitley, R. (2007) 'Changing Governance of the Public Science: The Consequences of Establishing Research Evaluation Systems for Knowledge Production in Different Countries and Scientific Fields', in R. Whitley and J. Gläser (eds.) <span class="journal">The Changing Governance of the Sciences: The Advent of Research Evaluation Systems, Sociology of Sciences Yearbook 26</span>, Dordrecht, The Netherlands: Springer, pp. 3–27.</li></ol></div><div id="ack"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>Acknowledgements</h3><p class="norm">The author thanks Gunnar Sivertsen from the Norwegian Institute for Studies in Innovation, Research and Education (NIFU STEP) for his kind support and his generous sharing of data and information in relation to the model and the experiences with it. The author also thanks the anonymous reviewers for their valuable comments.</p></div><div id="biographies"><a class="backtotop" href="#top">Top<span class="hidden"> of page</span></a><h3>About the author</h3><p class="norm"><b>Jesper W. Schneider</b> is an associate professor at the Royal School of Library and Information Science in Aalborg, Denmark. He holds a PhD degree in information science, and his specialties are bibliometrics and research evaluation. His main research interest is science mapping. Some principal publications in this area can be found at <a href="http://www.db.dk/jws">www.db.dk/jws</a>. For several years, he has been working as a bibliometric consultant for the Danish Agency for Science Technology and Innovation advising them in relation to implementing a performance-based research funding model in Denmark, as well as doing <i>ad hoc</i> bibliometric analyses.</p></div><div id="more">
	</div><!-- articlebody end --></div></div><!-- end content --><div class="archive" id="journalnav"><h1 class="hidden">Main navigation</h1><!-- necessary for correct descending order heading hierarchy - do not remove! -->
			<!-- whitespace removed to deal with IE5.0 PC bug. -->
<map title="main journal navigation" id="main-journal-nav" class="journal-nav">
<ul><li class="jn-home"><a href="http://www.palgrave-journals.com/eps/">Journal home</a></li>
	<li class="jn-aop"><a href="http://www.palgrave-journals.com/eps/journal/vaop/ncurrent/">Advance online publication</a>
		<ul class="subnav"><li class="jn-about-aop"><a href="http://www.palgrave-journals.com/eps/about_aop.html">About AOP</a></li></ul>
	</li>
	<li class="jn-issue"><a href="http://www.palgrave-journals.com/eps/journal/v12/n4/">Current issue</a></li>
	<li class="jn-archive"><a href="http://www.palgrave-journals.com/eps/archive/index.html">Archive</a></li>
	<!-- <li class="jn-press-releases"><a href="/eps/press_releases.html">Press releases</a></li> -->
	<li><a href="http://www.palgrave-journals.com/catalog/catalog_eps.pdf">Catalog entry</a></li>
</ul>
</map>		<!-- whitespace removed to deal with IE5.0 PC bug. -->
<map title="supplementary journal navigation" id="supplementary-journal-nav" class="journal-nav supplementary">
	<ul>
		<!--li class="jn-online-submission"><a href="http://eps.msubmit.net/" class="submission">Online submission</a></li-->
		 <li class="jn-ecpr-news"><a href="http://www.palgrave-journals.com/eps/archive/ne_current_archive.html">ECPR news</a></li>
		<li class="jn-for-authors"><a href="http://www.palgrave-journals.com/eps/author_instructions.html">Instructions for authors</a></li>
		<li class="jn-contact-eds"><a href="http://www.palgrave-journals.com/eps/contact_eds.html">Contact the editors</a></li>
		<li class="jn-about-the-journal"><a href="http://www.palgrave-journals.com/eps/about.html">About the journal</a></li>
		<!--li class="jn-about-the-society"><a href="/eps/about_society.html">About the society</a></li-->
		<!--li class="jn-call-for-papers"><a href="/eps/call_for_papers.html">Call for papers</a></li-->
		<li class="jn-subscribe"><a href="http://www.palgrave-journals.com/eps/subscribe.html">Subscribe</a></li>
		<li class="jn-contact-us"><a href="http://www.palgrave-journals.com/eps/contact_us.html">Contact Palgrave Macmillan</a></li>
		<li class="jn-sample-copy"><a href="http://www.palgrave.com/palgravejournals/journalregistration.aspx">Sample articles</a></li>
		<li class="jn-reprints"><a href="http://www.palgrave-journals.com/pal/information/reprint.html">Order reprints</a></li>
		<li class="jn-permissions"><a href="http://www.palgrave-journals.com/pal/authors/rights_and_permissions.html">Rights and permissions</a></li>
		<!--li class="jn-mediapack"><a href="/pal/advertisers/pdf/>Media Pack</a></li-->
	</ul>
</map>		<h2 class="related-titles">Related titles</h2>
		<ul class="related-titles">	
			<li><a href="http://www.palgrave-journals.com/politics/">Politics</a></li>
		</ul>		<h2 class="palgrave-journals">Palgrave Macmillan Journals</h2>
		<ul class="palgrave-journals">
			<li><a href="http://www.palgrave-journals.com/pal/">Home</a></li>
			<li class="jn-for-authors"><a href="http://www.palgrave-journals.com/pal/authors/">For authors</a></li>
			<li class="jn-institutions"><a href="http://www.palgrave-journals.com/pal/institutions/">For institutions</a></li>
			<li class="jn-librarians"><a href="http://www.palgrave-journals.com/pal/librarians/index.html">For librarians</a></li>
			<li class="jn-personal"><a href="http://www.palgrave-journals.com/pal/personal/">For personal users</a></li>
			<li class="jn-advertising"><a href="http://www.palgrave-journals.com/pal/advertisers/">For advertisers</a></li>
		</ul>		<h2 class="palgrave-journals">Palgrave Macmillan Books</h2>
		<ul class="palgrave-journals">
			<li><a href="http://www.palgrave.com/politics/">Politics</a></li>
		</ul></div></div><!-- end content and journal nav --><div id="extranav"><h1 class="hidden">Extra navigation</h1><span class="page-header-spacer">.</span><div id="articlenav"><h2><span class="hidden">ARTICLE NAVIGATION - </span>FULL TEXT</h2><div class="prevnext"><a title="previous article in this issue" class="prev" href="http://www.palgrave-journals.com/eps/journal/v8/n3/full/eps200917a.html">Previous</a><span class="divider"> | </span><a title="next article in this issue" class="next" href="http://www.palgrave-journals.com/eps/journal/v8/n3/full/eps200912a.html">Next</a></div><ul><li class="toc"><a class="toc" href="http://www.palgrave-journals.com/eps/journal/v8/n3/index.html">Table of contents</a></li><li class="download-pdf"><a class="download-pdf" href="http://www.palgrave-journals.com/eps/journal/v8/n3/pdf/eps200919a.pdf">Download PDF</a></li><li class="sendtofriend"><a class="sendtofriend" href="http://www.palgrave-journals.com/foxtrot/svc/mailform?file=/eps/journal/v8/n3/full/eps200919a.html">Send to a friend</a></li><li class="cited"><a class="cited" href="http://www.scopus.com/inward/record.url?eid=2-s2.0-68949103694&amp;partnerID=65&amp;md5=a93070e0d28ea1f74baf0fd53577c836">Scopus lists 11 articles citing this article</a></li>

				

<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript"><!--//--><![CDATA[//><!--
	(function($) {
		scopus = {
			receive: function(data){
				defaultStatus="";
				// get the article search total results count (should be 1)
				var articleResultCount=data.OK.TotalResults;
	
				if(articleResultCount > 0) {
					// get the count of citing articles and output to page
					var citedArticleCount = data.OK.Results[0].citedbycount;
					window.status = 'Scopus lists ' + citedArticleCount + ' articles citing this article';
	
					if(citedArticleCount > 0) {
						// get the url to the "cited by" results page
						var citationLink = data.OK.Results[0].inwardurl;
						// create the HTML snippet <li> to add
						var snippetLIElement = '<li class="cited"><a class="cited" href="' + citationLink + '">Scopus lists ' + citedArticleCount + ' article' + ((citedArticleCount > 1)?'s':'') + ' citing this article</a></li>';
						// add the new <li> a) after a <li class="cited"> if it exists; b) otherwise, before <li class="export">
						var citedLiElements = jQuery("li.cited");
						if(jQuery(citedLiElements).length == 1) {
							// insert the <li> after the "CrossRef citing" element
							jQuery(citedLiElements[0]).after(snippetLIElement);
						} else if (jQuery("li.sendtofriend").length > 0) {
							// insert the <li> before the "Export references" element
							jQuery("li.sendtofriend:last").after(snippetLIElement);
						} else if (jQuery("li.permissions last").length > 0) {
							jQuery("li.permissions last").before(snippetLIElement);
						} else {
							window.status='No location for Scopus found';
						}
					}
				} else {
					window.status = 'Scopus does not recognise this article';
				}
	
			}
		}
		
								callback = '<script src="http://www.scopus.com/scsearchapi/search.url?devId=6Bq6TF0exIbPa53svS3GnThk6jqgt6&search=DOI(10.1057/eps.2009.19)&fields=citedbycount%2Cinwardurl&callback=scopus.receive" type="text/javascript"><\/script>';
			$('body').append(callback)
			})(jQuery);
//--><!]]></script>
<li class="permissions last"><a class="permissions" href="http://s100.copyright.com/AppDispatchServlet?publisherName=PMJ&amp;publication=European+Political+Science&amp;title=An+Outline+of+the+Bibliometric+Indicator+Used+for+Performance-Based+Funding+of+Research+Institutions+in+Norway&amp;author=Jesper+W+Schneider&amp;contentID=10.1057/eps.2009.19&amp;publicationDate=09/01/2009&amp;volumeNum=8&amp;issueNum=3">Request Permission</a></li>			<li><a class="page" href="#abs">Abstract</a></li><li><a class="page" href="#BACKGROUND">BACKGROUND</a></li><li><a class="page" href="#THE-COMPONENTS-OF-THE-MODEL">THE COMPONENTS OF THE MODEL</a></li><li><a class="page" href="#THE-NORWEGIAN-MODEL-AND-THE-SOCIAL-SCIENCES">THE NORWEGIAN MODEL AND THE SOCIAL SCIENCES</a></li><li><a class="page" href="#BIBLIOMETRIC-EXPERIENCE-IN-NORWAY-AND-INFLUENCE-UPON-OTHER-COUNTRIES">BIBLIOMETRIC EXPERIENCE IN NORWAY AND INFLUENCE UPON OTHER COUNTRIES</a></li><li><a class="page" href="#CONCLUSION">CONCLUSION</a></li><li><a class="page" href="#footnote-endnote">Notes</a></li><li><a class="page" href="#References">References</a></li><li><a class="page" href="#ack">Acknowledgements</a></li><li><a class="page" href="#biographies">About the author</a></li><li><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/fig_tab/eps200919ft.html#figure-title">Figures and Tables</a></li></ul><ul class="supplementary"><li><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/ris/eps200919a.ris">Export citation</a></li><li><a href="http://www.palgrave-journals.com/eps/journal/v8/n3/ris/eps200919arefs.ris">Export references</a></li></ul><ul class="supplementary"></ul></div>
	<!-- div class="society-logo"><a href="#" title="#"><img src="#" style="max-width:100px; height:93px; border:0;" alt="#" /></a></div-->
	<h2 class="society-resources">ECPR resources</h2>
		<ul class="society-resources"><li><a href="http://www.essex.ac.uk/ECPR/">ECPR home page</a></li>
<li><a href="http://www.palgrave-journals.com/eps/archive/ne_current_archive.html">ECPR news</a></li></ul>
	<div class="ad-vert"><!--ADVERTISEMENT--><br>


<div class="ad-box">
<a href="http://www.palgrave-journals.com/politics/index.html"><img src="Politics-and-International-Relations-skyscraper-ad_AW.PNG" style="width: 160px; height: 555px; border: 0px none;" class="ad-vert" alt="View the Politics &amp; International Relations cluster page" title="View the Politics &amp; International Relations cluster page" <="" a=""></a></div><a href="http://www.palgrave-journals.com/politics/index.html">


</a></div></div><a href="http://www.palgrave-journals.com/politics/index.html">
	<!-- global links -->
<div class="cleardiv"><!--  --></div>




<!-- closing divs for fixed width layout -->
</a></div></div><a href="http://www.palgrave-journals.com/politics/index.html">



</a><p class="back-to-top hidden"><a href="http://www.palgrave-journals.com/politics/index.html"></a><a href="#top" title="Return to the top of this page">Top</a></p>
<div id="foot-er" class="footer">


<!-- adboard footer ad -->


			

			
		<!--display adboard footer ad -->
			<!--div class="header-leaderboard-wrap"-->
			<div>
				<div class="header-leaderboard">
					<!--a href="/pal/index.html"><img src="/pal/images/pal_banner_ad_missing_somet.gif" alt="Advertisement" /></a-->

					<div>
					<a href="http://publicationethics.org/" title="Committee on Publication Ethics - external website."><img src="logo_cope.gif" alt="COPE logo." style="vertical-align: text-top; border: 0px none;"></a>
					
					<a href="http://www.ithenticate.com/" title="ithenticate - external website."><img src="iThenticate-logo.gif" alt="ithenticate logo." style="vertical-align: text-top; border: 0px none;"></a>
					</div>

					<div>


					This journal is a member of and subscribes to the principles of the <a href="http://publicationethics.org/" title="Committee on Publication Ethics">Committee on Publication Ethics</a>.
					</div>
					
							
				</div>
			</div>
			<img src="clear.gif" style="border: 0px none; width: 1px; height: 14px;" alt=""><br>
		<!-- end adboard footer ad -->


    <div id="footer-journal">
        <div class="footer-constrain clearfix">        <p class="journal-name">European Political Science</p>        	<p class="issn" style="border-right: 1px solid rgb(0, 0, 0);"><abbr title="International Standard Serial Number">ISSN</abbr><span class="hidden">:</span> 1680-4333</p>        <p class="eissn"><abbr title="Electronic International Standard Serial Number">EISSN</abbr><span class="hidden">:</span> 1682-0983</p>	        <div class="cleardiv"><!--  --></div></div>        <div class="cleardiv"><!--  --></div>
    </div>
    <div id="footer-links">
        <div class="footer-constrain">            <ul>
			<li><a class="about-npg" href="http://www.palgrave.com/AboutUs/">About Palgrave Macmillan</a></li><li><a href="http://www.palgrave-journals.com/pal/information/contact_us.html">Contact Us</a></li><li><a href="http://www.palgrave.com/home/copyright.asp">Legal Notice</a></li><li><a href="http://www.palgrave-journals.com/pal/privacy.html">Privacy Notice</a></li><li><a href="http://www.palgrave-journals.com/pal/cookies.html">Use of Cookies</a></li><li><a href="http://www.palgrave-journals.com/pal/accessibility.html">Accessibility Statement</a></li><li><a class="rss" href="http://www.palgrave-journals.com/pal/information/webfeeds.html"><abbr title="RDF Site Summary">RSS</abbr> Web feeds</a></li><li><a href="http://www.palgrave-journals.com/help">Help</a></li>            </ul>
	        <div class="cleardiv"><!--  --></div>
        </div>    </div>

<p id="footer-copyright">

Copyright © 2014 Palgrave Macmillan, a division of Macmillan Publishers Limited. A company registered in England and Wales under Company Number: 785998 with its registered office at Brunel Road, Houndmills, Basingstoke, Hants, RG21 6XS, United Kingdom.<br>Palgrave Macmillan Journals - partner of <a href="http://www.inasp.info/">INASP</a>,  <a href="http://www.newschool.edu/centers/jdp">JDP</a>,  <a href="http://www.crossref.org/">Cross<span class="hidden"> </span>Ref</a>, <a href="http://www.projectcounter.org/">COUNTER</a>, <a href="http://publicationethics.org/">COPE</a> and <a href="http://www.ithenticate.com/">iThenticate</a>. <a href="http://www.palgrave-journals.com/pal/information/partners.html">View Partners</a>
</p>



</div>

<!--


    <div id="footer-copyright">
		<div class="footer-constrain">				        <p class="logo"><a href="$footerCopyrightLink.get(1)">$footerCopyrightLink.get(0)</a></p>
        </div>    </div>
</div>
 -->
<!-- end global links -->

	<!-- super body bottom -->
<!-- super javascript -->
												
						<script type="text/javascript" src="jquery.js"></script>
								<script type="text/javascript" src="group.js"></script>
			

<script type="text/javascript"><!--//--><![CDATA[//><!--
(function($) {
	$('a.popup-this').bind('click', function() {
		window.open(this.href);
		return false;
	});
})(jQuery);
//--><!]]></script>



																																																																																																																																																																																																																																								
<!--[if IE 6]>
<![endif]-->
																																																																																																																																																																																																																																																																																																																																																																																																																																																																																



	<noscript>

		<div><img alt="" id="DCSIMG" width="1" height="1" src="http://statse.webtrendslive.com/dcscbza1i10000s14yfywibo3_5i9g/njs.gif?dcsuri=/nojavascript&amp;WT.js=No&amp;WT.tv=10.2.55" /></div>	
	</noscript>
	



</body>
</html>
